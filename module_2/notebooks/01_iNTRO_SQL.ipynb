{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "862aac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ac8eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(r\"C:\\Users\\dhanu\\OneDrive\\Desktop\\Repo\\VR_Training\\module_2\\database\\VR.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf765d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor =  conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c5c7420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x27041f2be40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"SELECT * FROM employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dac3eb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'John', 'Smith', 'john.smith@company.com', '2020-01-15', 95000, 1, None)\n",
      "(2, 'Sarah', 'Johnson', 'sarah.johnson@company.com', '2019-03-22', 87000, 1, 1)\n",
      "(3, 'Mike', 'Brown', 'mike.brown@company.com', '2021-06-10', 72000, 1, 1)\n",
      "(4, 'Emily', 'Davis', 'emily.davis@company.com', '2020-09-05', 68000, 2, None)\n",
      "(5, 'David', 'Wilson', 'david.wilson@company.com', '2018-11-30', 78000, 2, 4)\n",
      "(6, 'Lisa', 'Anderson', 'lisa.anderson@company.com', '2022-02-14', 85000, 3, None)\n",
      "(7, 'Tom', 'Taylor', 'tom.taylor@company.com', '2021-08-20', 65000, 3, 6)\n",
      "(8, 'Anna', 'Martinez', 'anna.martinez@company.com', '2020-04-12', 62000, 4, None)\n",
      "(9, 'Chris', 'Garcia', 'chris.garcia@company.com', '2019-07-08', 89000, 5, None)\n",
      "(10, 'Jessica', 'Lee', 'jessica.lee@company.com', '2021-12-03', 71000, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in cursor.fetchall():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d183b97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b88309dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88617978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x27042286040>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"SELECT * from employees where salary > 70000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5c9b1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'John', 'Smith', 'john.smith@company.com', '2020-01-15', 95000, 1, None)\n",
      "(2, 'Sarah', 'Johnson', 'sarah.johnson@company.com', '2019-03-22', 87000, 1, 1)\n",
      "(3, 'Mike', 'Brown', 'mike.brown@company.com', '2021-06-10', 72000, 1, 1)\n",
      "(5, 'David', 'Wilson', 'david.wilson@company.com', '2018-11-30', 78000, 2, 4)\n",
      "(6, 'Lisa', 'Anderson', 'lisa.anderson@company.com', '2022-02-14', 85000, 3, None)\n",
      "(9, 'Chris', 'Garcia', 'chris.garcia@company.com', '2019-07-08', 89000, 5, None)\n",
      "(10, 'Jessica', 'Lee', 'jessica.lee@company.com', '2021-12-03', 71000, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in cursor.fetchall():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d950a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sql_statement = \"SELECT * from employees;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e6cae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(sql=sql_statement,con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db84ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM employees WHERE first_name LIKE 'J%';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fe975",
   "metadata": {},
   "source": [
    "SELECT first_name as Fname FROM employees WHERE first_name='John';\n",
    "\n",
    "select Fname from (Select first_name as fname from  employees) where fname='John';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca79a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c608fed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "      <td>john.smith@company.com</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>95000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Lee</td>\n",
       "      <td>jessica.lee@company.com</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>71000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                    email   hire_date  \\\n",
       "0            1       John     Smith   john.smith@company.com  2020-01-15   \n",
       "6           10    Jessica       Lee  jessica.lee@company.com  2021-12-03   \n",
       "\n",
       "   salary  department_id  manager_id  \n",
       "0   95000              1         NaN  \n",
       "6   71000              1         1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['first_name'].str.startswith(\"J\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1bdf1c",
   "metadata": {},
   "source": [
    "SELECT first_name from employees;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915d7d8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0ff0606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "      <td>john.smith@company.com</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>95000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                   email   hire_date  \\\n",
       "0            1       John     Smith  john.smith@company.com  2020-01-15   \n",
       "\n",
       "   salary  department_id  manager_id  \n",
       "0   95000              1         NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['first_name']=='John']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3611db52",
   "metadata": {},
   "source": [
    "SELECT first_name, last_name, email FROM employees WHERE UPPER(first_name) = 'JOHN';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a875f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a755e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "      <td>john.smith@company.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name last_name                   email\n",
       "0       John     Smith  john.smith@company.com"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['first_name'].str.upper()=='JOHN'][['first_name','last_name','email']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c5678",
   "metadata": {},
   "source": [
    "\n",
    "SELECT first_name,hire_date FROM employees WHERE hire_date BETWEEN '2020-01-01' AND '2020-12-31' ORDER by hire_date DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57034b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf=df[(df['hire_date']>'2020-01-01') & (df['hire_date']<'2020-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a276e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emily</td>\n",
       "      <td>2020-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Anna</td>\n",
       "      <td>2020-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>2020-01-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name   hire_date\n",
       "3      Emily  2020-09-05\n",
       "7       Anna  2020-04-12\n",
       "0       John  2020-01-15"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpdf[[\"first_name\",\"hire_date\"]].sort_values(by='hire_date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f3e43011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "      <td>john.smith@company.com</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>95000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>sarah.johnson@company.com</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mike</td>\n",
       "      <td>Brown</td>\n",
       "      <td>mike.brown@company.com</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>72000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Davis</td>\n",
       "      <td>emily.davis@company.com</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>68000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>David</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>david.wilson@company.com</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>78000</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>lisa.anderson@company.com</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>85000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>tom.taylor@company.com</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>65000</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Anna</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>anna.martinez@company.com</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>chris.garcia@company.com</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>89000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Lee</td>\n",
       "      <td>jessica.lee@company.com</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>71000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                      email   hire_date  \\\n",
       "0            1       John     Smith     john.smith@company.com  2020-01-15   \n",
       "1            2      Sarah   Johnson  sarah.johnson@company.com  2019-03-22   \n",
       "2            3       Mike     Brown     mike.brown@company.com  2021-06-10   \n",
       "3            4      Emily     Davis    emily.davis@company.com  2020-09-05   \n",
       "4            5      David    Wilson   david.wilson@company.com  2018-11-30   \n",
       "5            6       Lisa  Anderson  lisa.anderson@company.com  2022-02-14   \n",
       "6            7        Tom    Taylor     tom.taylor@company.com  2021-08-20   \n",
       "7            8       Anna  Martinez  anna.martinez@company.com  2020-04-12   \n",
       "8            9      Chris    Garcia   chris.garcia@company.com  2019-07-08   \n",
       "9           10    Jessica       Lee    jessica.lee@company.com  2021-12-03   \n",
       "\n",
       "   salary  department_id  manager_id  \n",
       "0   95000              1         NaN  \n",
       "1   87000              1         1.0  \n",
       "2   72000              1         1.0  \n",
       "3   68000              2         NaN  \n",
       "4   78000              2         4.0  \n",
       "5   85000              3         NaN  \n",
       "6   65000              3         6.0  \n",
       "7   62000              4         NaN  \n",
       "8   89000              5         NaN  \n",
       "9   71000              1         1.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a35758a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>sarah.johnson@company.com</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mike</td>\n",
       "      <td>Brown</td>\n",
       "      <td>mike.brown@company.com</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>72000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>David</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>david.wilson@company.com</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>78000</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>tom.taylor@company.com</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>65000</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Lee</td>\n",
       "      <td>jessica.lee@company.com</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>71000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                      email   hire_date  \\\n",
       "1            2      Sarah   Johnson  sarah.johnson@company.com  2019-03-22   \n",
       "2            3       Mike     Brown     mike.brown@company.com  2021-06-10   \n",
       "4            5      David    Wilson   david.wilson@company.com  2018-11-30   \n",
       "6            7        Tom    Taylor     tom.taylor@company.com  2021-08-20   \n",
       "9           10    Jessica       Lee    jessica.lee@company.com  2021-12-03   \n",
       "\n",
       "   salary  department_id  manager_id  \n",
       "1   87000              1         1.0  \n",
       "2   72000              1         1.0  \n",
       "4   78000              2         4.0  \n",
       "6   65000              3         6.0  \n",
       "9   71000              1         1.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['manager_id'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0cf0d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_of_employee = int(df[(df['department_id']==1) & (df['salary']>=80000)]['employee_id'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "304f9b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2 employees having salary more than 80000 in department_id 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {count_of_employee} employees having salary more than 80000 in department_id 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0446d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['a','b']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a45c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=[df[df['manager_id'].isna()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d2700dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "      <td>john.smith@company.com</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>95000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Davis</td>\n",
       "      <td>emily.davis@company.com</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>68000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>lisa.anderson@company.com</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>85000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Anna</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>anna.martinez@company.com</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>chris.garcia@company.com</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>89000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                      email   hire_date  \\\n",
       "0            1       John     Smith     john.smith@company.com  2020-01-15   \n",
       "3            4      Emily     Davis    emily.davis@company.com  2020-09-05   \n",
       "5            6       Lisa  Anderson  lisa.anderson@company.com  2022-02-14   \n",
       "7            8       Anna  Martinez  anna.martinez@company.com  2020-04-12   \n",
       "8            9      Chris    Garcia   chris.garcia@company.com  2019-07-08   \n",
       "\n",
       "   salary  department_id  manager_id  \n",
       "0   95000              1         NaN  \n",
       "3   68000              2         NaN  \n",
       "5   85000              3         NaN  \n",
       "7   62000              4         NaN  \n",
       "8   89000              5         NaN  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2640eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((df['department_id']==1) | (df['department_id']==2)) & (df['salary']>70000) & (df['manager_id'].notna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d64aa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "l = [1,2,4,5,7]\n",
    "if 3 in l:\n",
    "    print('1 is present in List')\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "379005c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "      <td>john.smith@company.com</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>95000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>sarah.johnson@company.com</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mike</td>\n",
       "      <td>Brown</td>\n",
       "      <td>mike.brown@company.com</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>72000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Davis</td>\n",
       "      <td>emily.davis@company.com</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>68000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>David</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>david.wilson@company.com</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>78000</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>lisa.anderson@company.com</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>85000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>tom.taylor@company.com</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>65000</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Anna</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>anna.martinez@company.com</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>chris.garcia@company.com</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>89000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Lee</td>\n",
       "      <td>jessica.lee@company.com</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>71000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                      email   hire_date  \\\n",
       "0            1       John     Smith     john.smith@company.com  2020-01-15   \n",
       "1            2      Sarah   Johnson  sarah.johnson@company.com  2019-03-22   \n",
       "2            3       Mike     Brown     mike.brown@company.com  2021-06-10   \n",
       "3            4      Emily     Davis    emily.davis@company.com  2020-09-05   \n",
       "4            5      David    Wilson   david.wilson@company.com  2018-11-30   \n",
       "5            6       Lisa  Anderson  lisa.anderson@company.com  2022-02-14   \n",
       "6            7        Tom    Taylor     tom.taylor@company.com  2021-08-20   \n",
       "7            8       Anna  Martinez  anna.martinez@company.com  2020-04-12   \n",
       "8            9      Chris    Garcia   chris.garcia@company.com  2019-07-08   \n",
       "9           10    Jessica       Lee    jessica.lee@company.com  2021-12-03   \n",
       "\n",
       "   salary  department_id  manager_id  \n",
       "0   95000              1         NaN  \n",
       "1   87000              1         1.0  \n",
       "2   72000              1         1.0  \n",
       "3   68000              2         NaN  \n",
       "4   78000              2         4.0  \n",
       "5   85000              3         NaN  \n",
       "6   65000              3         6.0  \n",
       "7   62000              4         NaN  \n",
       "8   89000              5         NaN  \n",
       "9   71000              1         1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d13ae65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "8    False\n",
       "9     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbc080c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>sarah.johnson@company.com</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mike</td>\n",
       "      <td>Brown</td>\n",
       "      <td>mike.brown@company.com</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>72000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>David</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>david.wilson@company.com</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>78000</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Lee</td>\n",
       "      <td>jessica.lee@company.com</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>71000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                      email   hire_date  \\\n",
       "1            2      Sarah   Johnson  sarah.johnson@company.com  2019-03-22   \n",
       "2            3       Mike     Brown     mike.brown@company.com  2021-06-10   \n",
       "4            5      David    Wilson   david.wilson@company.com  2018-11-30   \n",
       "9           10    Jessica       Lee    jessica.lee@company.com  2021-12-03   \n",
       "\n",
       "   salary  department_id  manager_id  \n",
       "1   87000              1         1.0  \n",
       "2   72000              1         1.0  \n",
       "4   78000              2         4.0  \n",
       "9   71000              1         1.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a6bf520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2b05170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Davis</td>\n",
       "      <td>emily.davis@company.com</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>68000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>David</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>david.wilson@company.com</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>78000</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>lisa.anderson@company.com</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>85000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>tom.taylor@company.com</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>65000</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>chris.garcia@company.com</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>89000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                      email   hire_date  \\\n",
       "3            4      Emily     Davis    emily.davis@company.com  2020-09-05   \n",
       "4            5      David    Wilson   david.wilson@company.com  2018-11-30   \n",
       "5            6       Lisa  Anderson  lisa.anderson@company.com  2022-02-14   \n",
       "6            7        Tom    Taylor     tom.taylor@company.com  2021-08-20   \n",
       "8            9      Chris    Garcia   chris.garcia@company.com  2019-07-08   \n",
       "\n",
       "   salary  department_id  manager_id  \n",
       "3   68000              2         NaN  \n",
       "4   78000              2         4.0  \n",
       "5   85000              3         NaN  \n",
       "6   65000              3         6.0  \n",
       "8   89000              5         NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df['department_id'].isin([1,4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51a84681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataFrame in module pandas.core.frame object:\n",
      "\n",
      "class DataFrame(pandas.core.generic.NDFrame, pandas.core.arraylike.OpsMixin)\n",
      " |  DataFrame(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None) -> 'None'\n",
      " |\n",
      " |  Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
      " |\n",
      " |  Data structure also contains labeled axes (rows and columns).\n",
      " |  Arithmetic operations align on both row and column labels. Can be\n",
      " |  thought of as a dict-like container for Series objects. The primary\n",
      " |  pandas data structure.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
      " |      Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
      " |      data is a dict, column order follows insertion-order. If a dict contains Series\n",
      " |      which have an index defined, it is aligned by its index. This alignment also\n",
      " |      occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
      " |      Series/DataFrame inputs.\n",
      " |\n",
      " |      If data is a list of dicts, column order follows insertion-order.\n",
      " |\n",
      " |  index : Index or array-like\n",
      " |      Index to use for resulting frame. Will default to RangeIndex if\n",
      " |      no indexing information part of input data and no index provided.\n",
      " |  columns : Index or array-like\n",
      " |      Column labels to use for resulting frame when data does not have them,\n",
      " |      defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
      " |      will perform column selection instead.\n",
      " |  dtype : dtype, default None\n",
      " |      Data type to force. Only a single dtype is allowed. If None, infer.\n",
      " |  copy : bool or None, default None\n",
      " |      Copy data from inputs.\n",
      " |      For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
      " |      or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
      " |      If data is a dict containing one or more Series (possibly of different dtypes),\n",
      " |      ``copy=False`` will ensure that these inputs are not copied.\n",
      " |\n",
      " |      .. versionchanged:: 1.3.0\n",
      " |\n",
      " |  See Also\n",
      " |  --------\n",
      " |  DataFrame.from_records : Constructor from tuples, also record arrays.\n",
      " |  DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
      " |  read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |  read_table : Read general delimited file into DataFrame.\n",
      " |  read_clipboard : Read text from clipboard into DataFrame.\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  Please reference the :ref:`User Guide <basics.dataframe>` for more information.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |  Constructing DataFrame from a dictionary.\n",
      " |\n",
      " |  >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |  >>> df = pd.DataFrame(data=d)\n",
      " |  >>> df\n",
      " |     col1  col2\n",
      " |  0     1     3\n",
      " |  1     2     4\n",
      " |\n",
      " |  Notice that the inferred dtype is int64.\n",
      " |\n",
      " |  >>> df.dtypes\n",
      " |  col1    int64\n",
      " |  col2    int64\n",
      " |  dtype: object\n",
      " |\n",
      " |  To enforce a single dtype:\n",
      " |\n",
      " |  >>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
      " |  >>> df.dtypes\n",
      " |  col1    int8\n",
      " |  col2    int8\n",
      " |  dtype: object\n",
      " |\n",
      " |  Constructing DataFrame from a dictionary including Series:\n",
      " |\n",
      " |  >>> d = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])}\n",
      " |  >>> pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
      " |     col1  col2\n",
      " |  0     0   NaN\n",
      " |  1     1   NaN\n",
      " |  2     2   2.0\n",
      " |  3     3   3.0\n",
      " |\n",
      " |  Constructing DataFrame from numpy ndarray:\n",
      " |\n",
      " |  >>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
      " |  ...                    columns=['a', 'b', 'c'])\n",
      " |  >>> df2\n",
      " |     a  b  c\n",
      " |  0  1  2  3\n",
      " |  1  4  5  6\n",
      " |  2  7  8  9\n",
      " |\n",
      " |  Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
      " |\n",
      " |  >>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
      " |  ...                 dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\n",
      " |  >>> df3 = pd.DataFrame(data, columns=['c', 'a'])\n",
      " |  ...\n",
      " |  >>> df3\n",
      " |     c  a\n",
      " |  0  3  1\n",
      " |  1  6  4\n",
      " |  2  9  7\n",
      " |\n",
      " |  Constructing DataFrame from dataclass:\n",
      " |\n",
      " |  >>> from dataclasses import make_dataclass\n",
      " |  >>> Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\n",
      " |  >>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
      " |     x  y\n",
      " |  0  0  0\n",
      " |  1  0  3\n",
      " |  2  2  3\n",
      " |\n",
      " |  Constructing DataFrame from Series/DataFrame:\n",
      " |\n",
      " |  >>> ser = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\n",
      " |  >>> df = pd.DataFrame(data=ser, index=[\"a\", \"c\"])\n",
      " |  >>> df\n",
      " |     0\n",
      " |  a  1\n",
      " |  c  3\n",
      " |\n",
      " |  >>> df1 = pd.DataFrame([1, 2, 3], index=[\"a\", \"b\", \"c\"], columns=[\"x\"])\n",
      " |  >>> df2 = pd.DataFrame(data=df1, index=[\"a\", \"c\"])\n",
      " |  >>> df2\n",
      " |     x\n",
      " |  a  1\n",
      " |  c  3\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      DataFrame\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.indexing.IndexingMixin\n",
      " |      pandas.core.arraylike.OpsMixin\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __arrow_c_stream__(self, requested_schema=None)\n",
      " |      Export the pandas DataFrame as an Arrow C stream PyCapsule.\n",
      " |\n",
      " |      This relies on pyarrow to convert the pandas DataFrame to the Arrow\n",
      " |      format (and follows the default behaviour of ``pyarrow.Table.from_pandas``\n",
      " |      in its handling of the index, i.e. store the index as a column except\n",
      " |      for RangeIndex).\n",
      " |      This conversion is not necessarily zero-copy.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      requested_schema : PyCapsule, default None\n",
      " |          The schema to which the dataframe should be casted, passed as a\n",
      " |          PyCapsule containing a C ArrowSchema representation of the\n",
      " |          requested schema.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      PyCapsule\n",
      " |\n",
      " |  __dataframe__(self, nan_as_null: 'bool' = False, allow_copy: 'bool' = True) -> 'DataFrameXchg'\n",
      " |      Return the dataframe interchange object implementing the interchange protocol.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      nan_as_null : bool, default False\n",
      " |          `nan_as_null` is DEPRECATED and has no effect. Please avoid using\n",
      " |          it; it will be removed in a future release.\n",
      " |      allow_copy : bool, default True\n",
      " |          Whether to allow memory copying when exporting. If set to False\n",
      " |          it would cause non-zero-copy exports to fail.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame interchange object\n",
      " |          The object which consuming library can use to ingress the dataframe.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Details on the interchange protocol:\n",
      " |      https://data-apis.org/dataframe-protocol/latest/index.html\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df_not_necessarily_pandas = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
      " |      >>> interchange_object = df_not_necessarily_pandas.__dataframe__()\n",
      " |      >>> interchange_object.column_names()\n",
      " |      Index(['A', 'B'], dtype='object')\n",
      " |      >>> df_pandas = (pd.api.interchange.from_dataframe\n",
      " |      ...              (interchange_object.select_columns_by_name(['A'])))\n",
      " |      >>> df_pandas\n",
      " |           A\n",
      " |      0    1\n",
      " |      1    2\n",
      " |\n",
      " |      These methods (``column_names``, ``select_columns_by_name``) should work\n",
      " |      for any dataframe library which implements the interchange protocol.\n",
      " |\n",
      " |  __dataframe_consortium_standard__(self, *, api_version: 'str | None' = None) -> 'Any'\n",
      " |      Provide entry point to the Consortium DataFrame Standard API.\n",
      " |\n",
      " |      This is developed and maintained outside of pandas.\n",
      " |      Please report any issues to https://github.com/data-apis/dataframe-api-compat.\n",
      " |\n",
      " |  __divmod__(self, other) -> 'tuple[DataFrame, DataFrame]'\n",
      " |\n",
      " |  __getitem__(self, key)\n",
      " |\n",
      " |  __init__(self, data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None) -> 'None'\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __len__(self) -> 'int'\n",
      " |      Returns length of info axis, but here we use the index.\n",
      " |\n",
      " |  __matmul__(self, other: 'AnyArrayLike | DataFrame') -> 'DataFrame | Series'\n",
      " |      Matrix multiplication using binary `@` operator.\n",
      " |\n",
      " |  __rdivmod__(self, other) -> 'tuple[DataFrame, DataFrame]'\n",
      " |\n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return a string representation for a particular DataFrame.\n",
      " |\n",
      " |  __rmatmul__(self, other) -> 'DataFrame'\n",
      " |      Matrix multiplication using binary `@` operator.\n",
      " |\n",
      " |  __setitem__(self, key, value) -> 'None'\n",
      " |\n",
      " |  add(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Addition of dataframe and other, element-wise (binary operator `add`).\n",
      " |\n",
      " |      Equivalent to ``dataframe + other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `radd`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  agg = aggregate(self, func=None, axis: 'Axis' = 0, *args, **kwargs)\n",
      " |\n",
      " |  aggregate(self, func=None, axis: 'Axis' = 0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply.\n",
      " |\n",
      " |          Accepted combinations are:\n",
      " |\n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |              If 0 or 'index': apply function to each column.\n",
      " |              If 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series or DataFrame\n",
      " |\n",
      " |          The return can be:\n",
      " |\n",
      " |          * scalar : when Series.agg is called with single function\n",
      " |          * Series : when DataFrame.agg is called with a single function\n",
      " |          * DataFrame : when DataFrame.agg is called with several functions\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Perform any type of operations.\n",
      " |      DataFrame.transform : Perform transformation type operations.\n",
      " |      pandas.DataFrame.groupby : Perform operations over groups.\n",
      " |      pandas.DataFrame.resample : Perform operations over resampled bins.\n",
      " |      pandas.DataFrame.rolling : Perform operations over rolling window.\n",
      " |      pandas.DataFrame.expanding : Perform operations over expanding window.\n",
      " |      pandas.core.window.ewm.ExponentialMovingWindow : Perform operation over exponential\n",
      " |          weighted window.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The aggregation operations are always performed over an axis, either the\n",
      " |      index (default) or the column axis. This behavior is different from\n",
      " |      `numpy` aggregation functions (`mean`, `median`, `prod`, `sum`, `std`,\n",
      " |      `var`), where the default is to compute the aggregation of the flattened\n",
      " |      array, e.g., ``numpy.mean(arr_2d)`` as opposed to\n",
      " |      ``numpy.mean(arr_2d, axis=0)``.\n",
      " |\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |\n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2, 3],\n",
      " |      ...                    [4, 5, 6],\n",
      " |      ...                    [7, 8, 9],\n",
      " |      ...                    [np.nan, np.nan, np.nan]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |\n",
      " |      Aggregate these functions over the rows.\n",
      " |\n",
      " |      >>> df.agg(['sum', 'min'])\n",
      " |              A     B     C\n",
      " |      sum  12.0  15.0  18.0\n",
      " |      min   1.0   2.0   3.0\n",
      " |\n",
      " |      Different aggregations per column.\n",
      " |\n",
      " |      >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
      " |              A    B\n",
      " |      sum  12.0  NaN\n",
      " |      min   1.0  2.0\n",
      " |      max   NaN  8.0\n",
      " |\n",
      " |      Aggregate different functions over the columns and rename the index of the resulting\n",
      " |      DataFrame.\n",
      " |\n",
      " |      >>> df.agg(x=('A', 'max'), y=('B', 'min'), z=('C', 'mean'))\n",
      " |           A    B    C\n",
      " |      x  7.0  NaN  NaN\n",
      " |      y  NaN  2.0  NaN\n",
      " |      z  NaN  NaN  6.0\n",
      " |\n",
      " |      Aggregate over the columns.\n",
      " |\n",
      " |      >>> df.agg(\"mean\", axis=\"columns\")\n",
      " |      0    2.0\n",
      " |      1    5.0\n",
      " |      2    8.0\n",
      " |      3    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  all(self, axis: 'Axis | None' = 0, bool_only: 'bool' = False, skipna: 'bool' = True, **kwargs) -> 'Series | bool'\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |\n",
      " |      Returns True unless there at least one element within a series or\n",
      " |      along a Dataframe axis that is False or equivalent (e.g. zero or\n",
      " |      empty).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced. For `Series` this parameter\n",
      " |          is unused and defaults to 0.\n",
      " |\n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |\n",
      " |      bool_only : bool, default False\n",
      " |          Include only boolean columns. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be True, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If level is specified, then, DataFrame is returned; otherwise, Series\n",
      " |          is returned.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.all : Return True if all elements are True.\n",
      " |      DataFrame.any : Return True if one (or more) elements are True.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      >>> pd.Series([], dtype=\"float64\").all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all(skipna=False)\n",
      " |      True\n",
      " |\n",
      " |      **DataFrames**\n",
      " |\n",
      " |      Create a dataframe from a dictionary.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |\n",
      " |      Default behaviour checks if values in each column all return True.\n",
      " |\n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      Specify ``axis='columns'`` to check if values in each row all return True.\n",
      " |\n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |\n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |\n",
      " |  any(self, *, axis: 'Axis | None' = 0, bool_only: 'bool' = False, skipna: 'bool' = True, **kwargs) -> 'Series | bool'\n",
      " |      Return whether any element is True, potentially over an axis.\n",
      " |\n",
      " |      Returns False unless there is at least one element within a series or\n",
      " |      along a Dataframe axis that is True or equivalent (e.g. non-zero or\n",
      " |      non-empty).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced. For `Series` this parameter\n",
      " |          is unused and defaults to 0.\n",
      " |\n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |\n",
      " |      bool_only : bool, default False\n",
      " |          Include only boolean columns. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be False, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If level is specified, then, DataFrame is returned; otherwise, Series\n",
      " |          is returned.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.any : Numpy version of this method.\n",
      " |      Series.any : Return whether any element is True.\n",
      " |      Series.all : Return whether all elements are True.\n",
      " |      DataFrame.any : Return whether any element is True over requested axis.\n",
      " |      DataFrame.all : Return whether all elements are True over requested axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |\n",
      " |      >>> pd.Series([False, False]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      >>> pd.Series([], dtype=\"float64\").any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any(skipna=False)\n",
      " |      True\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |\n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      Aggregating over the columns.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |\n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |\n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |\n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |\n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |\n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |\n",
      " |  apply(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type: \"Literal['expand', 'reduce', 'broadcast'] | None\" = None, args=(), by_row: \"Literal[False, 'compat']\" = 'compat', engine: \"Literal['python', 'numba']\" = 'python', engine_kwargs: 'dict[str, bool] | None' = None, **kwargs)\n",
      " |      Apply a function along an axis of the DataFrame.\n",
      " |\n",
      " |      Objects passed to the function are Series objects whose index is\n",
      " |      either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
      " |      (``axis=1``). By default (``result_type=None``), the final return type\n",
      " |      is inferred from the return type of the applied function. Otherwise,\n",
      " |      it depends on the `result_type` argument.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to each column or row.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the function is applied:\n",
      " |\n",
      " |          * 0 or 'index': apply function to each column.\n",
      " |          * 1 or 'columns': apply function to each row.\n",
      " |\n",
      " |      raw : bool, default False\n",
      " |          Determines if row or column is passed as a Series or ndarray object:\n",
      " |\n",
      " |          * ``False`` : passes each row or column as a Series to the\n",
      " |            function.\n",
      " |          * ``True`` : the passed function will receive ndarray objects\n",
      " |            instead.\n",
      " |            If you are just applying a NumPy reduction function this will\n",
      " |            achieve much better performance.\n",
      " |\n",
      " |      result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
      " |          These only act when ``axis=1`` (columns):\n",
      " |\n",
      " |          * 'expand' : list-like results will be turned into columns.\n",
      " |          * 'reduce' : returns a Series if possible rather than expanding\n",
      " |            list-like results. This is the opposite of 'expand'.\n",
      " |          * 'broadcast' : results will be broadcast to the original shape\n",
      " |            of the DataFrame, the original index and columns will be\n",
      " |            retained.\n",
      " |\n",
      " |          The default behaviour (None) depends on the return value of the\n",
      " |          applied function: list-like results will be returned as a Series\n",
      " |          of those. However if the apply function returns a Series these\n",
      " |          are expanded to columns.\n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to `func` in addition to the\n",
      " |          array/series.\n",
      " |      by_row : False or \"compat\", default \"compat\"\n",
      " |          Only has an effect when ``func`` is a listlike or dictlike of funcs\n",
      " |          and the func isn't a string.\n",
      " |          If \"compat\", will if possible first translate the func into pandas\n",
      " |          methods (e.g. ``Series().apply(np.sum)`` will be translated to\n",
      " |          ``Series().sum()``). If that doesn't work, will try call to apply again with\n",
      " |          ``by_row=True`` and if that fails, will call apply again with\n",
      " |          ``by_row=False`` (backward compatible).\n",
      " |          If False, the funcs will be passed the whole Series at once.\n",
      " |\n",
      " |          .. versionadded:: 2.1.0\n",
      " |\n",
      " |      engine : {'python', 'numba'}, default 'python'\n",
      " |          Choose between the python (default) engine or the numba engine in apply.\n",
      " |\n",
      " |          The numba engine will attempt to JIT compile the passed function,\n",
      " |          which may result in speedups for large DataFrames.\n",
      " |          It also supports the following engine_kwargs :\n",
      " |\n",
      " |          - nopython (compile the function in nopython mode)\n",
      " |          - nogil (release the GIL inside the JIT compiled function)\n",
      " |          - parallel (try to apply the function in parallel over the DataFrame)\n",
      " |\n",
      " |            Note: Due to limitations within numba/how pandas interfaces with numba,\n",
      " |            you should only use this if raw=True\n",
      " |\n",
      " |          Note: The numba compiler only supports a subset of\n",
      " |          valid Python/numpy operations.\n",
      " |\n",
      " |          Please read more about the `supported python features\n",
      " |          <https://numba.pydata.org/numba-doc/dev/reference/pysupported.html>`_\n",
      " |          and `supported numpy features\n",
      " |          <https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html>`_\n",
      " |          in numba to learn what you can or cannot use in the passed function.\n",
      " |\n",
      " |          .. versionadded:: 2.2.0\n",
      " |\n",
      " |      engine_kwargs : dict\n",
      " |          Pass keyword arguments to the engine.\n",
      " |          This is currently only used by the numba engine,\n",
      " |          see the documentation for the engine argument for more information.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Result of applying ``func`` along the given axis of the\n",
      " |          DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.map: For elementwise operations.\n",
      " |      DataFrame.aggregate: Only perform aggregating type operations.\n",
      " |      DataFrame.transform: Only perform transforming type operations.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  4  9\n",
      " |      1  4  9\n",
      " |      2  4  9\n",
      " |\n",
      " |      Using a numpy universal function (in this case the same as\n",
      " |      ``np.sqrt(df)``):\n",
      " |\n",
      " |      >>> df.apply(np.sqrt)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  2.0  3.0\n",
      " |      2  2.0  3.0\n",
      " |\n",
      " |      Using a reducing function on either axis\n",
      " |\n",
      " |      >>> df.apply(np.sum, axis=0)\n",
      " |      A    12\n",
      " |      B    27\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df.apply(np.sum, axis=1)\n",
      " |      0    13\n",
      " |      1    13\n",
      " |      2    13\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Returning a list-like will result in a Series\n",
      " |\n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1)\n",
      " |      0    [1, 2]\n",
      " |      1    [1, 2]\n",
      " |      2    [1, 2]\n",
      " |      dtype: object\n",
      " |\n",
      " |      Passing ``result_type='expand'`` will expand list-like results\n",
      " |      to columns of a Dataframe\n",
      " |\n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
      " |         0  1\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |\n",
      " |      Returning a Series inside the function is similar to passing\n",
      " |      ``result_type='expand'``. The resulting column names\n",
      " |      will be the Series index.\n",
      " |\n",
      " |      >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
      " |         foo  bar\n",
      " |      0    1    2\n",
      " |      1    1    2\n",
      " |      2    1    2\n",
      " |\n",
      " |      Passing ``result_type='broadcast'`` will ensure the same shape\n",
      " |      result, whether list-like or scalar is returned by the function,\n",
      " |      and broadcast it along the axis. The resulting column names will\n",
      " |      be the originals.\n",
      " |\n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |\n",
      " |  applymap(self, func: 'PythonFuncType', na_action: 'NaAction | None' = None, **kwargs) -> 'DataFrame'\n",
      " |      Apply a function to a Dataframe elementwise.\n",
      " |\n",
      " |      .. deprecated:: 2.1.0\n",
      " |\n",
      " |         DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      " |\n",
      " |      This method applies a function that accepts and returns a scalar\n",
      " |      to every element of a DataFrame.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          Python function, returns a single value from a single value.\n",
      " |      na_action : {None, 'ignore'}, default None\n",
      " |          If 'ignore', propagate NaN values, without passing them to func.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Transformed DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.map : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.replace: Replace values given in `to_replace` with `value`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
      " |      >>> df\n",
      " |             0      1\n",
      " |      0  1.000  2.120\n",
      " |      1  3.356  4.567\n",
      " |\n",
      " |      >>> df.map(lambda x: len(str(x)))\n",
      " |         0  1\n",
      " |      0  3  4\n",
      " |      1  5  5\n",
      " |\n",
      " |  assign(self, **kwargs) -> 'DataFrame'\n",
      " |      Assign new columns to a DataFrame.\n",
      " |\n",
      " |      Returns a new object with all original columns in addition to new ones.\n",
      " |      Existing columns that are re-assigned will be overwritten.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **kwargs : dict of {str: callable or Series}\n",
      " |          The column names are keywords. If the values are\n",
      " |          callable, they are computed on the DataFrame and\n",
      " |          assigned to the new columns. The callable must not\n",
      " |          change input DataFrame (though pandas doesn't check it).\n",
      " |          If the values are not callable, (e.g. a Series, scalar, or array),\n",
      " |          they are simply assigned.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A new DataFrame with the new columns in addition to\n",
      " |          all the existing columns.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Assigning multiple columns within the same ``assign`` is possible.\n",
      " |      Later items in '\\*\\*kwargs' may refer to newly created or modified\n",
      " |      columns in 'df'; items are computed and assigned into 'df' in order.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'temp_c': [17.0, 25.0]},\n",
      " |      ...                   index=['Portland', 'Berkeley'])\n",
      " |      >>> df\n",
      " |                temp_c\n",
      " |      Portland    17.0\n",
      " |      Berkeley    25.0\n",
      " |\n",
      " |      Where the value is a callable, evaluated on `df`:\n",
      " |\n",
      " |      >>> df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)\n",
      " |                temp_c  temp_f\n",
      " |      Portland    17.0    62.6\n",
      " |      Berkeley    25.0    77.0\n",
      " |\n",
      " |      Alternatively, the same behavior can be achieved by directly\n",
      " |      referencing an existing Series or sequence:\n",
      " |\n",
      " |      >>> df.assign(temp_f=df['temp_c'] * 9 / 5 + 32)\n",
      " |                temp_c  temp_f\n",
      " |      Portland    17.0    62.6\n",
      " |      Berkeley    25.0    77.0\n",
      " |\n",
      " |      You can create multiple columns within the same assign where one\n",
      " |      of the columns depends on another one defined within the same assign:\n",
      " |\n",
      " |      >>> df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,\n",
      " |      ...           temp_k=lambda x: (x['temp_f'] + 459.67) * 5 / 9)\n",
      " |                temp_c  temp_f  temp_k\n",
      " |      Portland    17.0    62.6  290.15\n",
      " |      Berkeley    25.0    77.0  298.15\n",
      " |\n",
      " |  boxplot = boxplot_frame(self: 'DataFrame', column=None, by=None, ax=None, fontsize: 'int | None' = None, rot: 'int' = 0, grid: 'bool' = True, figsize: 'tuple[float, float] | None' = None, layout=None, return_type=None, backend=None, **kwargs)\n",
      " |      Make a box plot from DataFrame columns.\n",
      " |\n",
      " |      Make a box-and-whisker plot from DataFrame columns, optionally grouped\n",
      " |      by some other columns. A box plot is a method for graphically depicting\n",
      " |      groups of numerical data through their quartiles.\n",
      " |      The box extends from the Q1 to Q3 quartile values of the data,\n",
      " |      with a line at the median (Q2). The whiskers extend from the edges\n",
      " |      of box to show the range of the data. By default, they extend no more than\n",
      " |      `1.5 * IQR (IQR = Q3 - Q1)` from the edges of the box, ending at the farthest\n",
      " |      data point within that interval. Outliers are plotted as separate dots.\n",
      " |\n",
      " |      For further details see\n",
      " |      Wikipedia's entry for `boxplot <https://en.wikipedia.org/wiki/Box_plot>`_.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : str or list of str, optional\n",
      " |          Column name or list of names, or vector.\n",
      " |          Can be any valid input to :meth:`pandas.DataFrame.groupby`.\n",
      " |      by : str or array-like, optional\n",
      " |          Column in the DataFrame to :meth:`pandas.DataFrame.groupby`.\n",
      " |          One box-plot will be done per value of columns in `by`.\n",
      " |      ax : object of class matplotlib.axes.Axes, optional\n",
      " |          The matplotlib axes to be used by boxplot.\n",
      " |      fontsize : float or str\n",
      " |          Tick label font size in points or as a string (e.g., `large`).\n",
      " |      rot : float, default 0\n",
      " |          The rotation angle of labels (in degrees)\n",
      " |          with respect to the screen coordinate system.\n",
      " |      grid : bool, default True\n",
      " |          Setting this to True will show the grid.\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |          The size of the figure to create in matplotlib.\n",
      " |      layout : tuple (rows, columns), optional\n",
      " |          For example, (3, 5) will display the subplots\n",
      " |          using 3 rows and 5 columns, starting from the top-left.\n",
      " |      return_type : {'axes', 'dict', 'both'} or None, default 'axes'\n",
      " |          The kind of object to return. The default is ``axes``.\n",
      " |\n",
      " |          * 'axes' returns the matplotlib axes the boxplot is drawn on.\n",
      " |          * 'dict' returns a dictionary whose values are the matplotlib\n",
      " |            Lines of the boxplot.\n",
      " |          * 'both' returns a namedtuple with the axes and dict.\n",
      " |          * when grouping with ``by``, a Series mapping columns to\n",
      " |            ``return_type`` is returned.\n",
      " |\n",
      " |            If ``return_type`` is `None`, a NumPy array\n",
      " |            of axes with the same shape as ``layout`` is returned.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |\n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :func:`matplotlib.pyplot.boxplot`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      result\n",
      " |          See Notes.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.plot.hist: Make a histogram.\n",
      " |      matplotlib.pyplot.boxplot : Matplotlib equivalent plot.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The return type depends on the `return_type` parameter:\n",
      " |\n",
      " |      * 'axes' : object of class matplotlib.axes.Axes\n",
      " |      * 'dict' : dict of matplotlib.lines.Line2D objects\n",
      " |      * 'both' : a namedtuple with structure (ax, lines)\n",
      " |\n",
      " |      For data grouped with ``by``, return a Series of the above or a numpy\n",
      " |      array:\n",
      " |\n",
      " |      * :class:`~pandas.Series`\n",
      " |      * :class:`~numpy.array` (for ``return_type = None``)\n",
      " |\n",
      " |      Use ``return_type='dict'`` when you want to tweak the appearance\n",
      " |      of the lines after plotting. In this case a dict containing the Lines\n",
      " |      making up the boxes, caps, fliers, medians, and whiskers is returned.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      Boxplots can be created for every column in the dataframe\n",
      " |      by ``df.boxplot()`` or indicating the columns to be used:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> np.random.seed(1234)\n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 4),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])  # doctest: +SKIP\n",
      " |\n",
      " |      Boxplots of variables distributions grouped by the values of a third\n",
      " |      variable can be created using the option ``by``. For instance:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 2),\n",
      " |          ...                   columns=['Col1', 'Col2'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> boxplot = df.boxplot(by='X')\n",
      " |\n",
      " |      A list of strings (i.e. ``['X', 'Y']``) can be passed to boxplot\n",
      " |      in order to group the data by combination of the variables in the x-axis:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 3),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',\n",
      " |          ...                      'B', 'A', 'B', 'A', 'B'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])\n",
      " |\n",
      " |      The layout of boxplot can be adjusted giving a tuple to ``layout``:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      layout=(2, 1))\n",
      " |\n",
      " |      Additional formatting can be done to the boxplot, like suppressing the grid\n",
      " |      (``grid=False``), rotating the labels in the x-axis (i.e. ``rot=45``)\n",
      " |      or changing the fontsize (i.e. ``fontsize=15``):\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)  # doctest: +SKIP\n",
      " |\n",
      " |      The parameter ``return_type`` can be used to select the type of element\n",
      " |      returned by `boxplot`.  When ``return_type='axes'`` is selected,\n",
      " |      the matplotlib axes on which the boxplot is drawn are returned:\n",
      " |\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'matplotlib.axes._axes.Axes'>\n",
      " |\n",
      " |      When grouping with ``by``, a Series mapping columns to ``return_type``\n",
      " |      is returned:\n",
      " |\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'pandas.core.series.Series'>\n",
      " |\n",
      " |      If ``return_type`` is `None`, a NumPy array of axes with the same shape\n",
      " |      as ``layout`` is returned:\n",
      " |\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type=None)\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'numpy.ndarray'>\n",
      " |\n",
      " |  combine(self, other: 'DataFrame', func: 'Callable[[Series, Series], Series | Hashable]', fill_value=None, overwrite: 'bool' = True) -> 'DataFrame'\n",
      " |      Perform column-wise combine with another DataFrame.\n",
      " |\n",
      " |      Combines a DataFrame with `other` DataFrame using `func`\n",
      " |      to element-wise combine columns. The row and column indexes of the\n",
      " |      resulting DataFrame will be the union of the two.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          The DataFrame to merge column-wise.\n",
      " |      func : function\n",
      " |          Function that takes two series as inputs and return a Series or a\n",
      " |          scalar. Used to merge the two dataframes column by columns.\n",
      " |      fill_value : scalar value, default None\n",
      " |          The value to fill NaNs with prior to passing any column to the\n",
      " |          merge func.\n",
      " |      overwrite : bool, default True\n",
      " |          If True, columns in `self` that do not exist in `other` will be\n",
      " |          overwritten with NaNs.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Combination of the provided DataFrames.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine_first : Combine two DataFrame objects and default to\n",
      " |          non-null values in frame calling the method.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Combine using a simple function that chooses the smaller column.\n",
      " |\n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n",
      " |      >>> df1.combine(df2, take_smaller)\n",
      " |         A  B\n",
      " |      0  0  3\n",
      " |      1  0  3\n",
      " |\n",
      " |      Example using a true element-wise combine function.\n",
      " |\n",
      " |      >>> df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, np.minimum)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  0  3\n",
      " |\n",
      " |      Using `fill_value` fills Nones prior to passing the column to the\n",
      " |      merge function.\n",
      " |\n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      " |         A    B\n",
      " |      0  0 -5.0\n",
      " |      1  0  4.0\n",
      " |\n",
      " |      However, if the same element in both dataframes is None, that None\n",
      " |      is preserved\n",
      " |\n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})\n",
      " |      >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      " |          A    B\n",
      " |      0  0 -5.0\n",
      " |      1  0  3.0\n",
      " |\n",
      " |      Example that demonstrates the use of `overwrite` and behavior when\n",
      " |      the axis differ between the dataframes.\n",
      " |\n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])\n",
      " |      >>> df1.combine(df2, take_smaller)\n",
      " |           A    B     C\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  3.0 -10.0\n",
      " |      2  NaN  3.0   1.0\n",
      " |\n",
      " |      >>> df1.combine(df2, take_smaller, overwrite=False)\n",
      " |           A    B     C\n",
      " |      0  0.0  NaN   NaN\n",
      " |      1  0.0  3.0 -10.0\n",
      " |      2  NaN  3.0   1.0\n",
      " |\n",
      " |      Demonstrating the preference of the passed in dataframe.\n",
      " |\n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])\n",
      " |      >>> df2.combine(df1, take_smaller)\n",
      " |         A    B   C\n",
      " |      0  0.0  NaN NaN\n",
      " |      1  0.0  3.0 NaN\n",
      " |      2  NaN  3.0 NaN\n",
      " |\n",
      " |      >>> df2.combine(df1, take_smaller, overwrite=False)\n",
      " |           A    B   C\n",
      " |      0  0.0  NaN NaN\n",
      " |      1  0.0  3.0 1.0\n",
      " |      2  NaN  3.0 1.0\n",
      " |\n",
      " |  combine_first(self, other: 'DataFrame') -> 'DataFrame'\n",
      " |      Update null elements with value in the same location in `other`.\n",
      " |\n",
      " |      Combine two DataFrame objects by filling null values in one DataFrame\n",
      " |      with non-null values from other DataFrame. The row and column indexes\n",
      " |      of the resulting DataFrame will be the union of the two. The resulting\n",
      " |      dataframe contains the 'first' dataframe values and overrides the\n",
      " |      second one values where both first.loc[index, col] and\n",
      " |      second.loc[index, col] are not missing values, upon calling\n",
      " |      first.combine_first(second).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          Provided DataFrame to use to fill null values.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The result of combining the provided DataFrame with the other object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine : Perform series-wise operation on two DataFrames\n",
      " |          using a given function.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine_first(df2)\n",
      " |           A    B\n",
      " |      0  1.0  3.0\n",
      " |      1  0.0  4.0\n",
      " |\n",
      " |      Null values still persist if the location of that null value\n",
      " |      does not exist in `other`\n",
      " |\n",
      " |      >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})\n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])\n",
      " |      >>> df1.combine_first(df2)\n",
      " |           A    B    C\n",
      " |      0  NaN  4.0  NaN\n",
      " |      1  0.0  3.0  1.0\n",
      " |      2  NaN  3.0  1.0\n",
      " |\n",
      " |  compare(self, other: 'DataFrame', align_axis: 'Axis' = 1, keep_shape: 'bool' = False, keep_equal: 'bool' = False, result_names: 'Suffixes' = ('self', 'other')) -> 'DataFrame'\n",
      " |      Compare to another DataFrame and show the differences.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          Object to compare with.\n",
      " |\n",
      " |      align_axis : {0 or 'index', 1 or 'columns'}, default 1\n",
      " |          Determine which axis to align the comparison on.\n",
      " |\n",
      " |          * 0, or 'index' : Resulting differences are stacked vertically\n",
      " |              with rows drawn alternately from self and other.\n",
      " |          * 1, or 'columns' : Resulting differences are aligned horizontally\n",
      " |              with columns drawn alternately from self and other.\n",
      " |\n",
      " |      keep_shape : bool, default False\n",
      " |          If true, all rows and columns are kept.\n",
      " |          Otherwise, only the ones with different values are kept.\n",
      " |\n",
      " |      keep_equal : bool, default False\n",
      " |          If true, the result keeps values that are equal.\n",
      " |          Otherwise, equal values are shown as NaNs.\n",
      " |\n",
      " |      result_names : tuple, default ('self', 'other')\n",
      " |          Set the dataframes names in the comparison.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame that shows the differences stacked side by side.\n",
      " |\n",
      " |          The resulting index will be a MultiIndex with 'self' and 'other'\n",
      " |          stacked alternately at the inner level.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the two DataFrames don't have identical labels or shape.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.compare : Compare with another Series and show differences.\n",
      " |      DataFrame.equals : Test whether two objects contain the same elements.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Matching NaNs will not appear as a difference.\n",
      " |\n",
      " |      Can only compare identically-labeled\n",
      " |      (i.e. same shape, identical row and column labels) DataFrames\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"col1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\n",
      " |      ...         \"col2\": [1.0, 2.0, 3.0, np.nan, 5.0],\n",
      " |      ...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0]\n",
      " |      ...     },\n",
      " |      ...     columns=[\"col1\", \"col2\", \"col3\"],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |        col1  col2  col3\n",
      " |      0    a   1.0   1.0\n",
      " |      1    a   2.0   2.0\n",
      " |      2    b   3.0   3.0\n",
      " |      3    b   NaN   4.0\n",
      " |      4    a   5.0   5.0\n",
      " |\n",
      " |      >>> df2 = df.copy()\n",
      " |      >>> df2.loc[0, 'col1'] = 'c'\n",
      " |      >>> df2.loc[2, 'col3'] = 4.0\n",
      " |      >>> df2\n",
      " |        col1  col2  col3\n",
      " |      0    c   1.0   1.0\n",
      " |      1    a   2.0   2.0\n",
      " |      2    b   3.0   4.0\n",
      " |      3    b   NaN   4.0\n",
      " |      4    a   5.0   5.0\n",
      " |\n",
      " |      Align the differences on columns\n",
      " |\n",
      " |      >>> df.compare(df2)\n",
      " |        col1       col3\n",
      " |        self other self other\n",
      " |      0    a     c  NaN   NaN\n",
      " |      2  NaN   NaN  3.0   4.0\n",
      " |\n",
      " |      Assign result_names\n",
      " |\n",
      " |      >>> df.compare(df2, result_names=(\"left\", \"right\"))\n",
      " |        col1       col3\n",
      " |        left right left right\n",
      " |      0    a     c  NaN   NaN\n",
      " |      2  NaN   NaN  3.0   4.0\n",
      " |\n",
      " |      Stack the differences on rows\n",
      " |\n",
      " |      >>> df.compare(df2, align_axis=0)\n",
      " |              col1  col3\n",
      " |      0 self     a   NaN\n",
      " |        other    c   NaN\n",
      " |      2 self   NaN   3.0\n",
      " |        other  NaN   4.0\n",
      " |\n",
      " |      Keep the equal values\n",
      " |\n",
      " |      >>> df.compare(df2, keep_equal=True)\n",
      " |        col1       col3\n",
      " |        self other self other\n",
      " |      0    a     c  1.0   1.0\n",
      " |      2    b     b  3.0   4.0\n",
      " |\n",
      " |      Keep all original rows and columns\n",
      " |\n",
      " |      >>> df.compare(df2, keep_shape=True)\n",
      " |        col1       col2       col3\n",
      " |        self other self other self other\n",
      " |      0    a     c  NaN   NaN  NaN   NaN\n",
      " |      1  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      2  NaN   NaN  NaN   NaN  3.0   4.0\n",
      " |      3  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      4  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |\n",
      " |      Keep all original rows and columns and also all original values\n",
      " |\n",
      " |      >>> df.compare(df2, keep_shape=True, keep_equal=True)\n",
      " |        col1       col2       col3\n",
      " |        self other self other self other\n",
      " |      0    a     c  1.0   1.0  1.0   1.0\n",
      " |      1    a     a  2.0   2.0  2.0   2.0\n",
      " |      2    b     b  3.0   3.0  3.0   4.0\n",
      " |      3    b     b  NaN   NaN  4.0   4.0\n",
      " |      4    a     a  5.0   5.0  5.0   5.0\n",
      " |\n",
      " |  corr(self, method: 'CorrelationMethod' = 'pearson', min_periods: 'int' = 1, numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float. Note that the returned matrix from corr\n",
      " |              will have 1 along the diagonals and will be symmetric\n",
      " |              regardless of the callable's behavior.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for Pearson\n",
      " |          and Spearman correlation.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Correlation matrix.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corrwith : Compute pairwise correlation with another\n",
      " |          DataFrame or Series.\n",
      " |      Series.corr : Compute the correlation between two Series.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Pearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.\n",
      " |\n",
      " |      * `Pearson correlation coefficient <https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>`_\n",
      " |      * `Kendall rank correlation coefficient <https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient>`_\n",
      " |      * `Spearman's rank correlation coefficient <https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient>`_\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> def histogram_intersection(a, b):\n",
      " |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      " |      ...     return v\n",
      " |      >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(method=histogram_intersection)\n",
      " |            dogs  cats\n",
      " |      dogs   1.0   0.3\n",
      " |      cats   0.3   1.0\n",
      " |\n",
      " |      >>> df = pd.DataFrame([(1, 1), (2, np.nan), (np.nan, 3), (4, 4)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(min_periods=3)\n",
      " |            dogs  cats\n",
      " |      dogs   1.0   NaN\n",
      " |      cats   NaN   1.0\n",
      " |\n",
      " |  corrwith(self, other: 'DataFrame | Series', axis: 'Axis' = 0, drop: 'bool' = False, method: 'CorrelationMethod' = 'pearson', numeric_only: 'bool' = False) -> 'Series'\n",
      " |      Compute pairwise correlation.\n",
      " |\n",
      " |      Pairwise correlation is computed between rows or columns of\n",
      " |      DataFrame with rows or columns of Series or DataFrame. DataFrames\n",
      " |      are first aligned along both axes before computing the\n",
      " |      correlations.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series\n",
      " |          Object with which to compute correlations.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' to compute row-wise, 1 or 'columns' for\n",
      " |          column-wise.\n",
      " |      drop : bool, default False\n",
      " |          Drop missing indices from result.\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float.\n",
      " |\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Pairwise correlations.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corr : Compute pairwise correlation of columns.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
      " |      >>> columns = [\"one\", \"two\", \"three\", \"four\"]\n",
      " |      >>> df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)\n",
      " |      >>> df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)\n",
      " |      >>> df1.corrwith(df2)\n",
      " |      one      1.0\n",
      " |      two      1.0\n",
      " |      three    1.0\n",
      " |      four     1.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> df2.corrwith(df1, axis=1)\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  count(self, axis: 'Axis' = 0, numeric_only: 'bool' = False)\n",
      " |      Count non-NA cells for each column or row.\n",
      " |\n",
      " |      The values `None`, `NaN`, `NaT`, ``pandas.NA`` are considered NA.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          If 0 or 'index' counts are generated for each column.\n",
      " |          If 1 or 'columns' counts are generated for each row.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          For each column/row the number of non-NA/null entries.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.count: Number of non-NA elements in a Series.\n",
      " |      DataFrame.value_counts: Count unique combinations of columns.\n",
      " |      DataFrame.shape: Number of DataFrame rows and columns (including NA\n",
      " |          elements).\n",
      " |      DataFrame.isna: Boolean same-sized DataFrame showing places of NA\n",
      " |          elements.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Constructing DataFrame from a dictionary:\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"Person\":\n",
      " |      ...                    [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\n",
      " |      ...                    \"Age\": [24., np.nan, 21., 33, 26],\n",
      " |      ...                    \"Single\": [False, True, True, True, False]})\n",
      " |      >>> df\n",
      " |         Person   Age  Single\n",
      " |      0    John  24.0   False\n",
      " |      1    Myla   NaN    True\n",
      " |      2   Lewis  21.0    True\n",
      " |      3    John  33.0    True\n",
      " |      4    Myla  26.0   False\n",
      " |\n",
      " |      Notice the uncounted NA values:\n",
      " |\n",
      " |      >>> df.count()\n",
      " |      Person    5\n",
      " |      Age       4\n",
      " |      Single    5\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Counts for each **row**:\n",
      " |\n",
      " |      >>> df.count(axis='columns')\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |\n",
      " |  cov(self, min_periods: 'int | None' = None, ddof: 'int | None' = 1, numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |\n",
      " |      Compute the pairwise covariance among the series of a DataFrame.\n",
      " |      The returned data frame is the `covariance matrix\n",
      " |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      " |      of the DataFrame.\n",
      " |\n",
      " |      Both NA and null values are automatically excluded from the\n",
      " |      calculation. (See the note below about bias from missing values.)\n",
      " |      A threshold can be set for the minimum number of\n",
      " |      observations for each value created. Comparisons with observations\n",
      " |      below this threshold will be returned as ``NaN``.\n",
      " |\n",
      " |      This method is generally used for the analysis of time series data to\n",
      " |      understand the relationship between different measures\n",
      " |      across time.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |\n",
      " |      ddof : int, default 1\n",
      " |          Delta degrees of freedom.  The divisor used in calculations\n",
      " |          is ``N - ddof``, where ``N`` represents the number of elements.\n",
      " |          This argument is applicable only when no ``nan`` is in the dataframe.\n",
      " |\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The covariance matrix of the series of the DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.cov : Compute covariance with another Series.\n",
      " |      core.window.ewm.ExponentialMovingWindow.cov : Exponential weighted sample\n",
      " |          covariance.\n",
      " |      core.window.expanding.Expanding.cov : Expanding sample covariance.\n",
      " |      core.window.rolling.Rolling.cov : Rolling sample covariance.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-ddof.\n",
      " |\n",
      " |      For DataFrames that have Series that are missing data (assuming that\n",
      " |      data is `missing at random\n",
      " |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      " |      the returned covariance matrix will be an unbiased estimate\n",
      " |      of the variance and covariance between the member Series.\n",
      " |\n",
      " |      However, for many applications this estimate may not be acceptable\n",
      " |      because the estimate covariance matrix is not guaranteed to be positive\n",
      " |      semi-definite. This could lead to estimate correlations having\n",
      " |      absolute values which are greater than one, and/or a non-invertible\n",
      " |      covariance matrix. See `Estimation of covariance matrices\n",
      " |      <https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      " |      matrices>`__ for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.cov()\n",
      " |                dogs      cats\n",
      " |      dogs  0.666667 -1.000000\n",
      " |      cats -1.000000  1.666667\n",
      " |\n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      " |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> df.cov()\n",
      " |                a         b         c         d         e\n",
      " |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      " |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      " |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      " |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      " |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      " |\n",
      " |      **Minimum number of periods**\n",
      " |\n",
      " |      This method also supports an optional ``min_periods`` keyword\n",
      " |      that specifies the required minimum number of non-NA observations for\n",
      " |      each column pair in order to have a valid result:\n",
      " |\n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      " |      ...                   columns=['a', 'b', 'c'])\n",
      " |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      " |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      " |      >>> df.cov(min_periods=12)\n",
      " |                a         b         c\n",
      " |      a  0.316741       NaN -0.150812\n",
      " |      b       NaN  1.248003  0.191417\n",
      " |      c -0.150812  0.191417  0.895202\n",
      " |\n",
      " |  cummax(self, axis: 'Axis | None' = None, skipna: 'bool' = True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |\n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative maximum of Series or DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.max : Return the maximum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      By default, NA values are ignored.\n",
      " |\n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |\n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                   columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |\n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |\n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |\n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |\n",
      " |  cummin(self, axis: 'Axis | None' = None, skipna: 'bool' = True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |\n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative minimum of Series or DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.min : Return the minimum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      By default, NA values are ignored.\n",
      " |\n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |\n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                   columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |\n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |\n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |  cumprod(self, axis: 'Axis | None' = None, skipna: 'bool' = True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |\n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative product of Series or DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.prod : Return the product over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      By default, NA values are ignored.\n",
      " |\n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |\n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                   columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |\n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |\n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |\n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |  cumsum(self, axis: 'Axis | None' = None, skipna: 'bool' = True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |\n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative sum of Series or DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.sum : Return the sum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      By default, NA values are ignored.\n",
      " |\n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |\n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                   columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |\n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |\n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |\n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |\n",
      " |  diff(self, periods: 'int' = 1, axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      First discrete difference of element.\n",
      " |\n",
      " |      Calculates the difference of a DataFrame element compared with another\n",
      " |      element in the DataFrame (default is element in previous row).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          First differences of the Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pct_change: Percent change over given number of periods.\n",
      " |      DataFrame.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      Series.diff: First discrete difference of object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      For boolean dtypes, this uses :meth:`operator.xor` rather than\n",
      " |      :meth:`operator.sub`.\n",
      " |      The result is calculated according to current dtype in DataFrame,\n",
      " |      however dtype of the result is always float64.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      Difference with previous row\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'b': [1, 1, 2, 3, 5, 8],\n",
      " |      ...                    'c': [1, 4, 9, 16, 25, 36]})\n",
      " |      >>> df\n",
      " |         a  b   c\n",
      " |      0  1  1   1\n",
      " |      1  2  1   4\n",
      " |      2  3  2   9\n",
      " |      3  4  3  16\n",
      " |      4  5  5  25\n",
      " |      5  6  8  36\n",
      " |\n",
      " |      >>> df.diff()\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  1.0  0.0   3.0\n",
      " |      2  1.0  1.0   5.0\n",
      " |      3  1.0  1.0   7.0\n",
      " |      4  1.0  2.0   9.0\n",
      " |      5  1.0  3.0  11.0\n",
      " |\n",
      " |      Difference with previous column\n",
      " |\n",
      " |      >>> df.diff(axis=1)\n",
      " |          a  b   c\n",
      " |      0 NaN  0   0\n",
      " |      1 NaN -1   3\n",
      " |      2 NaN -1   7\n",
      " |      3 NaN -1  13\n",
      " |      4 NaN  0  20\n",
      " |      5 NaN  2  28\n",
      " |\n",
      " |      Difference with 3rd previous row\n",
      " |\n",
      " |      >>> df.diff(periods=3)\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  NaN   NaN\n",
      " |      2  NaN  NaN   NaN\n",
      " |      3  3.0  2.0  15.0\n",
      " |      4  3.0  4.0  21.0\n",
      " |      5  3.0  6.0  27.0\n",
      " |\n",
      " |      Difference with following row\n",
      " |\n",
      " |      >>> df.diff(periods=-1)\n",
      " |           a    b     c\n",
      " |      0 -1.0  0.0  -3.0\n",
      " |      1 -1.0 -1.0  -5.0\n",
      " |      2 -1.0 -1.0  -7.0\n",
      " |      3 -1.0 -2.0  -9.0\n",
      " |      4 -1.0 -3.0 -11.0\n",
      " |      5  NaN  NaN   NaN\n",
      " |\n",
      " |      Overflow in input dtype\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'a': [1, 0]}, dtype=np.uint8)\n",
      " |      >>> df.diff()\n",
      " |             a\n",
      " |      0    NaN\n",
      " |      1  255.0\n",
      " |\n",
      " |  div = truediv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  divide = truediv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  dot(self, other: 'AnyArrayLike | DataFrame') -> 'DataFrame | Series'\n",
      " |      Compute the matrix multiplication between the DataFrame and other.\n",
      " |\n",
      " |      This method computes the matrix product between the DataFrame and the\n",
      " |      values of an other Series, DataFrame or a numpy array.\n",
      " |\n",
      " |      It can also be called using ``self @ other``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame or array-like\n",
      " |          The other object to compute the matrix product with.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If other is a Series, return the matrix product between self and\n",
      " |          other as a Series. If other is a DataFrame or a numpy.array, return\n",
      " |          the matrix product of self and other in a DataFrame of a np.array.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dot: Similar method for Series.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dimensions of DataFrame and other must be compatible in order to\n",
      " |      compute the matrix multiplication. In addition, the column names of\n",
      " |      DataFrame and the index of other must contain the same values, as they\n",
      " |      will be aligned prior to the multiplication.\n",
      " |\n",
      " |      The dot method for Series computes the inner product, instead of the\n",
      " |      matrix product here.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Here we multiply a DataFrame with a Series.\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])\n",
      " |      >>> s = pd.Series([1, 1, 2, 1])\n",
      " |      >>> df.dot(s)\n",
      " |      0    -4\n",
      " |      1     5\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Here we multiply a DataFrame with another DataFrame.\n",
      " |\n",
      " |      >>> other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
      " |      >>> df.dot(other)\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |\n",
      " |      Note that the dot method give the same result as @\n",
      " |\n",
      " |      >>> df @ other\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |\n",
      " |      The dot method works also if other is an np.array.\n",
      " |\n",
      " |      >>> arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
      " |      >>> df.dot(arr)\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |\n",
      " |      Note how shuffling of the objects does not change the result.\n",
      " |\n",
      " |      >>> s2 = s.reindex([1, 0, 2, 3])\n",
      " |      >>> df.dot(s2)\n",
      " |      0    -4\n",
      " |      1     5\n",
      " |      dtype: int64\n",
      " |\n",
      " |  drop(self, labels: 'IndexLabel | None' = None, *, axis: 'Axis' = 0, index: 'IndexLabel | None' = None, columns: 'IndexLabel | None' = None, level: 'Level | None' = None, inplace: 'bool' = False, errors: 'IgnoreRaise' = 'raise') -> 'DataFrame | None'\n",
      " |      Drop specified labels from rows or columns.\n",
      " |\n",
      " |      Remove rows or columns by specifying label names and corresponding\n",
      " |      axis, or by directly specifying index or column names. When using a\n",
      " |      multi-index, labels on different levels can be removed by specifying\n",
      " |      the level. See the :ref:`user guide <advanced.shown_levels>`\n",
      " |      for more information about the now unused levels.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index or column labels to drop. A tuple will be used as a single\n",
      " |          label and not treated as a list-like.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Whether to drop labels from the index (0 or 'index') or\n",
      " |          columns (1 or 'columns').\n",
      " |      index : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=0``\n",
      " |          is equivalent to ``index=labels``).\n",
      " |      columns : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=1``\n",
      " |          is equivalent to ``columns=labels``).\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level from which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If False, return a copy. Otherwise, do operation\n",
      " |          in place and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are\n",
      " |          dropped.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          Returns DataFrame or None DataFrame with the specified\n",
      " |          index or column labels removed or None if inplace=True.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any of the labels is not found in the selected axis.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Label-location based indexer for selection by label.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing.\n",
      " |      DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n",
      " |          removed, optionally only considering certain columns.\n",
      " |      Series.drop : Return Series with specified index labels removed.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
      " |      ...                   columns=['A', 'B', 'C', 'D'])\n",
      " |      >>> df\n",
      " |         A  B   C   D\n",
      " |      0  0  1   2   3\n",
      " |      1  4  5   6   7\n",
      " |      2  8  9  10  11\n",
      " |\n",
      " |      Drop columns\n",
      " |\n",
      " |      >>> df.drop(['B', 'C'], axis=1)\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |\n",
      " |      >>> df.drop(columns=['B', 'C'])\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |\n",
      " |      Drop a row by index\n",
      " |\n",
      " |      >>> df.drop([0, 1])\n",
      " |         A  B   C   D\n",
      " |      2  8  9  10  11\n",
      " |\n",
      " |      Drop columns and/or rows of MultiIndex DataFrame\n",
      " |\n",
      " |      >>> midx = pd.MultiIndex(levels=[['llama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n",
      " |      ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n",
      " |      ...                         [250, 150], [1.5, 0.8], [320, 250],\n",
      " |      ...                         [1, 0.8], [0.3, 0.2]])\n",
      " |      >>> df\n",
      " |                      big     small\n",
      " |      llama   speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |              length  1.5     1.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |              length  1.5     0.8\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |              length  0.3     0.2\n",
      " |\n",
      " |      Drop a specific index combination from the MultiIndex\n",
      " |      DataFrame, i.e., drop the combination ``'falcon'`` and\n",
      " |      ``'weight'``, which deletes only the corresponding row\n",
      " |\n",
      " |      >>> df.drop(index=('falcon', 'weight'))\n",
      " |                      big     small\n",
      " |      llama   speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |              length  1.5     1.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |              length  1.5     0.8\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              length  0.3     0.2\n",
      " |\n",
      " |      >>> df.drop(index='cow', columns='small')\n",
      " |                      big\n",
      " |      llama   speed   45.0\n",
      " |              weight  200.0\n",
      " |              length  1.5\n",
      " |      falcon  speed   320.0\n",
      " |              weight  1.0\n",
      " |              length  0.3\n",
      " |\n",
      " |      >>> df.drop(index='length', level=1)\n",
      " |                      big     small\n",
      " |      llama   speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |\n",
      " |  drop_duplicates(self, subset: 'Hashable | Sequence[Hashable] | None' = None, *, keep: 'DropKeep' = 'first', inplace: 'bool' = False, ignore_index: 'bool' = False) -> 'DataFrame | None'\n",
      " |      Return DataFrame with duplicate rows removed.\n",
      " |\n",
      " |      Considering certain columns is optional. Indexes, including time indexes\n",
      " |      are ignored.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns.\n",
      " |      keep : {'first', 'last', ``False``}, default 'first'\n",
      " |          Determines which duplicates (if any) to keep.\n",
      " |\n",
      " |          - 'first' : Drop duplicates except for the first occurrence.\n",
      " |          - 'last' : Drop duplicates except for the last occurrence.\n",
      " |          - ``False`` : Drop all duplicates.\n",
      " |\n",
      " |      inplace : bool, default ``False``\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      ignore_index : bool, default ``False``\n",
      " |          If ``True``, the resulting axis will be labeled 0, 1, , n - 1.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with duplicates removed or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.value_counts: Count unique combinations of columns.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing ramen rating.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
      " |      ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
      " |      ...     'rating': [4, 4, 3.5, 15, 5]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |\n",
      " |      By default, it removes duplicate rows based on all columns.\n",
      " |\n",
      " |      >>> df.drop_duplicates()\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |\n",
      " |      To remove duplicates on specific column(s), use ``subset``.\n",
      " |\n",
      " |      >>> df.drop_duplicates(subset=['brand'])\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |\n",
      " |      To remove duplicates and keep last occurrences, use ``keep``.\n",
      " |\n",
      " |      >>> df.drop_duplicates(subset=['brand', 'style'], keep='last')\n",
      " |          brand style  rating\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      4  Indomie  pack     5.0\n",
      " |\n",
      " |  dropna(self, *, axis: 'Axis' = 0, how: 'AnyAll | lib.NoDefault' = <no_default>, thresh: 'int | lib.NoDefault' = <no_default>, subset: 'IndexLabel | None' = None, inplace: 'bool' = False, ignore_index: 'bool' = False) -> 'DataFrame | None'\n",
      " |      Remove missing values.\n",
      " |\n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine if rows or columns which contain missing values are\n",
      " |          removed.\n",
      " |\n",
      " |          * 0, or 'index' : Drop rows which contain missing values.\n",
      " |          * 1, or 'columns' : Drop columns which contain missing value.\n",
      " |\n",
      " |          Only a single axis is allowed.\n",
      " |\n",
      " |      how : {'any', 'all'}, default 'any'\n",
      " |          Determine if row or column is removed from DataFrame, when we have\n",
      " |          at least one NA or all NA.\n",
      " |\n",
      " |          * 'any' : If any NA values are present, drop that row or column.\n",
      " |          * 'all' : If all values are NA, drop that row or column.\n",
      " |\n",
      " |      thresh : int, optional\n",
      " |          Require that many non-NA values. Cannot be combined with how.\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Labels along other axis to consider, e.g. if you are dropping rows\n",
      " |          these would be a list of columns to include.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      ignore_index : bool, default ``False``\n",
      " |          If ``True``, the resulting axis will be labeled 0, 1, , n - 1.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with NA entries dropped from it or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isna: Indicate missing values.\n",
      " |      DataFrame.notna : Indicate existing (non-missing) values.\n",
      " |      DataFrame.fillna : Replace missing values.\n",
      " |      Series.dropna : Drop missing values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
      " |      ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
      " |      ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
      " |      ...                             pd.NaT]})\n",
      " |      >>> df\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |\n",
      " |      Drop the rows where at least one element is missing.\n",
      " |\n",
      " |      >>> df.dropna()\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |\n",
      " |      Drop the columns where at least one element is missing.\n",
      " |\n",
      " |      >>> df.dropna(axis='columns')\n",
      " |             name\n",
      " |      0    Alfred\n",
      " |      1    Batman\n",
      " |      2  Catwoman\n",
      " |\n",
      " |      Drop the rows where all elements are missing.\n",
      " |\n",
      " |      >>> df.dropna(how='all')\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |\n",
      " |      Keep only the rows with at least 2 non-NA values.\n",
      " |\n",
      " |      >>> df.dropna(thresh=2)\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |\n",
      " |      Define in which columns to look for missing values.\n",
      " |\n",
      " |      >>> df.dropna(subset=['name', 'toy'])\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |\n",
      " |  duplicated(self, subset: 'Hashable | Sequence[Hashable] | None' = None, keep: 'DropKeep' = 'first') -> 'Series'\n",
      " |      Return boolean Series denoting duplicate rows.\n",
      " |\n",
      " |      Considering certain columns is optional.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns.\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Determines which duplicates (if any) to mark.\n",
      " |\n",
      " |          - ``first`` : Mark duplicates as ``True`` except for the first occurrence.\n",
      " |          - ``last`` : Mark duplicates as ``True`` except for the last occurrence.\n",
      " |          - False : Mark all duplicates as ``True``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Boolean series for each duplicated rows.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.duplicated : Equivalent method on index.\n",
      " |      Series.duplicated : Equivalent method on Series.\n",
      " |      Series.drop_duplicates : Remove duplicate values from Series.\n",
      " |      DataFrame.drop_duplicates : Remove duplicate values from DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing ramen rating.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
      " |      ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
      " |      ...     'rating': [4, 4, 3.5, 15, 5]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |\n",
      " |      By default, for each set of duplicated values, the first occurrence\n",
      " |      is set on False and all others on True.\n",
      " |\n",
      " |      >>> df.duplicated()\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      By using 'last', the last occurrence of each set of duplicated values\n",
      " |      is set on False and all others on True.\n",
      " |\n",
      " |      >>> df.duplicated(keep='last')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      By setting ``keep`` on False, all duplicates are True.\n",
      " |\n",
      " |      >>> df.duplicated(keep=False)\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      To find duplicates on specific column(s), use ``subset``.\n",
      " |\n",
      " |      >>> df.duplicated(subset=['brand'])\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3     True\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |\n",
      " |  eq(self, other, axis: 'Axis' = 'columns', level=None) -> 'DataFrame'\n",
      " |      Get Equal to of dataframe and other, element-wise (binary operator `eq`).\n",
      " |\n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |\n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |\n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |\n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |\n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |\n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |\n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |\n",
      " |      Use the method to control the broadcast axis:\n",
      " |\n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |\n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |\n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |\n",
      " |      Use the method to control the axis:\n",
      " |\n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |\n",
      " |      Compare to a DataFrame of different shape.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |\n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |\n",
      " |      Compare to a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |\n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |\n",
      " |  eval(self, expr: 'str', *, inplace: 'bool' = False, **kwargs) -> 'Any | None'\n",
      " |      Evaluate a string describing operations on DataFrame columns.\n",
      " |\n",
      " |      Operates on columns only, not specific rows or elements.  This allows\n",
      " |      `eval` to run arbitrary code, which can make you vulnerable to code\n",
      " |      injection if you pass user input to this function.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The expression string to evaluate.\n",
      " |      inplace : bool, default False\n",
      " |          If the expression contains an assignment, whether to perform the\n",
      " |          operation inplace and mutate the existing DataFrame. Otherwise,\n",
      " |          a new DataFrame is returned.\n",
      " |      **kwargs\n",
      " |          See the documentation for :func:`eval` for complete details\n",
      " |          on the keyword arguments accepted by\n",
      " |          :meth:`~pandas.DataFrame.query`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray, scalar, pandas object, or None\n",
      " |          The result of the evaluation or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.query : Evaluates a boolean expression to query the columns\n",
      " |          of a frame.\n",
      " |      DataFrame.assign : Can evaluate an expression or function to create new\n",
      " |          values for a column.\n",
      " |      eval : Evaluate a Python expression as a string using various\n",
      " |          backends.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      For more details see the API documentation for :func:`~eval`.\n",
      " |      For detailed examples see :ref:`enhancing performance with eval\n",
      " |      <enhancingperf.eval>`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      >>> df.eval('A + B')\n",
      " |      0    11\n",
      " |      1    10\n",
      " |      2     9\n",
      " |      3     8\n",
      " |      4     7\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Assignment is allowed though by default the original DataFrame is not\n",
      " |      modified.\n",
      " |\n",
      " |      >>> df.eval('C = A + B')\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |\n",
      " |      Multiple columns can be assigned to using multi-line expressions:\n",
      " |\n",
      " |      >>> df.eval(\n",
      " |      ...     '''\n",
      " |      ... C = A + B\n",
      " |      ... D = A - B\n",
      " |      ... '''\n",
      " |      ... )\n",
      " |         A   B   C  D\n",
      " |      0  1  10  11 -9\n",
      " |      1  2   8  10 -6\n",
      " |      2  3   6   9 -3\n",
      " |      3  4   4   8  0\n",
      " |      4  5   2   7  3\n",
      " |\n",
      " |  explode(self, column: 'IndexLabel', ignore_index: 'bool' = False) -> 'DataFrame'\n",
      " |      Transform each element of a list-like to a row, replicating index values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : IndexLabel\n",
      " |          Column(s) to explode.\n",
      " |          For multiple columns, specify a non-empty list with each element\n",
      " |          be str or tuple, and all specified columns their list-like data\n",
      " |          on same row of the frame must have matching length.\n",
      " |\n",
      " |          .. versionadded:: 1.3.0\n",
      " |              Multi-column explode\n",
      " |\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, , n - 1.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Exploded lists to rows of the subset columns;\n",
      " |          index will be duplicated for these rows.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError :\n",
      " |          * If columns of the frame are not unique.\n",
      " |          * If specified columns to explode is empty list.\n",
      " |          * If specified columns to explode have not matching count of\n",
      " |            elements rowwise in the frame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Pivot a level of the (necessarily hierarchical)\n",
      " |          index labels.\n",
      " |      DataFrame.melt : Unpivot a DataFrame from wide format to long format.\n",
      " |      Series.explode : Explode a DataFrame from list-like columns to long format.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This routine will explode list-likes including lists, tuples, sets,\n",
      " |      Series, and np.ndarray. The result dtype of the subset rows will\n",
      " |      be object. Scalars will be returned unchanged, and empty list-likes will\n",
      " |      result in a np.nan for that row. In addition, the ordering of rows in the\n",
      " |      output will be non-deterministic when exploding sets.\n",
      " |\n",
      " |      Reference :ref:`the user guide <reshaping.explode>` for more examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [[0, 1, 2], 'foo', [], [3, 4]],\n",
      " |      ...                    'B': 1,\n",
      " |      ...                    'C': [['a', 'b', 'c'], np.nan, [], ['d', 'e']]})\n",
      " |      >>> df\n",
      " |                 A  B          C\n",
      " |      0  [0, 1, 2]  1  [a, b, c]\n",
      " |      1        foo  1        NaN\n",
      " |      2         []  1         []\n",
      " |      3     [3, 4]  1     [d, e]\n",
      " |\n",
      " |      Single-column explode.\n",
      " |\n",
      " |      >>> df.explode('A')\n",
      " |           A  B          C\n",
      " |      0    0  1  [a, b, c]\n",
      " |      0    1  1  [a, b, c]\n",
      " |      0    2  1  [a, b, c]\n",
      " |      1  foo  1        NaN\n",
      " |      2  NaN  1         []\n",
      " |      3    3  1     [d, e]\n",
      " |      3    4  1     [d, e]\n",
      " |\n",
      " |      Multi-column explode.\n",
      " |\n",
      " |      >>> df.explode(list('AC'))\n",
      " |           A  B    C\n",
      " |      0    0  1    a\n",
      " |      0    1  1    b\n",
      " |      0    2  1    c\n",
      " |      1  foo  1  NaN\n",
      " |      2  NaN  1  NaN\n",
      " |      3    3  1    d\n",
      " |      3    4  1    e\n",
      " |\n",
      " |  floordiv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Integer division of dataframe and other, element-wise (binary operator `floordiv`).\n",
      " |\n",
      " |      Equivalent to ``dataframe // other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rfloordiv`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  ge(self, other, axis: 'Axis' = 'columns', level=None) -> 'DataFrame'\n",
      " |      Get Greater than or equal to of dataframe and other, element-wise (binary operator `ge`).\n",
      " |\n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |\n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |\n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |\n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |\n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |\n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |\n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |\n",
      " |      Use the method to control the broadcast axis:\n",
      " |\n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |\n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |\n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |\n",
      " |      Use the method to control the axis:\n",
      " |\n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |\n",
      " |      Compare to a DataFrame of different shape.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |\n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |\n",
      " |      Compare to a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |\n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |\n",
      " |  groupby(self, by=None, axis: 'Axis | lib.NoDefault' = <no_default>, level: 'IndexLabel | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, observed: 'bool | lib.NoDefault' = <no_default>, dropna: 'bool' = True) -> 'DataFrameGroupBy'\n",
      " |      Group DataFrame using a mapper or by a Series of columns.\n",
      " |\n",
      " |      A groupby operation involves some combination of splitting the\n",
      " |      object, applying a function, and combining the results. This can be\n",
      " |      used to group large amounts of data and compute operations on these\n",
      " |      groups.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, pd.Grouper or list of such\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If a list or ndarray of length\n",
      " |          equal to the selected axis is passed (see the `groupby user guide\n",
      " |          <https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#splitting-an-object-into-groups>`_),\n",
      " |          the values are used as-is to determine the groups. A label or list\n",
      " |          of labels may be passed to group by the columns in ``self``.\n",
      " |          Notice that a tuple is interpreted as a (single) key.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Split along rows (0) or columns (1). For `Series` this parameter\n",
      " |          is unused and defaults to 0.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |\n",
      " |              Will be removed and behave like axis=0 in a future version.\n",
      " |              For ``axis=1``, do ``frame.T.groupby(...)`` instead.\n",
      " |\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels. Do not specify both ``by`` and ``level``.\n",
      " |      as_index : bool, default True\n",
      " |          Return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output. This argument has no effect\n",
      " |          on filtrations (see the `filtrations in the user guide\n",
      " |          <https://pandas.pydata.org/docs/dev/user_guide/groupby.html#filtration>`_),\n",
      " |          such as ``head()``, ``tail()``, ``nth()`` and in transformations\n",
      " |          (see the `transformations in the user guide\n",
      " |          <https://pandas.pydata.org/docs/dev/user_guide/groupby.html#transformation>`_).\n",
      " |      sort : bool, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group. Groupby preserves the order of rows within each group. If False,\n",
      " |          the groups will appear in the same order as they did in the original DataFrame.\n",
      " |          This argument has no effect on filtrations (see the `filtrations in the user guide\n",
      " |          <https://pandas.pydata.org/docs/dev/user_guide/groupby.html#filtration>`_),\n",
      " |          such as ``head()``, ``tail()``, ``nth()`` and in transformations\n",
      " |          (see the `transformations in the user guide\n",
      " |          <https://pandas.pydata.org/docs/dev/user_guide/groupby.html#transformation>`_).\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |\n",
      " |              Specifying ``sort=False`` with an ordered categorical grouper will no\n",
      " |              longer sort the values.\n",
      " |\n",
      " |      group_keys : bool, default True\n",
      " |          When calling apply and the ``by`` argument produces a like-indexed\n",
      " |          (i.e. :ref:`a transform <groupby.transform>`) result, add group keys to\n",
      " |          index to identify pieces. By default group keys are not included\n",
      " |          when the result's index (and column) labels match the inputs, and\n",
      " |          are included otherwise.\n",
      " |\n",
      " |          .. versionchanged:: 1.5.0\n",
      " |\n",
      " |             Warns that ``group_keys`` will no longer be ignored when the\n",
      " |             result from ``apply`` is a like-indexed Series or DataFrame.\n",
      " |             Specify ``group_keys`` explicitly to include the group keys or\n",
      " |             not.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |\n",
      " |             ``group_keys`` now defaults to ``True``.\n",
      " |\n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |\n",
      " |              The default value will change to True in a future version of pandas.\n",
      " |\n",
      " |      dropna : bool, default True\n",
      " |          If True, and if group keys contain NA values, NA values together\n",
      " |          with row/column will be dropped.\n",
      " |          If False, NA values will also be treated as the key in groups.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.DataFrameGroupBy\n",
      " |          Returns a groupby object that contains information about the groups.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/groupby.html>`__ for more\n",
      " |      detailed usage and examples, including splitting an object into groups,\n",
      " |      iterating through groups, selecting a group, aggregation, and more.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
      " |      ...                               'Parrot', 'Parrot'],\n",
      " |      ...                    'Max Speed': [380., 370., 24., 26.]})\n",
      " |      >>> df\n",
      " |         Animal  Max Speed\n",
      " |      0  Falcon      380.0\n",
      " |      1  Falcon      370.0\n",
      " |      2  Parrot       24.0\n",
      " |      3  Parrot       26.0\n",
      " |      >>> df.groupby(['Animal']).mean()\n",
      " |              Max Speed\n",
      " |      Animal\n",
      " |      Falcon      375.0\n",
      " |      Parrot       25.0\n",
      " |\n",
      " |      **Hierarchical Indexes**\n",
      " |\n",
      " |      We can groupby different levels of a hierarchical index\n",
      " |      using the `level` parameter:\n",
      " |\n",
      " |      >>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
      " |      ...           ['Captive', 'Wild', 'Captive', 'Wild']]\n",
      " |      >>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
      " |      >>> df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                      Max Speed\n",
      " |      Animal Type\n",
      " |      Falcon Captive      390.0\n",
      " |             Wild         350.0\n",
      " |      Parrot Captive       30.0\n",
      " |             Wild          20.0\n",
      " |      >>> df.groupby(level=0).mean()\n",
      " |              Max Speed\n",
      " |      Animal\n",
      " |      Falcon      370.0\n",
      " |      Parrot       25.0\n",
      " |      >>> df.groupby(level=\"Type\").mean()\n",
      " |               Max Speed\n",
      " |      Type\n",
      " |      Captive      210.0\n",
      " |      Wild         185.0\n",
      " |\n",
      " |      We can also choose to include NA in group keys or not by setting\n",
      " |      `dropna` parameter, the default setting is `True`.\n",
      " |\n",
      " |      >>> l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n",
      " |      >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      " |\n",
      " |      >>> df.groupby(by=[\"b\"]).sum()\n",
      " |          a   c\n",
      " |      b\n",
      " |      1.0 2   3\n",
      " |      2.0 2   5\n",
      " |\n",
      " |      >>> df.groupby(by=[\"b\"], dropna=False).sum()\n",
      " |          a   c\n",
      " |      b\n",
      " |      1.0 2   3\n",
      " |      2.0 2   5\n",
      " |      NaN 1   4\n",
      " |\n",
      " |      >>> l = [[\"a\", 12, 12], [None, 12.3, 33.], [\"b\", 12.3, 123], [\"a\", 1, 1]]\n",
      " |      >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      " |\n",
      " |      >>> df.groupby(by=\"a\").sum()\n",
      " |          b     c\n",
      " |      a\n",
      " |      a   13.0   13.0\n",
      " |      b   12.3  123.0\n",
      " |\n",
      " |      >>> df.groupby(by=\"a\", dropna=False).sum()\n",
      " |          b     c\n",
      " |      a\n",
      " |      a   13.0   13.0\n",
      " |      b   12.3  123.0\n",
      " |      NaN 12.3   33.0\n",
      " |\n",
      " |      When using ``.apply()``, use ``group_keys`` to include or exclude the\n",
      " |      group keys. The ``group_keys`` argument defaults to ``True`` (include).\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
      " |      ...                               'Parrot', 'Parrot'],\n",
      " |      ...                    'Max Speed': [380., 370., 24., 26.]})\n",
      " |      >>> df.groupby(\"Animal\", group_keys=True)[['Max Speed']].apply(lambda x: x)\n",
      " |                Max Speed\n",
      " |      Animal\n",
      " |      Falcon 0      380.0\n",
      " |             1      370.0\n",
      " |      Parrot 2       24.0\n",
      " |             3       26.0\n",
      " |\n",
      " |      >>> df.groupby(\"Animal\", group_keys=False)[['Max Speed']].apply(lambda x: x)\n",
      " |         Max Speed\n",
      " |      0      380.0\n",
      " |      1      370.0\n",
      " |      2       24.0\n",
      " |      3       26.0\n",
      " |\n",
      " |  gt(self, other, axis: 'Axis' = 'columns', level=None) -> 'DataFrame'\n",
      " |      Get Greater than of dataframe and other, element-wise (binary operator `gt`).\n",
      " |\n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |\n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |\n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |\n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |\n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |\n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |\n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |\n",
      " |      Use the method to control the broadcast axis:\n",
      " |\n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |\n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |\n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |\n",
      " |      Use the method to control the axis:\n",
      " |\n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |\n",
      " |      Compare to a DataFrame of different shape.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |\n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |\n",
      " |      Compare to a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |\n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |\n",
      " |  hist = hist_frame(data: 'DataFrame', column: 'IndexLabel | None' = None, by=None, grid: 'bool' = True, xlabelsize: 'int | None' = None, xrot: 'float | None' = None, ylabelsize: 'int | None' = None, yrot: 'float | None' = None, ax=None, sharex: 'bool' = False, sharey: 'bool' = False, figsize: 'tuple[int, int] | None' = None, layout: 'tuple[int, int] | None' = None, bins: 'int | Sequence[int]' = 10, backend: 'str | None' = None, legend: 'bool' = False, **kwargs)\n",
      " |      Make a histogram of the DataFrame's columns.\n",
      " |\n",
      " |      A `histogram`_ is a representation of the distribution of data.\n",
      " |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      " |      the DataFrame, resulting in one histogram per column.\n",
      " |\n",
      " |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          The pandas object holding the data.\n",
      " |      column : str or sequence, optional\n",
      " |          If passed, will be used to limit data to a subset of columns.\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      grid : bool, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      " |          x labels rotated 90 degrees clockwise.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      " |          y labels rotated 90 degrees clockwise.\n",
      " |      ax : Matplotlib axes object, default None\n",
      " |          The axes to plot the histogram on.\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in.\n",
      " |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      " |          labels for all subplots in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible.\n",
      " |      figsize : tuple, optional\n",
      " |          The size in inches of the figure to create. Uses the value in\n",
      " |          `matplotlib.rcParams` by default.\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms.\n",
      " |      bins : int or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |\n",
      " |      legend : bool, default False\n",
      " |          Whether to show the legend.\n",
      " |\n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :meth:`matplotlib.pyplot.hist`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      matplotlib.AxesSubplot or numpy.ndarray of them\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      This example draws a histogram based on the length and width of\n",
      " |      some animals, displayed in three bins\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> data = {'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...         'width': [0.7, 0.2, 0.15, 0.2, 1.1]}\n",
      " |          >>> index = ['pig', 'rabbit', 'duck', 'chicken', 'horse']\n",
      " |          >>> df = pd.DataFrame(data, index=index)\n",
      " |          >>> hist = df.hist(bins=3)\n",
      " |\n",
      " |  idxmax(self, axis: 'Axis' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False) -> 'Series'\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |\n",
      " |      NA/null values are excluded.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of maxima along the specified axis.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax : Return index of the maximum element.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                     'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                   index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |\n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |\n",
      " |      By default, it returns the index for the maximum value in each column.\n",
      " |\n",
      " |      >>> df.idxmax()\n",
      " |      consumption     Wheat Products\n",
      " |      co2_emissions             Beef\n",
      " |      dtype: object\n",
      " |\n",
      " |      To return the index for the maximum value in each row, use ``axis=\"columns\"``.\n",
      " |\n",
      " |      >>> df.idxmax(axis=\"columns\")\n",
      " |      Pork              co2_emissions\n",
      " |      Wheat Products     consumption\n",
      " |      Beef              co2_emissions\n",
      " |      dtype: object\n",
      " |\n",
      " |  idxmin(self, axis: 'Axis' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False) -> 'Series'\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |\n",
      " |      NA/null values are excluded.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of minima along the specified axis.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin : Return index of the minimum element.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                     'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                   index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |\n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |\n",
      " |      By default, it returns the index for the minimum value in each column.\n",
      " |\n",
      " |      >>> df.idxmin()\n",
      " |      consumption                Pork\n",
      " |      co2_emissions    Wheat Products\n",
      " |      dtype: object\n",
      " |\n",
      " |      To return the index for the minimum value in each row, use ``axis=\"columns\"``.\n",
      " |\n",
      " |      >>> df.idxmin(axis=\"columns\")\n",
      " |      Pork                consumption\n",
      " |      Wheat Products    co2_emissions\n",
      " |      Beef                consumption\n",
      " |      dtype: object\n",
      " |\n",
      " |  info(self, verbose: 'bool | None' = None, buf: 'WriteBuffer[str] | None' = None, max_cols: 'int | None' = None, memory_usage: 'bool | str | None' = None, show_counts: 'bool | None' = None) -> 'None'\n",
      " |      Print a concise summary of a DataFrame.\n",
      " |\n",
      " |      This method prints information about a DataFrame including\n",
      " |      the index dtype and columns, non-null values and memory usage.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      verbose : bool, optional\n",
      " |          Whether to print the full summary. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is followed.\n",
      " |      buf : writable buffer, defaults to sys.stdout\n",
      " |          Where to send the output. By default, the output is printed to\n",
      " |          sys.stdout. Pass a writable buffer if you need to further process\n",
      " |          the output.\n",
      " |      max_cols : int, optional\n",
      " |          When to switch from the verbose to the truncated output. If the\n",
      " |          DataFrame has more than `max_cols` columns, the truncated output\n",
      " |          is used. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is used.\n",
      " |      memory_usage : bool, str, optional\n",
      " |          Specifies whether total memory usage of the DataFrame\n",
      " |          elements (including the index) should be displayed. By default,\n",
      " |          this follows the ``pandas.options.display.memory_usage`` setting.\n",
      " |\n",
      " |          True always show memory usage. False never shows memory usage.\n",
      " |          A value of 'deep' is equivalent to \"True with deep introspection\".\n",
      " |          Memory usage is shown in human-readable units (base-2\n",
      " |          representation). Without deep introspection a memory estimation is\n",
      " |          made based in column dtype and number of rows assuming values\n",
      " |          consume the same memory amount for corresponding dtypes. With deep\n",
      " |          memory introspection, a real memory usage calculation is performed\n",
      " |          at the cost of computational resources. See the\n",
      " |          :ref:`Frequently Asked Questions <df-memory-usage>` for more\n",
      " |          details.\n",
      " |      show_counts : bool, optional\n",
      " |          Whether to show the non-null counts. By default, this is shown\n",
      " |          only if the DataFrame is smaller than\n",
      " |          ``pandas.options.display.max_info_rows`` and\n",
      " |          ``pandas.options.display.max_info_columns``. A value of True always\n",
      " |          shows the counts, and False never shows the counts.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |          This method prints a summary of a DataFrame and returns None.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.describe: Generate descriptive statistics of DataFrame\n",
      " |          columns.\n",
      " |      DataFrame.memory_usage: Memory usage of DataFrame columns.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> int_values = [1, 2, 3, 4, 5]\n",
      " |      >>> text_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\n",
      " |      >>> float_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      " |      >>> df = pd.DataFrame({\"int_col\": int_values, \"text_col\": text_values,\n",
      " |      ...                   \"float_col\": float_values})\n",
      " |      >>> df\n",
      " |          int_col text_col  float_col\n",
      " |      0        1    alpha       0.00\n",
      " |      1        2     beta       0.25\n",
      " |      2        3    gamma       0.50\n",
      " |      3        4    delta       0.75\n",
      " |      4        5  epsilon       1.00\n",
      " |\n",
      " |      Prints information of all columns:\n",
      " |\n",
      " |      >>> df.info(verbose=True)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column     Non-Null Count  Dtype\n",
      " |      ---  ------     --------------  -----\n",
      " |       0   int_col    5 non-null      int64\n",
      " |       1   text_col   5 non-null      object\n",
      " |       2   float_col  5 non-null      float64\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 248.0+ bytes\n",
      " |\n",
      " |      Prints a summary of columns count and its dtypes but not per column\n",
      " |      information:\n",
      " |\n",
      " |      >>> df.info(verbose=False)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Columns: 3 entries, int_col to float_col\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 248.0+ bytes\n",
      " |\n",
      " |      Pipe output of DataFrame.info to buffer instead of sys.stdout, get\n",
      " |      buffer content and writes to a text file:\n",
      " |\n",
      " |      >>> import io\n",
      " |      >>> buffer = io.StringIO()\n",
      " |      >>> df.info(buf=buffer)\n",
      " |      >>> s = buffer.getvalue()\n",
      " |      >>> with open(\"df_info.txt\", \"w\",\n",
      " |      ...           encoding=\"utf-8\") as f:  # doctest: +SKIP\n",
      " |      ...     f.write(s)\n",
      " |      260\n",
      " |\n",
      " |      The `memory_usage` parameter allows deep introspection mode, specially\n",
      " |      useful for big DataFrames and fine-tune memory optimization:\n",
      " |\n",
      " |      >>> random_strings_array = np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'column_1': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_2': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_3': np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      ... })\n",
      " |      >>> df.info()\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column    Non-Null Count    Dtype\n",
      " |      ---  ------    --------------    -----\n",
      " |       0   column_1  1000000 non-null  object\n",
      " |       1   column_2  1000000 non-null  object\n",
      " |       2   column_3  1000000 non-null  object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 22.9+ MB\n",
      " |\n",
      " |      >>> df.info(memory_usage='deep')\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column    Non-Null Count    Dtype\n",
      " |      ---  ------    --------------    -----\n",
      " |       0   column_1  1000000 non-null  object\n",
      " |       1   column_2  1000000 non-null  object\n",
      " |       2   column_3  1000000 non-null  object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 165.9 MB\n",
      " |\n",
      " |  insert(self, loc: 'int', column: 'Hashable', value: 'Scalar | AnyArrayLike', allow_duplicates: 'bool | lib.NoDefault' = <no_default>) -> 'None'\n",
      " |      Insert column into DataFrame at specified location.\n",
      " |\n",
      " |      Raises a ValueError if `column` is already contained in the DataFrame,\n",
      " |      unless `allow_duplicates` is set to True.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int\n",
      " |          Insertion index. Must verify 0 <= loc <= len(columns).\n",
      " |      column : str, number, or hashable object\n",
      " |          Label of the inserted column.\n",
      " |      value : Scalar, Series, or array-like\n",
      " |          Content of the inserted column.\n",
      " |      allow_duplicates : bool, optional, default lib.no_default\n",
      " |          Allow duplicate column labels to be created.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.insert : Insert new item by index.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      >>> df.insert(1, \"newcol\", [99, 99])\n",
      " |      >>> df\n",
      " |         col1  newcol  col2\n",
      " |      0     1      99     3\n",
      " |      1     2      99     4\n",
      " |      >>> df.insert(0, \"col1\", [100, 100], allow_duplicates=True)\n",
      " |      >>> df\n",
      " |         col1  col1  newcol  col2\n",
      " |      0   100     1      99     3\n",
      " |      1   100     2      99     4\n",
      " |\n",
      " |      Notice that pandas uses index alignment in case of `value` from type `Series`:\n",
      " |\n",
      " |      >>> df.insert(0, \"col0\", pd.Series([5, 6], index=[1, 2]))\n",
      " |      >>> df\n",
      " |         col0  col1  col1  newcol  col2\n",
      " |      0   NaN   100     1      99     3\n",
      " |      1   5.0   100     2      99     4\n",
      " |\n",
      " |  isetitem(self, loc, value) -> 'None'\n",
      " |      Set the given value in the column with position `loc`.\n",
      " |\n",
      " |      This is a positional analogue to ``__setitem__``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int or sequence of ints\n",
      " |          Index position for the column.\n",
      " |      value : scalar or arraylike\n",
      " |          Value(s) for the column.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``frame.isetitem(loc, value)`` is an in-place method as it will\n",
      " |      modify the DataFrame in place (not returning a new object). In contrast to\n",
      " |      ``frame.iloc[:, i] = value`` which will try to update the existing values in\n",
      " |      place, ``frame.isetitem(loc, value)`` will not update the values of the column\n",
      " |      itself in place, it will instead insert a new array.\n",
      " |\n",
      " |      In cases where ``frame.columns`` is unique, this is equivalent to\n",
      " |      ``frame[frame.columns[i]] = value``.\n",
      " |\n",
      " |  isin(self, values: 'Series | DataFrame | Sequence | Mapping') -> 'DataFrame'\n",
      " |      Whether each element in the DataFrame is contained in values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : iterable, Series, DataFrame or dict\n",
      " |          The result will only be true at a location if all the\n",
      " |          labels match. If `values` is a Series, that's the index. If\n",
      " |          `values` is a dict, the keys must be the column names,\n",
      " |          which must match. If `values` is a DataFrame,\n",
      " |          then both the index and column labels must match.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame of booleans showing whether each element in the DataFrame\n",
      " |          is contained in values.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq: Equality test for DataFrame.\n",
      " |      Series.isin: Equivalent method on Series.\n",
      " |      Series.str.contains: Test if pattern or regex is contained within a\n",
      " |          string of a Series or Index.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},\n",
      " |      ...                   index=['falcon', 'dog'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings\n",
      " |      falcon         2          2\n",
      " |      dog            4          0\n",
      " |\n",
      " |      When ``values`` is a list check whether every value in the DataFrame\n",
      " |      is present in the list (which animals have 0 or 2 legs or wings)\n",
      " |\n",
      " |      >>> df.isin([0, 2])\n",
      " |              num_legs  num_wings\n",
      " |      falcon      True       True\n",
      " |      dog        False       True\n",
      " |\n",
      " |      To check if ``values`` is *not* in the DataFrame, use the ``~`` operator:\n",
      " |\n",
      " |      >>> ~df.isin([0, 2])\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False      False\n",
      " |      dog         True      False\n",
      " |\n",
      " |      When ``values`` is a dict, we can pass values to check for each\n",
      " |      column separately:\n",
      " |\n",
      " |      >>> df.isin({'num_wings': [0, 3]})\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False      False\n",
      " |      dog        False       True\n",
      " |\n",
      " |      When ``values`` is a Series or DataFrame the index and column must\n",
      " |      match. Note that 'falcon' does not match based on the number of legs\n",
      " |      in other.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'num_legs': [8, 3], 'num_wings': [0, 2]},\n",
      " |      ...                      index=['spider', 'falcon'])\n",
      " |      >>> df.isin(other)\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False       True\n",
      " |      dog        False      False\n",
      " |\n",
      " |  isna(self) -> 'DataFrame'\n",
      " |      Detect missing values.\n",
      " |\n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is an NA value.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : Alias of isna.\n",
      " |      DataFrame.notna : Boolean inverse of isna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |\n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n",
      " |      ...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                              pd.Timestamp('1940-04-25')],\n",
      " |      ...                        name=['Alfred', 'Batman', ''],\n",
      " |      ...                        toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |\n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |\n",
      " |      Show which entries in a Series are NA.\n",
      " |\n",
      " |      >>> ser = pd.Series([5, 6, np.nan])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |\n",
      " |  isnull(self) -> 'DataFrame'\n",
      " |      DataFrame.isnull is an alias for DataFrame.isna.\n",
      " |\n",
      " |      Detect missing values.\n",
      " |\n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is an NA value.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : Alias of isna.\n",
      " |      DataFrame.notna : Boolean inverse of isna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |\n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n",
      " |      ...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                              pd.Timestamp('1940-04-25')],\n",
      " |      ...                        name=['Alfred', 'Batman', ''],\n",
      " |      ...                        toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |\n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |\n",
      " |      Show which entries in a Series are NA.\n",
      " |\n",
      " |      >>> ser = pd.Series([5, 6, np.nan])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |\n",
      " |  items(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over (column name, Series) pairs.\n",
      " |\n",
      " |      Iterates over the DataFrame columns, returning a tuple with\n",
      " |      the column name and the content as a Series.\n",
      " |\n",
      " |      Yields\n",
      " |      ------\n",
      " |      label : object\n",
      " |          The column names for the DataFrame being iterated over.\n",
      " |      content : Series\n",
      " |          The column entries belonging to each label, as a Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as\n",
      " |          (index, Series) pairs.\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples\n",
      " |          of the values.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'],\n",
      " |      ...                   'population': [1864, 22000, 80000]},\n",
      " |      ...                   index=['panda', 'polar', 'koala'])\n",
      " |      >>> df\n",
      " |              species   population\n",
      " |      panda   bear      1864\n",
      " |      polar   bear      22000\n",
      " |      koala   marsupial 80000\n",
      " |      >>> for label, content in df.items():\n",
      " |      ...     print(f'label: {label}')\n",
      " |      ...     print(f'content: {content}', sep='\\n')\n",
      " |      ...\n",
      " |      label: species\n",
      " |      content:\n",
      " |      panda         bear\n",
      " |      polar         bear\n",
      " |      koala    marsupial\n",
      " |      Name: species, dtype: object\n",
      " |      label: population\n",
      " |      content:\n",
      " |      panda     1864\n",
      " |      polar    22000\n",
      " |      koala    80000\n",
      " |      Name: population, dtype: int64\n",
      " |\n",
      " |  iterrows(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |\n",
      " |      Yields\n",
      " |      ------\n",
      " |      index : label or tuple of label\n",
      " |          The index of the row. A tuple for a `MultiIndex`.\n",
      " |      data : Series\n",
      " |          The data of the row as a Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      1. Because ``iterrows`` returns a Series for each row,\n",
      " |         it does **not** preserve dtypes across the rows (dtypes are\n",
      " |         preserved across columns for DataFrames).\n",
      " |\n",
      " |         To preserve dtypes while iterating over the rows, it is better\n",
      " |         to use :meth:`itertuples` which returns namedtuples of the values\n",
      " |         and which is generally faster than ``iterrows``.\n",
      " |\n",
      " |      2. You should **never modify** something you are iterating over.\n",
      " |         This is not guaranteed to work in all cases. Depending on the\n",
      " |         data types, the iterator returns a copy and not a view, and writing\n",
      " |         to it will have no effect.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\n",
      " |      >>> row = next(df.iterrows())[1]\n",
      " |      >>> row\n",
      " |      int      1.0\n",
      " |      float    1.5\n",
      " |      Name: 0, dtype: float64\n",
      " |      >>> print(row['int'].dtype)\n",
      " |      float64\n",
      " |      >>> print(df['int'].dtype)\n",
      " |      int64\n",
      " |\n",
      " |  itertuples(self, index: 'bool' = True, name: 'str | None' = 'Pandas') -> 'Iterable[tuple[Any, ...]]'\n",
      " |      Iterate over DataFrame rows as namedtuples.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          If True, return the index as the first element of the tuple.\n",
      " |      name : str or None, default \"Pandas\"\n",
      " |          The name of the returned namedtuples or None to return regular\n",
      " |          tuples.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |          An object to iterate over namedtuples for each row in the\n",
      " |          DataFrame with the first field possibly being the index and\n",
      " |          following fields being the column values.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as (index, Series)\n",
      " |          pairs.\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The column names will be renamed to positional names if they are\n",
      " |      invalid Python identifiers, repeated, or start with an underscore.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]},\n",
      " |      ...                   index=['dog', 'hawk'])\n",
      " |      >>> df\n",
      " |            num_legs  num_wings\n",
      " |      dog          4          0\n",
      " |      hawk         2          2\n",
      " |      >>> for row in df.itertuples():\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(Index='dog', num_legs=4, num_wings=0)\n",
      " |      Pandas(Index='hawk', num_legs=2, num_wings=2)\n",
      " |\n",
      " |      By setting the `index` parameter to False we can remove the index\n",
      " |      as the first element of the tuple:\n",
      " |\n",
      " |      >>> for row in df.itertuples(index=False):\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(num_legs=4, num_wings=0)\n",
      " |      Pandas(num_legs=2, num_wings=2)\n",
      " |\n",
      " |      With the `name` parameter set we set a custom name for the yielded\n",
      " |      namedtuples:\n",
      " |\n",
      " |      >>> for row in df.itertuples(name='Animal'):\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Animal(Index='dog', num_legs=4, num_wings=0)\n",
      " |      Animal(Index='hawk', num_legs=2, num_wings=2)\n",
      " |\n",
      " |  join(self, other: 'DataFrame | Series | Iterable[DataFrame | Series]', on: 'IndexLabel | None' = None, how: 'MergeHow' = 'left', lsuffix: 'str' = '', rsuffix: 'str' = '', sort: 'bool' = False, validate: 'JoinValidate | None' = None) -> 'DataFrame'\n",
      " |      Join columns of another DataFrame.\n",
      " |\n",
      " |      Join columns with `other` DataFrame either on index or on a key\n",
      " |      column. Efficiently join multiple DataFrame objects by index at once by\n",
      " |      passing a list.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series, or a list containing any combination of them\n",
      " |          Index should be similar to one of the columns in this one. If a\n",
      " |          Series is passed, its name attribute must be set, and that will be\n",
      " |          used as the column name in the resulting joined DataFrame.\n",
      " |      on : str, list of str, or array-like, optional\n",
      " |          Column or index level name(s) in the caller to join on the index\n",
      " |          in `other`, otherwise joins index-on-index. If multiple\n",
      " |          values given, the `other` DataFrame must have a MultiIndex. Can\n",
      " |          pass an array as the join key if it is not already contained in\n",
      " |          the calling DataFrame. Like an Excel VLOOKUP operation.\n",
      " |      how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'left'\n",
      " |          How to handle the operation of the two objects.\n",
      " |\n",
      " |          * left: use calling frame's index (or column if on is specified)\n",
      " |          * right: use `other`'s index.\n",
      " |          * outer: form union of calling frame's index (or column if on is\n",
      " |            specified) with `other`'s index, and sort it lexicographically.\n",
      " |          * inner: form intersection of calling frame's index (or column if\n",
      " |            on is specified) with `other`'s index, preserving the order\n",
      " |            of the calling's one.\n",
      " |          * cross: creates the cartesian product from both frames, preserves the order\n",
      " |            of the left keys.\n",
      " |      lsuffix : str, default ''\n",
      " |          Suffix to use from left frame's overlapping columns.\n",
      " |      rsuffix : str, default ''\n",
      " |          Suffix to use from right frame's overlapping columns.\n",
      " |      sort : bool, default False\n",
      " |          Order result DataFrame lexicographically by the join key. If False,\n",
      " |          the order of the join key depends on the join type (how keyword).\n",
      " |      validate : str, optional\n",
      " |          If specified, checks if join is of specified type.\n",
      " |\n",
      " |          * \"one_to_one\" or \"1:1\": check if join keys are unique in both left\n",
      " |            and right datasets.\n",
      " |          * \"one_to_many\" or \"1:m\": check if join keys are unique in left dataset.\n",
      " |          * \"many_to_one\" or \"m:1\": check if join keys are unique in right dataset.\n",
      " |          * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A dataframe containing columns from both the caller and `other`.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.merge : For column(s)-on-column(s) operations.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Parameters `on`, `lsuffix`, and `rsuffix` are not supported when\n",
      " |      passing a list of `DataFrame` objects.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
      " |      ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      " |\n",
      " |      >>> df\n",
      " |        key   A\n",
      " |      0  K0  A0\n",
      " |      1  K1  A1\n",
      " |      2  K2  A2\n",
      " |      3  K3  A3\n",
      " |      4  K4  A4\n",
      " |      5  K5  A5\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
      " |      ...                       'B': ['B0', 'B1', 'B2']})\n",
      " |\n",
      " |      >>> other\n",
      " |        key   B\n",
      " |      0  K0  B0\n",
      " |      1  K1  B1\n",
      " |      2  K2  B2\n",
      " |\n",
      " |      Join DataFrames using their indexes.\n",
      " |\n",
      " |      >>> df.join(other, lsuffix='_caller', rsuffix='_other')\n",
      " |        key_caller   A key_other    B\n",
      " |      0         K0  A0        K0   B0\n",
      " |      1         K1  A1        K1   B1\n",
      " |      2         K2  A2        K2   B2\n",
      " |      3         K3  A3       NaN  NaN\n",
      " |      4         K4  A4       NaN  NaN\n",
      " |      5         K5  A5       NaN  NaN\n",
      " |\n",
      " |      If we want to join using the key columns, we need to set key to be\n",
      " |      the index in both `df` and `other`. The joined DataFrame will have\n",
      " |      key as its index.\n",
      " |\n",
      " |      >>> df.set_index('key').join(other.set_index('key'))\n",
      " |            A    B\n",
      " |      key\n",
      " |      K0   A0   B0\n",
      " |      K1   A1   B1\n",
      " |      K2   A2   B2\n",
      " |      K3   A3  NaN\n",
      " |      K4   A4  NaN\n",
      " |      K5   A5  NaN\n",
      " |\n",
      " |      Another option to join using the key columns is to use the `on`\n",
      " |      parameter. DataFrame.join always uses `other`'s index but we can use\n",
      " |      any column in `df`. This method preserves the original DataFrame's\n",
      " |      index in the result.\n",
      " |\n",
      " |      >>> df.join(other.set_index('key'), on='key')\n",
      " |        key   A    B\n",
      " |      0  K0  A0   B0\n",
      " |      1  K1  A1   B1\n",
      " |      2  K2  A2   B2\n",
      " |      3  K3  A3  NaN\n",
      " |      4  K4  A4  NaN\n",
      " |      5  K5  A5  NaN\n",
      " |\n",
      " |      Using non-unique key values shows how they are matched.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K1', 'K3', 'K0', 'K1'],\n",
      " |      ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      " |\n",
      " |      >>> df\n",
      " |        key   A\n",
      " |      0  K0  A0\n",
      " |      1  K1  A1\n",
      " |      2  K1  A2\n",
      " |      3  K3  A3\n",
      " |      4  K0  A4\n",
      " |      5  K1  A5\n",
      " |\n",
      " |      >>> df.join(other.set_index('key'), on='key', validate='m:1')\n",
      " |        key   A    B\n",
      " |      0  K0  A0   B0\n",
      " |      1  K1  A1   B1\n",
      " |      2  K1  A2   B1\n",
      " |      3  K3  A3  NaN\n",
      " |      4  K0  A4   B0\n",
      " |      5  K1  A5   B1\n",
      " |\n",
      " |  kurt(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis.\n",
      " |\n",
      " |      Kurtosis obtained using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |\n",
      " |                  Examples\n",
      " |                  --------\n",
      " |                  >>> s = pd.Series([1, 2, 2, 3], index=['cat', 'dog', 'dog', 'mouse'])\n",
      " |                  >>> s\n",
      " |                  cat    1\n",
      " |                  dog    2\n",
      " |                  dog    2\n",
      " |                  mouse  3\n",
      " |                  dtype: int64\n",
      " |                  >>> s.kurt()\n",
      " |                  1.5\n",
      " |\n",
      " |                  With a DataFrame\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2, 2, 3], 'b': [3, 4, 4, 4]},\n",
      " |                  ...                   index=['cat', 'dog', 'dog', 'mouse'])\n",
      " |                  >>> df\n",
      " |                         a   b\n",
      " |                    cat  1   3\n",
      " |                    dog  2   4\n",
      " |                    dog  2   4\n",
      " |                  mouse  3   4\n",
      " |                  >>> df.kurt()\n",
      " |                  a   1.5\n",
      " |                  b   4.0\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  With axis=None\n",
      " |\n",
      " |                  >>> df.kurt(axis=None).round(6)\n",
      " |                  -0.988693\n",
      " |\n",
      " |                  Using axis=1\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': [3, 4], 'c': [3, 4], 'd': [1, 2]},\n",
      " |                  ...                   index=['cat', 'dog'])\n",
      " |                  >>> df.kurt(axis=1)\n",
      " |                  cat   -6.0\n",
      " |                  dog   -6.0\n",
      " |                  dtype: float64\n",
      " |\n",
      " |  kurtosis = kurt(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |\n",
      " |  le(self, other, axis: 'Axis' = 'columns', level=None) -> 'DataFrame'\n",
      " |      Get Less than or equal to of dataframe and other, element-wise (binary operator `le`).\n",
      " |\n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |\n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |\n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |\n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |\n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |\n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |\n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |\n",
      " |      Use the method to control the broadcast axis:\n",
      " |\n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |\n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |\n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |\n",
      " |      Use the method to control the axis:\n",
      " |\n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |\n",
      " |      Compare to a DataFrame of different shape.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |\n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |\n",
      " |      Compare to a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |\n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |\n",
      " |  lt(self, other, axis: 'Axis' = 'columns', level=None) -> 'DataFrame'\n",
      " |      Get Less than of dataframe and other, element-wise (binary operator `lt`).\n",
      " |\n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |\n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |\n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |\n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |\n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |\n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |\n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |\n",
      " |      Use the method to control the broadcast axis:\n",
      " |\n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |\n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |\n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |\n",
      " |      Use the method to control the axis:\n",
      " |\n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |\n",
      " |      Compare to a DataFrame of different shape.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |\n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |\n",
      " |      Compare to a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |\n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |\n",
      " |  map(self, func: 'PythonFuncType', na_action: 'str | None' = None, **kwargs) -> 'DataFrame'\n",
      " |      Apply a function to a Dataframe elementwise.\n",
      " |\n",
      " |      .. versionadded:: 2.1.0\n",
      " |\n",
      " |         DataFrame.applymap was deprecated and renamed to DataFrame.map.\n",
      " |\n",
      " |      This method applies a function that accepts and returns a scalar\n",
      " |      to every element of a DataFrame.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          Python function, returns a single value from a single value.\n",
      " |      na_action : {None, 'ignore'}, default None\n",
      " |          If 'ignore', propagate NaN values, without passing them to func.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Transformed DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.replace: Replace values given in `to_replace` with `value`.\n",
      " |      Series.map : Apply a function elementwise on a Series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
      " |      >>> df\n",
      " |             0      1\n",
      " |      0  1.000  2.120\n",
      " |      1  3.356  4.567\n",
      " |\n",
      " |      >>> df.map(lambda x: len(str(x)))\n",
      " |         0  1\n",
      " |      0  3  4\n",
      " |      1  5  5\n",
      " |\n",
      " |      Like Series.map, NA values can be ignored:\n",
      " |\n",
      " |      >>> df_copy = df.copy()\n",
      " |      >>> df_copy.iloc[0, 0] = pd.NA\n",
      " |      >>> df_copy.map(lambda x: len(str(x)), na_action='ignore')\n",
      " |           0  1\n",
      " |      0  NaN  4\n",
      " |      1  5.0  5\n",
      " |\n",
      " |      It is also possible to use `map` with functions that are not\n",
      " |      `lambda` functions:\n",
      " |\n",
      " |      >>> df.map(round, ndigits=1)\n",
      " |           0    1\n",
      " |      0  1.0  2.1\n",
      " |      1  3.4  4.6\n",
      " |\n",
      " |      Note that a vectorized version of `func` often exists, which will\n",
      " |      be much faster. You could square each number elementwise.\n",
      " |\n",
      " |      >>> df.map(lambda x: x**2)\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |\n",
      " |      But it's better to avoid map in that case.\n",
      " |\n",
      " |      >>> df ** 2\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |\n",
      " |  max(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return the maximum of the values over the requested axis.\n",
      " |\n",
      " |      If you want the *index* of the maximum, use ``idxmax``. This is the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |\n",
      " |      >>> s.max()\n",
      " |      8\n",
      " |\n",
      " |  mean(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return the mean of the values over the requested axis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |\n",
      " |                  Examples\n",
      " |                  --------\n",
      " |                  >>> s = pd.Series([1, 2, 3])\n",
      " |                  >>> s.mean()\n",
      " |                  2.0\n",
      " |\n",
      " |                  With a DataFrame\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])\n",
      " |                  >>> df\n",
      " |                         a   b\n",
      " |                  tiger  1   2\n",
      " |                  zebra  2   3\n",
      " |                  >>> df.mean()\n",
      " |                  a   1.5\n",
      " |                  b   2.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  Using axis=1\n",
      " |\n",
      " |                  >>> df.mean(axis=1)\n",
      " |                  tiger   1.5\n",
      " |                  zebra   2.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  In this case, `numeric_only` should be set to `True` to avoid\n",
      " |                  getting an error.\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},\n",
      " |                  ...                   index=['tiger', 'zebra'])\n",
      " |                  >>> df.mean(numeric_only=True)\n",
      " |                  a   1.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |  median(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return the median of the values over the requested axis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |\n",
      " |                  Examples\n",
      " |                  --------\n",
      " |                  >>> s = pd.Series([1, 2, 3])\n",
      " |                  >>> s.median()\n",
      " |                  2.0\n",
      " |\n",
      " |                  With a DataFrame\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])\n",
      " |                  >>> df\n",
      " |                         a   b\n",
      " |                  tiger  1   2\n",
      " |                  zebra  2   3\n",
      " |                  >>> df.median()\n",
      " |                  a   1.5\n",
      " |                  b   2.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  Using axis=1\n",
      " |\n",
      " |                  >>> df.median(axis=1)\n",
      " |                  tiger   1.5\n",
      " |                  zebra   2.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  In this case, `numeric_only` should be set to `True`\n",
      " |                  to avoid getting an error.\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},\n",
      " |                  ...                   index=['tiger', 'zebra'])\n",
      " |                  >>> df.median(numeric_only=True)\n",
      " |                  a   1.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |  melt(self, id_vars=None, value_vars=None, var_name=None, value_name: 'Hashable' = 'value', col_level: 'Level | None' = None, ignore_index: 'bool' = True) -> 'DataFrame'\n",
      " |      Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.\n",
      " |\n",
      " |      This function is useful to massage a DataFrame into a format where one\n",
      " |      or more columns are identifier variables (`id_vars`), while all other\n",
      " |      columns, considered measured variables (`value_vars`), are \"unpivoted\" to\n",
      " |      the row axis, leaving just two non-identifier columns, 'variable' and\n",
      " |      'value'.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      id_vars : scalar, tuple, list, or ndarray, optional\n",
      " |          Column(s) to use as identifier variables.\n",
      " |      value_vars : scalar, tuple, list, or ndarray, optional\n",
      " |          Column(s) to unpivot. If not specified, uses all columns that\n",
      " |          are not set as `id_vars`.\n",
      " |      var_name : scalar, default None\n",
      " |          Name to use for the 'variable' column. If None it uses\n",
      " |          ``frame.columns.name`` or 'variable'.\n",
      " |      value_name : scalar, default 'value'\n",
      " |          Name to use for the 'value' column, can't be an existing column label.\n",
      " |      col_level : scalar, optional\n",
      " |          If columns are a MultiIndex then use this level to melt.\n",
      " |      ignore_index : bool, default True\n",
      " |          If True, original index is ignored. If False, the original index is retained.\n",
      " |          Index labels will be repeated as necessary.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Unpivoted DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      melt : Identical method.\n",
      " |      pivot_table : Create a spreadsheet-style pivot table as a DataFrame.\n",
      " |      DataFrame.pivot : Return reshaped DataFrame organized\n",
      " |          by given index / column values.\n",
      " |      DataFrame.explode : Explode a DataFrame from list-like\n",
      " |              columns to long format.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.melt>` for more examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n",
      " |      ...                    'B': {0: 1, 1: 3, 2: 5},\n",
      " |      ...                    'C': {0: 2, 1: 4, 2: 6}})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |\n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |\n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      3  a        C      2\n",
      " |      4  b        C      4\n",
      " |      5  c        C      6\n",
      " |\n",
      " |      The names of 'variable' and 'value' columns can be customized:\n",
      " |\n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'],\n",
      " |      ...         var_name='myVarname', value_name='myValname')\n",
      " |         A myVarname  myValname\n",
      " |      0  a         B          1\n",
      " |      1  b         B          3\n",
      " |      2  c         B          5\n",
      " |\n",
      " |      Original index values can be kept around:\n",
      " |\n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      0  a        C      2\n",
      " |      1  b        C      4\n",
      " |      2  c        C      6\n",
      " |\n",
      " |      If you have multi-index columns:\n",
      " |\n",
      " |      >>> df.columns = [list('ABC'), list('DEF')]\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |         D  E  F\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |\n",
      " |      >>> df.melt(col_level=0, id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |\n",
      " |      >>> df.melt(id_vars=[('A', 'D')], value_vars=[('B', 'E')])\n",
      " |        (A, D) variable_0 variable_1  value\n",
      " |      0      a          B          E      1\n",
      " |      1      b          B          E      3\n",
      " |      2      c          B          E      5\n",
      " |\n",
      " |  memory_usage(self, index: 'bool' = True, deep: 'bool' = False) -> 'Series'\n",
      " |      Return the memory usage of each column in bytes.\n",
      " |\n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and elements of `object` dtype.\n",
      " |\n",
      " |      This value is displayed in `DataFrame.info` by default. This can be\n",
      " |      suppressed by setting ``pandas.options.display.memory_usage`` to False.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the DataFrame's\n",
      " |          index in returned Series. If ``index=True``, the memory usage of\n",
      " |          the index is the first item in the output.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned values.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A Series whose index is the original column names and whose values\n",
      " |          is the memory usage of each column in bytes.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of an\n",
      " |          ndarray.\n",
      " |      Series.memory_usage : Bytes consumed by a Series.\n",
      " |      Categorical : Memory-efficient array for string values with\n",
      " |          many repeated values.\n",
      " |      DataFrame.info : Concise summary of a DataFrame.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the :ref:`Frequently Asked Questions <df-memory-usage>` for more\n",
      " |      details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']\n",
      " |      >>> data = dict([(t, np.ones(shape=5000, dtype=int).astype(t))\n",
      " |      ...              for t in dtypes])\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df.head()\n",
      " |         int64  float64            complex128  object  bool\n",
      " |      0      1      1.0              1.0+0.0j       1  True\n",
      " |      1      1      1.0              1.0+0.0j       1  True\n",
      " |      2      1      1.0              1.0+0.0j       1  True\n",
      " |      3      1      1.0              1.0+0.0j       1  True\n",
      " |      4      1      1.0              1.0+0.0j       1  True\n",
      " |\n",
      " |      >>> df.memory_usage()\n",
      " |      Index           128\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df.memory_usage(index=False)\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |\n",
      " |      The memory footprint of `object` dtype columns is ignored by default:\n",
      " |\n",
      " |      >>> df.memory_usage(deep=True)\n",
      " |      Index            128\n",
      " |      int64          40000\n",
      " |      float64        40000\n",
      " |      complex128     80000\n",
      " |      object        180000\n",
      " |      bool            5000\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Use a Categorical for efficient storage of an object-dtype column with\n",
      " |      many repeated values.\n",
      " |\n",
      " |      >>> df['object'].astype('category').memory_usage(deep=True)\n",
      " |      5244\n",
      " |\n",
      " |  merge(self, right: 'DataFrame | Series', how: 'MergeHow' = 'inner', on: 'IndexLabel | AnyArrayLike | None' = None, left_on: 'IndexLabel | AnyArrayLike | None' = None, right_on: 'IndexLabel | AnyArrayLike | None' = None, left_index: 'bool' = False, right_index: 'bool' = False, sort: 'bool' = False, suffixes: 'Suffixes' = ('_x', '_y'), copy: 'bool | None' = None, indicator: 'str | bool' = False, validate: 'MergeValidate | None' = None) -> 'DataFrame'\n",
      " |      Merge DataFrame or named Series objects with a database-style join.\n",
      " |\n",
      " |      A named Series object is treated as a DataFrame with a single named column.\n",
      " |\n",
      " |      The join is done on columns or indexes. If joining columns on\n",
      " |      columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
      " |      on indexes or indexes on a column or columns, the index will be passed on.\n",
      " |      When performing a cross merge, no column specifications to merge on are\n",
      " |      allowed.\n",
      " |\n",
      " |      .. warning::\n",
      " |\n",
      " |          If both key columns contain rows where the key is a null value, those\n",
      " |          rows will be matched against each other. This is different from usual SQL\n",
      " |          join behaviour and can lead to unexpected results.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : DataFrame or named Series\n",
      " |          Object to merge with.\n",
      " |      how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'inner'\n",
      " |          Type of merge to be performed.\n",
      " |\n",
      " |          * left: use only keys from left frame, similar to a SQL left outer join;\n",
      " |            preserve key order.\n",
      " |          * right: use only keys from right frame, similar to a SQL right outer join;\n",
      " |            preserve key order.\n",
      " |          * outer: use union of keys from both frames, similar to a SQL full outer\n",
      " |            join; sort keys lexicographically.\n",
      " |          * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      " |            join; preserve the order of the left keys.\n",
      " |          * cross: creates the cartesian product from both frames, preserves the order\n",
      " |            of the left keys.\n",
      " |      on : label or list\n",
      " |          Column or index level names to join on. These must be found in both\n",
      " |          DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      " |          to the intersection of the columns in both DataFrames.\n",
      " |      left_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the left DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the left DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      right_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the right DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the right DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      left_index : bool, default False\n",
      " |          Use the index from the left DataFrame as the join key(s). If it is a\n",
      " |          MultiIndex, the number of keys in the other DataFrame (either the index\n",
      " |          or a number of columns) must match the number of levels.\n",
      " |      right_index : bool, default False\n",
      " |          Use the index from the right DataFrame as the join key. Same caveats as\n",
      " |          left_index.\n",
      " |      sort : bool, default False\n",
      " |          Sort the join keys lexicographically in the result DataFrame. If False,\n",
      " |          the order of the join keys depends on the join type (how keyword).\n",
      " |      suffixes : list-like, default is (\"_x\", \"_y\")\n",
      " |          A length-2 sequence where each element is optionally a string\n",
      " |          indicating the suffix to add to overlapping column names in\n",
      " |          `left` and `right` respectively. Pass a value of `None` instead\n",
      " |          of a string to indicate that the column name from `left` or\n",
      " |          `right` should be left as-is, with no suffix. At least one of the\n",
      " |          values must not be None.\n",
      " |      copy : bool, default True\n",
      " |          If False, avoid copy if possible.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      indicator : bool or str, default False\n",
      " |          If True, adds a column to the output DataFrame called \"_merge\" with\n",
      " |          information on the source of each row. The column can be given a different\n",
      " |          name by providing a string argument. The column will have a Categorical\n",
      " |          type with the value of \"left_only\" for observations whose merge key only\n",
      " |          appears in the left DataFrame, \"right_only\" for observations\n",
      " |          whose merge key only appears in the right DataFrame, and \"both\"\n",
      " |          if the observation's merge key is found in both DataFrames.\n",
      " |\n",
      " |      validate : str, optional\n",
      " |          If specified, checks if merge is of specified type.\n",
      " |\n",
      " |          * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      " |            left and right datasets.\n",
      " |          * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      " |            dataset.\n",
      " |          * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      " |            dataset.\n",
      " |          * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame of the two merged objects.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_ordered : Merge with optional filling/interpolation.\n",
      " |      merge_asof : Merge on nearest keys.\n",
      " |      DataFrame.join : Similar method using indices.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
      " |      ...                     'value': [1, 2, 3, 5]})\n",
      " |      >>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
      " |      ...                     'value': [5, 6, 7, 8]})\n",
      " |      >>> df1\n",
      " |          lkey value\n",
      " |      0   foo      1\n",
      " |      1   bar      2\n",
      " |      2   baz      3\n",
      " |      3   foo      5\n",
      " |      >>> df2\n",
      " |          rkey value\n",
      " |      0   foo      5\n",
      " |      1   bar      6\n",
      " |      2   baz      7\n",
      " |      3   foo      8\n",
      " |\n",
      " |      Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
      " |      the default suffixes, _x and _y, appended.\n",
      " |\n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
      " |        lkey  value_x rkey  value_y\n",
      " |      0  foo        1  foo        5\n",
      " |      1  foo        1  foo        8\n",
      " |      2  bar        2  bar        6\n",
      " |      3  baz        3  baz        7\n",
      " |      4  foo        5  foo        5\n",
      " |      5  foo        5  foo        8\n",
      " |\n",
      " |      Merge DataFrames df1 and df2 with specified left and right suffixes\n",
      " |      appended to any overlapping columns.\n",
      " |\n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
      " |      ...           suffixes=('_left', '_right'))\n",
      " |        lkey  value_left rkey  value_right\n",
      " |      0  foo           1  foo            5\n",
      " |      1  foo           1  foo            8\n",
      " |      2  bar           2  bar            6\n",
      " |      3  baz           3  baz            7\n",
      " |      4  foo           5  foo            5\n",
      " |      5  foo           5  foo            8\n",
      " |\n",
      " |      Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
      " |      any overlapping columns.\n",
      " |\n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: columns overlap but no suffix specified:\n",
      " |          Index(['value'], dtype='object')\n",
      " |\n",
      " |      >>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\n",
      " |      >>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\n",
      " |      >>> df1\n",
      " |            a  b\n",
      " |      0   foo  1\n",
      " |      1   bar  2\n",
      " |      >>> df2\n",
      " |            a  c\n",
      " |      0   foo  3\n",
      " |      1   baz  4\n",
      " |\n",
      " |      >>> df1.merge(df2, how='inner', on='a')\n",
      " |            a  b  c\n",
      " |      0   foo  1  3\n",
      " |\n",
      " |      >>> df1.merge(df2, how='left', on='a')\n",
      " |            a  b  c\n",
      " |      0   foo  1  3.0\n",
      " |      1   bar  2  NaN\n",
      " |\n",
      " |      >>> df1 = pd.DataFrame({'left': ['foo', 'bar']})\n",
      " |      >>> df2 = pd.DataFrame({'right': [7, 8]})\n",
      " |      >>> df1\n",
      " |          left\n",
      " |      0   foo\n",
      " |      1   bar\n",
      " |      >>> df2\n",
      " |          right\n",
      " |      0   7\n",
      " |      1   8\n",
      " |\n",
      " |      >>> df1.merge(df2, how='cross')\n",
      " |         left  right\n",
      " |      0   foo      7\n",
      " |      1   foo      8\n",
      " |      2   bar      7\n",
      " |      3   bar      8\n",
      " |\n",
      " |  min(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return the minimum of the values over the requested axis.\n",
      " |\n",
      " |      If you want the *index* of the minimum, use ``idxmin``. This is the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |\n",
      " |      >>> s.min()\n",
      " |      0\n",
      " |\n",
      " |  mod(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Modulo of dataframe and other, element-wise (binary operator `mod`).\n",
      " |\n",
      " |      Equivalent to ``dataframe % other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rmod`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  mode(self, axis: 'Axis' = 0, numeric_only: 'bool' = False, dropna: 'bool' = True) -> 'DataFrame'\n",
      " |      Get the mode(s) of each element along the selected axis.\n",
      " |\n",
      " |      The mode of a set of values is the value that appears most often.\n",
      " |      It can be multiple values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to iterate over while searching for the mode:\n",
      " |\n",
      " |          * 0 or 'index' : get mode of each column\n",
      " |          * 1 or 'columns' : get mode of each row.\n",
      " |\n",
      " |      numeric_only : bool, default False\n",
      " |          If True, only apply to numeric columns.\n",
      " |      dropna : bool, default True\n",
      " |          Don't consider counts of NaN/NaT.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The modes of each column or row.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.mode : Return the highest frequency value in a Series.\n",
      " |      Series.value_counts : Return the counts of values in a Series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird', 2, 2),\n",
      " |      ...                    ('mammal', 4, np.nan),\n",
      " |      ...                    ('arthropod', 8, 0),\n",
      " |      ...                    ('bird', 2, np.nan)],\n",
      " |      ...                   index=('falcon', 'horse', 'spider', 'ostrich'),\n",
      " |      ...                   columns=('species', 'legs', 'wings'))\n",
      " |      >>> df\n",
      " |                 species  legs  wings\n",
      " |      falcon        bird     2    2.0\n",
      " |      horse       mammal     4    NaN\n",
      " |      spider   arthropod     8    0.0\n",
      " |      ostrich       bird     2    NaN\n",
      " |\n",
      " |      By default, missing values are not considered, and the mode of wings\n",
      " |      are both 0 and 2. Because the resulting DataFrame has two rows,\n",
      " |      the second row of ``species`` and ``legs`` contains ``NaN``.\n",
      " |\n",
      " |      >>> df.mode()\n",
      " |        species  legs  wings\n",
      " |      0    bird   2.0    0.0\n",
      " |      1     NaN   NaN    2.0\n",
      " |\n",
      " |      Setting ``dropna=False`` ``NaN`` values are considered and they can be\n",
      " |      the mode (like for wings).\n",
      " |\n",
      " |      >>> df.mode(dropna=False)\n",
      " |        species  legs  wings\n",
      " |      0    bird     2    NaN\n",
      " |\n",
      " |      Setting ``numeric_only=True``, only the mode of numeric columns is\n",
      " |      computed, and columns of other types are ignored.\n",
      " |\n",
      " |      >>> df.mode(numeric_only=True)\n",
      " |         legs  wings\n",
      " |      0   2.0    0.0\n",
      " |      1   NaN    2.0\n",
      " |\n",
      " |      To compute the mode over columns and not rows, use the axis parameter:\n",
      " |\n",
      " |      >>> df.mode(axis='columns', numeric_only=True)\n",
      " |                 0    1\n",
      " |      falcon   2.0  NaN\n",
      " |      horse    4.0  NaN\n",
      " |      spider   0.0  8.0\n",
      " |      ostrich  2.0  NaN\n",
      " |\n",
      " |  mul(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Multiplication of dataframe and other, element-wise (binary operator `mul`).\n",
      " |\n",
      " |      Equivalent to ``dataframe * other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rmul`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  multiply = mul(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  ne(self, other, axis: 'Axis' = 'columns', level=None) -> 'DataFrame'\n",
      " |      Get Not equal to of dataframe and other, element-wise (binary operator `ne`).\n",
      " |\n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |\n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |\n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |\n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |\n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |\n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |\n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |\n",
      " |      Use the method to control the broadcast axis:\n",
      " |\n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |\n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |\n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |\n",
      " |      Use the method to control the axis:\n",
      " |\n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |\n",
      " |      Compare to a DataFrame of different shape.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |\n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |\n",
      " |      Compare to a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |\n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |\n",
      " |  nlargest(self, n: 'int', columns: 'IndexLabel', keep: 'NsmallestNlargestKeep' = 'first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in descending order.\n",
      " |\n",
      " |      Return the first `n` rows with the largest values in `columns`, in\n",
      " |      descending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |\n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=False).head(n)``, but more\n",
      " |      performant.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of rows to return.\n",
      " |      columns : label or list of labels\n",
      " |          Column label(s) to order by.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |\n",
      " |          - ``first`` : prioritize the first occurrence(s)\n",
      " |          - ``last`` : prioritize the last occurrence(s)\n",
      " |          - ``all`` : keep all the ties of the smallest item even if it means\n",
      " |            selecting more than ``n`` items.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The first `n` rows ordered by the given columns in descending\n",
      " |          order.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nsmallest : Return the first `n` rows ordered by `columns` in\n",
      " |          ascending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values.\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function cannot be used with all column types. For example, when\n",
      " |      specifying columns with `object` or `category` dtypes, ``TypeError`` is\n",
      " |      raised.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n",
      " |      ...                                   434000, 434000, 337000, 11300,\n",
      " |      ...                                   11300, 11300],\n",
      " |      ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n",
      " |      ...                            17036, 182, 38, 311],\n",
      " |      ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n",
      " |      ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n",
      " |      ...                   index=[\"Italy\", \"France\", \"Malta\",\n",
      " |      ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n",
      " |      ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n",
      " |      >>> df\n",
      " |                population      GDP alpha-2\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      France      65000000  2583560      FR\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      Iceland       337000    17036      IS\n",
      " |      Nauru          11300      182      NR\n",
      " |      Tuvalu         11300       38      TV\n",
      " |      Anguilla       11300      311      AI\n",
      " |\n",
      " |      In the following example, we will use ``nlargest`` to select the three\n",
      " |      rows having the largest values in column \"population\".\n",
      " |\n",
      " |      >>> df.nlargest(3, 'population')\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Malta       434000    12011      MT\n",
      " |\n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |\n",
      " |      >>> df.nlargest(3, 'population', keep='last')\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Brunei      434000    12128      BN\n",
      " |\n",
      " |      When using ``keep='all'``, the number of element kept can go beyond ``n``\n",
      " |      if there are duplicate values for the smallest element, all the\n",
      " |      ties are kept:\n",
      " |\n",
      " |      >>> df.nlargest(3, 'population', keep='all')\n",
      " |                population      GDP alpha-2\n",
      " |      France      65000000  2583560      FR\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |\n",
      " |      However, ``nlargest`` does not keep ``n`` distinct largest elements:\n",
      " |\n",
      " |      >>> df.nlargest(5, 'population', keep='all')\n",
      " |                population      GDP alpha-2\n",
      " |      France      65000000  2583560      FR\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |\n",
      " |      To order by the largest values in column \"population\" and then \"GDP\",\n",
      " |      we can specify multiple columns like in the next example.\n",
      " |\n",
      " |      >>> df.nlargest(3, ['population', 'GDP'])\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Brunei      434000    12128      BN\n",
      " |\n",
      " |  notna(self) -> 'DataFrame'\n",
      " |      Detect existing (non-missing) values.\n",
      " |\n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : Alias of notna.\n",
      " |      DataFrame.isna : Boolean inverse of notna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |\n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n",
      " |      ...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                              pd.Timestamp('1940-04-25')],\n",
      " |      ...                        name=['Alfred', 'Batman', ''],\n",
      " |      ...                        toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |\n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |\n",
      " |      Show which entries in a Series are not NA.\n",
      " |\n",
      " |      >>> ser = pd.Series([5, 6, np.nan])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |  notnull(self) -> 'DataFrame'\n",
      " |      DataFrame.notnull is an alias for DataFrame.notna.\n",
      " |\n",
      " |      Detect existing (non-missing) values.\n",
      " |\n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : Alias of notna.\n",
      " |      DataFrame.isna : Boolean inverse of notna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |\n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n",
      " |      ...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                              pd.Timestamp('1940-04-25')],\n",
      " |      ...                        name=['Alfred', 'Batman', ''],\n",
      " |      ...                        toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |\n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |\n",
      " |      Show which entries in a Series are not NA.\n",
      " |\n",
      " |      >>> ser = pd.Series([5, 6, np.nan])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |  nsmallest(self, n: 'int', columns: 'IndexLabel', keep: 'NsmallestNlargestKeep' = 'first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in ascending order.\n",
      " |\n",
      " |      Return the first `n` rows with the smallest values in `columns`, in\n",
      " |      ascending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |\n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=True).head(n)``, but more\n",
      " |      performant.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of items to retrieve.\n",
      " |      columns : list or str\n",
      " |          Column name or names to order by.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |          - ``all`` : keep all the ties of the largest item even if it means\n",
      " |            selecting more than ``n`` items.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nlargest : Return the first `n` rows ordered by `columns` in\n",
      " |          descending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values.\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n",
      " |      ...                                   434000, 434000, 337000, 337000,\n",
      " |      ...                                   11300, 11300],\n",
      " |      ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n",
      " |      ...                            17036, 182, 38, 311],\n",
      " |      ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n",
      " |      ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n",
      " |      ...                   index=[\"Italy\", \"France\", \"Malta\",\n",
      " |      ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n",
      " |      ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n",
      " |      >>> df\n",
      " |                population      GDP alpha-2\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      France      65000000  2583560      FR\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      Iceland       337000    17036      IS\n",
      " |      Nauru         337000      182      NR\n",
      " |      Tuvalu         11300       38      TV\n",
      " |      Anguilla       11300      311      AI\n",
      " |\n",
      " |      In the following example, we will use ``nsmallest`` to select the\n",
      " |      three rows having the smallest values in column \"population\".\n",
      " |\n",
      " |      >>> df.nsmallest(3, 'population')\n",
      " |                population    GDP alpha-2\n",
      " |      Tuvalu         11300     38      TV\n",
      " |      Anguilla       11300    311      AI\n",
      " |      Iceland       337000  17036      IS\n",
      " |\n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |\n",
      " |      >>> df.nsmallest(3, 'population', keep='last')\n",
      " |                population  GDP alpha-2\n",
      " |      Anguilla       11300  311      AI\n",
      " |      Tuvalu         11300   38      TV\n",
      " |      Nauru         337000  182      NR\n",
      " |\n",
      " |      When using ``keep='all'``, the number of element kept can go beyond ``n``\n",
      " |      if there are duplicate values for the largest element, all the\n",
      " |      ties are kept.\n",
      " |\n",
      " |      >>> df.nsmallest(3, 'population', keep='all')\n",
      " |                population    GDP alpha-2\n",
      " |      Tuvalu         11300     38      TV\n",
      " |      Anguilla       11300    311      AI\n",
      " |      Iceland       337000  17036      IS\n",
      " |      Nauru         337000    182      NR\n",
      " |\n",
      " |      However, ``nsmallest`` does not keep ``n`` distinct\n",
      " |      smallest elements:\n",
      " |\n",
      " |      >>> df.nsmallest(4, 'population', keep='all')\n",
      " |                population    GDP alpha-2\n",
      " |      Tuvalu         11300     38      TV\n",
      " |      Anguilla       11300    311      AI\n",
      " |      Iceland       337000  17036      IS\n",
      " |      Nauru         337000    182      NR\n",
      " |\n",
      " |      To order by the smallest values in column \"population\" and then \"GDP\", we can\n",
      " |      specify multiple columns like in the next example.\n",
      " |\n",
      " |      >>> df.nsmallest(3, ['population', 'GDP'])\n",
      " |                population  GDP alpha-2\n",
      " |      Tuvalu         11300   38      TV\n",
      " |      Anguilla       11300  311      AI\n",
      " |      Nauru         337000  182      NR\n",
      " |\n",
      " |  nunique(self, axis: 'Axis' = 0, dropna: 'bool' = True) -> 'Series'\n",
      " |      Count number of distinct elements in specified axis.\n",
      " |\n",
      " |      Return Series with number of distinct elements. Can ignore NaN\n",
      " |      values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for\n",
      " |          column-wise.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nunique: Method nunique for Series.\n",
      " |      DataFrame.count: Count non-NA cells for each column or row.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [4, 5, 6], 'B': [4, 1, 1]})\n",
      " |      >>> df.nunique()\n",
      " |      A    3\n",
      " |      B    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df.nunique(axis=1)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |  pivot(self, *, columns, index=<no_default>, values=<no_default>) -> 'DataFrame'\n",
      " |      Return reshaped DataFrame organized by given index / column values.\n",
      " |\n",
      " |      Reshape data (produce a \"pivot\" table) based on column values. Uses\n",
      " |      unique values from specified `index` / `columns` to form axes of the\n",
      " |      resulting DataFrame. This function does not support data\n",
      " |      aggregation, multiple values will result in a MultiIndex in the\n",
      " |      columns. See the :ref:`User Guide <reshaping>` for more on reshaping.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns : str or object or a list of str\n",
      " |          Column to use to make new frame's columns.\n",
      " |      index : str or object or a list of str, optional\n",
      " |          Column to use to make new frame's index. If not given, uses existing index.\n",
      " |      values : str, object or a list of the previous, optional\n",
      " |          Column(s) to use for populating new frame's values. If not\n",
      " |          specified, all remaining columns will be used and the result will\n",
      " |          have hierarchically indexed columns.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Returns reshaped DataFrame.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError:\n",
      " |          When there are any `index`, `columns` combinations with multiple\n",
      " |          values. `DataFrame.pivot_table` when you need to aggregate.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot_table : Generalization of pivot that can handle\n",
      " |          duplicate values for one index/column pair.\n",
      " |      DataFrame.unstack : Pivot based on the index values instead of a\n",
      " |          column.\n",
      " |      wide_to_long : Wide panel to long format. Less flexible but more\n",
      " |          user-friendly than melt.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      For finer-tuned control, see hierarchical indexing documentation along\n",
      " |      with the related stack/unstack methods.\n",
      " |\n",
      " |      Reference :ref:`the user guide <reshaping.pivot>` for more examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n",
      " |      ...                            'two'],\n",
      " |      ...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
      " |      ...                    'baz': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\n",
      " |      >>> df\n",
      " |          foo   bar  baz  zoo\n",
      " |      0   one   A    1    x\n",
      " |      1   one   B    2    y\n",
      " |      2   one   C    3    z\n",
      " |      3   two   A    4    q\n",
      " |      4   two   B    5    w\n",
      " |      5   two   C    6    t\n",
      " |\n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |\n",
      " |      >>> df.pivot(index='foo', columns='bar')['baz']\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |\n",
      " |      >>> df.pivot(index='foo', columns='bar', values=['baz', 'zoo'])\n",
      " |            baz       zoo\n",
      " |      bar   A  B  C   A  B  C\n",
      " |      foo\n",
      " |      one   1  2  3   x  y  z\n",
      " |      two   4  5  6   q  w  t\n",
      " |\n",
      " |      You could also assign a list of column names or a list of index names.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...        \"lev1\": [1, 1, 1, 2, 2, 2],\n",
      " |      ...        \"lev2\": [1, 1, 2, 1, 1, 2],\n",
      " |      ...        \"lev3\": [1, 2, 1, 2, 1, 2],\n",
      " |      ...        \"lev4\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...        \"values\": [0, 1, 2, 3, 4, 5]})\n",
      " |      >>> df\n",
      " |          lev1 lev2 lev3 lev4 values\n",
      " |      0   1    1    1    1    0\n",
      " |      1   1    1    2    2    1\n",
      " |      2   1    2    1    3    2\n",
      " |      3   2    1    2    4    3\n",
      " |      4   2    1    1    5    4\n",
      " |      5   2    2    2    6    5\n",
      " |\n",
      " |      >>> df.pivot(index=\"lev1\", columns=[\"lev2\", \"lev3\"], values=\"values\")\n",
      " |      lev2    1         2\n",
      " |      lev3    1    2    1    2\n",
      " |      lev1\n",
      " |      1     0.0  1.0  2.0  NaN\n",
      " |      2     4.0  3.0  NaN  5.0\n",
      " |\n",
      " |      >>> df.pivot(index=[\"lev1\", \"lev2\"], columns=[\"lev3\"], values=\"values\")\n",
      " |            lev3    1    2\n",
      " |      lev1  lev2\n",
      " |         1     1  0.0  1.0\n",
      " |               2  2.0  NaN\n",
      " |         2     1  4.0  3.0\n",
      " |               2  NaN  5.0\n",
      " |\n",
      " |      A ValueError is raised if there are any duplicates.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"foo\": ['one', 'one', 'two', 'two'],\n",
      " |      ...                    \"bar\": ['A', 'A', 'B', 'C'],\n",
      " |      ...                    \"baz\": [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         foo bar  baz\n",
      " |      0  one   A    1\n",
      " |      1  one   A    2\n",
      " |      2  two   B    3\n",
      " |      3  two   C    4\n",
      " |\n",
      " |      Notice that the first two rows are the same for our `index`\n",
      " |      and `columns` arguments.\n",
      " |\n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      Traceback (most recent call last):\n",
      " |         ...\n",
      " |      ValueError: Index contains duplicate entries, cannot reshape\n",
      " |\n",
      " |  pivot_table(self, values=None, index=None, columns=None, aggfunc: 'AggFuncType' = 'mean', fill_value=None, margins: 'bool' = False, dropna: 'bool' = True, margins_name: 'Level' = 'All', observed: 'bool | lib.NoDefault' = <no_default>, sort: 'bool' = True) -> 'DataFrame'\n",
      " |      Create a spreadsheet-style pivot table as a DataFrame.\n",
      " |\n",
      " |      The levels in the pivot table will be stored in MultiIndex objects\n",
      " |      (hierarchical indexes) on the index and columns of the result DataFrame.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : list-like or scalar, optional\n",
      " |          Column or columns to aggregate.\n",
      " |      index : column, Grouper, array, or list of the previous\n",
      " |          Keys to group by on the pivot table index. If a list is passed,\n",
      " |          it can contain any of the other types (except list). If an array is\n",
      " |          passed, it must be the same length as the data and will be used in\n",
      " |          the same manner as column values.\n",
      " |      columns : column, Grouper, array, or list of the previous\n",
      " |          Keys to group by on the pivot table column. If a list is passed,\n",
      " |          it can contain any of the other types (except list). If an array is\n",
      " |          passed, it must be the same length as the data and will be used in\n",
      " |          the same manner as column values.\n",
      " |      aggfunc : function, list of functions, dict, default \"mean\"\n",
      " |          If a list of functions is passed, the resulting pivot table will have\n",
      " |          hierarchical columns whose top level are the function names\n",
      " |          (inferred from the function objects themselves).\n",
      " |          If a dict is passed, the key is column to aggregate and the value is\n",
      " |          function or list of functions. If ``margin=True``, aggfunc will be\n",
      " |          used to calculate the partial aggregates.\n",
      " |      fill_value : scalar, default None\n",
      " |          Value to replace missing values with (in the resulting pivot table,\n",
      " |          after aggregation).\n",
      " |      margins : bool, default False\n",
      " |          If ``margins=True``, special ``All`` columns and rows\n",
      " |          will be added with partial group aggregates across the categories\n",
      " |          on the rows and columns.\n",
      " |      dropna : bool, default True\n",
      " |          Do not include columns whose entries are all NaN. If True,\n",
      " |          rows with a NaN value in any column will be omitted before\n",
      " |          computing margins.\n",
      " |      margins_name : str, default 'All'\n",
      " |          Name of the row / column that will contain the totals\n",
      " |          when margins is True.\n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |\n",
      " |          .. deprecated:: 2.2.0\n",
      " |\n",
      " |              The default value of ``False`` is deprecated and will change to\n",
      " |              ``True`` in a future version of pandas.\n",
      " |\n",
      " |      sort : bool, default True\n",
      " |          Specifies if the result should be sorted.\n",
      " |\n",
      " |          .. versionadded:: 1.3.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          An Excel style pivot table.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot without aggregation that can handle\n",
      " |          non-numeric data.\n",
      " |      DataFrame.melt: Unpivot a DataFrame from wide to long format,\n",
      " |          optionally leaving identifiers set.\n",
      " |      wide_to_long : Wide panel to long format. Less flexible but more\n",
      " |          user-friendly than melt.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.pivot>` for more examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      " |      ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      " |      ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      " |      ...                          \"one\", \"one\", \"two\", \"two\"],\n",
      " |      ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      " |      ...                          \"small\", \"large\", \"small\", \"small\",\n",
      " |      ...                          \"large\"],\n",
      " |      ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
      " |      ...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
      " |      >>> df\n",
      " |           A    B      C  D  E\n",
      " |      0  foo  one  small  1  2\n",
      " |      1  foo  one  large  2  4\n",
      " |      2  foo  one  large  2  5\n",
      " |      3  foo  two  small  3  5\n",
      " |      4  foo  two  small  3  6\n",
      " |      5  bar  one  large  4  6\n",
      " |      6  bar  one  small  5  8\n",
      " |      7  bar  two  small  6  9\n",
      " |      8  bar  two  large  7  9\n",
      " |\n",
      " |      This first example aggregates values by taking the sum.\n",
      " |\n",
      " |      >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                        columns=['C'], aggfunc=\"sum\")\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one    4.0    5.0\n",
      " |          two    7.0    6.0\n",
      " |      foo one    4.0    1.0\n",
      " |          two    NaN    6.0\n",
      " |\n",
      " |      We can also fill missing values using the `fill_value` parameter.\n",
      " |\n",
      " |      >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                        columns=['C'], aggfunc=\"sum\", fill_value=0)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one      4      5\n",
      " |          two      7      6\n",
      " |      foo one      4      1\n",
      " |          two      0      6\n",
      " |\n",
      " |      The next example aggregates by taking the mean across multiple columns.\n",
      " |\n",
      " |      >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                        aggfunc={'D': \"mean\", 'E': \"mean\"})\n",
      " |      >>> table\n",
      " |                      D         E\n",
      " |      A   C\n",
      " |      bar large  5.500000  7.500000\n",
      " |          small  5.500000  8.500000\n",
      " |      foo large  2.000000  4.500000\n",
      " |          small  2.333333  4.333333\n",
      " |\n",
      " |      We can also calculate multiple types of aggregations for any given\n",
      " |      value column.\n",
      " |\n",
      " |      >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                        aggfunc={'D': \"mean\",\n",
      " |      ...                                 'E': [\"min\", \"max\", \"mean\"]})\n",
      " |      >>> table\n",
      " |                        D   E\n",
      " |                     mean max      mean  min\n",
      " |      A   C\n",
      " |      bar large  5.500000   9  7.500000    6\n",
      " |          small  5.500000   9  8.500000    8\n",
      " |      foo large  2.000000   5  4.500000    4\n",
      " |          small  2.333333   6  4.333333    2\n",
      " |\n",
      " |  pop(self, item: 'Hashable') -> 'Series'\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : label\n",
      " |          Label of column to be popped.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=('name', 'class', 'max_speed'))\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |\n",
      " |      >>> df.pop('class')\n",
      " |      0      bird\n",
      " |      1      bird\n",
      " |      2    mammal\n",
      " |      3    mammal\n",
      " |      Name: class, dtype: object\n",
      " |\n",
      " |      >>> df\n",
      " |           name  max_speed\n",
      " |      0  falcon      389.0\n",
      " |      1  parrot       24.0\n",
      " |      2    lion       80.5\n",
      " |      3  monkey        NaN\n",
      " |\n",
      " |  pow(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Exponential power of dataframe and other, element-wise (binary operator `pow`).\n",
      " |\n",
      " |      Equivalent to ``dataframe ** other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rpow`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  prod(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, min_count: 'int' = 0, **kwargs)\n",
      " |      Return the product of the values over the requested axis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          .. warning::\n",
      " |\n",
      " |              The behavior of DataFrame.prod with ``axis=None`` is deprecated,\n",
      " |              in a future version this will reduce over both axes and return a scalar\n",
      " |              To retain the old behavior, pass axis=0 (or do not pass axis).\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |\n",
      " |      >>> pd.Series([], dtype=\"float64\").prod()\n",
      " |      1.0\n",
      " |\n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |\n",
      " |      >>> pd.Series([], dtype=\"float64\").prod(min_count=1)\n",
      " |      nan\n",
      " |\n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |\n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |\n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |\n",
      " |  product = prod(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, min_count: 'int' = 0, **kwargs)\n",
      " |\n",
      " |  quantile(self, q: 'float | AnyArrayLike | Sequence[float]' = 0.5, axis: 'Axis' = 0, numeric_only: 'bool' = False, interpolation: 'QuantileInterpolation' = 'linear', method: \"Literal['single', 'table']\" = 'single') -> 'Series | DataFrame'\n",
      " |      Return values at the given quantile over requested axis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          Value between 0 <= q <= 1, the quantile(s) to compute.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |\n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      method : {'single', 'table'}, default 'single'\n",
      " |          Whether to compute quantiles per-column ('single') or over all columns\n",
      " |          ('table'). When 'table', the only allowed interpolation methods are\n",
      " |          'nearest', 'lower', and 'higher'.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |\n",
      " |          If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.rolling.Rolling.quantile: Rolling quantile.\n",
      " |      numpy.percentile: Numpy function to compute the percentile.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      Name: 0.1, dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |\n",
      " |      Specifying `method='table'` will compute the quantile over all columns.\n",
      " |\n",
      " |      >>> df.quantile(.1, method=\"table\", interpolation=\"nearest\")\n",
      " |      a    1\n",
      " |      b    1\n",
      " |      Name: 0.1, dtype: int64\n",
      " |      >>> df.quantile([.1, .5], method=\"table\", interpolation=\"nearest\")\n",
      " |           a    b\n",
      " |      0.1  1    1\n",
      " |      0.5  3  100\n",
      " |\n",
      " |      Specifying `numeric_only=False` will also compute the quantile of\n",
      " |      datetime and timedelta data.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2],\n",
      " |      ...                    'B': [pd.Timestamp('2010'),\n",
      " |      ...                          pd.Timestamp('2011')],\n",
      " |      ...                    'C': [pd.Timedelta('1 days'),\n",
      " |      ...                          pd.Timedelta('2 days')]})\n",
      " |      >>> df.quantile(0.5, numeric_only=False)\n",
      " |      A                    1.5\n",
      " |      B    2010-07-02 12:00:00\n",
      " |      C        1 days 12:00:00\n",
      " |      Name: 0.5, dtype: object\n",
      " |\n",
      " |  query(self, expr: 'str', *, inplace: 'bool' = False, **kwargs) -> 'DataFrame | None'\n",
      " |      Query the columns of a DataFrame with a boolean expression.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The query string to evaluate.\n",
      " |\n",
      " |          You can refer to variables\n",
      " |          in the environment by prefixing them with an '@' character like\n",
      " |          ``@a + b``.\n",
      " |\n",
      " |          You can refer to column names that are not valid Python variable names\n",
      " |          by surrounding them in backticks. Thus, column names containing spaces\n",
      " |          or punctuations (besides underscores) or starting with digits must be\n",
      " |          surrounded by backticks. (For example, a column named \"Area (cm^2)\" would\n",
      " |          be referenced as ```Area (cm^2)```). Column names which are Python keywords\n",
      " |          (like \"list\", \"for\", \"import\", etc) cannot be used.\n",
      " |\n",
      " |          For example, if one of your columns is called ``a a`` and you want\n",
      " |          to sum it with ``b``, your query should be ```a a` + b``.\n",
      " |\n",
      " |      inplace : bool\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      **kwargs\n",
      " |          See the documentation for :func:`eval` for complete details\n",
      " |          on the keyword arguments accepted by :meth:`DataFrame.query`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame resulting from the provided query expression or\n",
      " |          None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      eval : Evaluate a string describing operations on\n",
      " |          DataFrame columns.\n",
      " |      DataFrame.eval : Evaluate a string describing operations on\n",
      " |          DataFrame columns.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The result of the evaluation of this expression is first passed to\n",
      " |      :attr:`DataFrame.loc` and if that fails because of a\n",
      " |      multidimensional key (e.g., a DataFrame) then the result will be passed\n",
      " |      to :meth:`DataFrame.__getitem__`.\n",
      " |\n",
      " |      This method uses the top-level :func:`eval` function to\n",
      " |      evaluate the passed query.\n",
      " |\n",
      " |      The :meth:`~pandas.DataFrame.query` method uses a slightly\n",
      " |      modified Python syntax by default. For example, the ``&`` and ``|``\n",
      " |      (bitwise) operators have the precedence of their boolean cousins,\n",
      " |      :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\n",
      " |      however the semantics are different.\n",
      " |\n",
      " |      You can change the semantics of the expression by passing the keyword\n",
      " |      argument ``parser='python'``. This enforces the same semantics as\n",
      " |      evaluation in Python space. Likewise, you can pass ``engine='python'``\n",
      " |      to evaluate an expression using Python itself as a backend. This is not\n",
      " |      recommended as it is inefficient compared to using ``numexpr`` as the\n",
      " |      engine.\n",
      " |\n",
      " |      The :attr:`DataFrame.index` and\n",
      " |      :attr:`DataFrame.columns` attributes of the\n",
      " |      :class:`~pandas.DataFrame` instance are placed in the query namespace\n",
      " |      by default, which allows you to treat both the index and columns of the\n",
      " |      frame as a column in the frame.\n",
      " |      The identifier ``index`` is used for the frame index; you can also\n",
      " |      use the name of the index to identify it in a query. Please note that\n",
      " |      Python keywords may not be used as identifiers.\n",
      " |\n",
      " |      For further details and examples see the ``query`` documentation in\n",
      " |      :ref:`indexing <indexing.query>`.\n",
      " |\n",
      " |      *Backtick quoted variables*\n",
      " |\n",
      " |      Backtick quoted variables are parsed as literal Python code and\n",
      " |      are converted internally to a Python valid identifier.\n",
      " |      This can lead to the following problems.\n",
      " |\n",
      " |      During parsing a number of disallowed characters inside the backtick\n",
      " |      quoted string are replaced by strings that are allowed as a Python identifier.\n",
      " |      These characters include all operators in Python, the space character, the\n",
      " |      question mark, the exclamation mark, the dollar sign, and the euro sign.\n",
      " |      For other characters that fall outside the ASCII range (U+0001..U+007F)\n",
      " |      and those that are not further specified in PEP 3131,\n",
      " |      the query parser will raise an error.\n",
      " |      This excludes whitespace different than the space character,\n",
      " |      but also the hashtag (as it is used for comments) and the backtick\n",
      " |      itself (backtick can also not be escaped).\n",
      " |\n",
      " |      In a special case, quotes that make a pair around a backtick can\n",
      " |      confuse the parser.\n",
      " |      For example, ```it's` > `that's``` will raise an error,\n",
      " |      as it forms a quoted string (``'s > `that'``) with a backtick inside.\n",
      " |\n",
      " |      See also the Python documentation about lexical analysis\n",
      " |      (https://docs.python.org/3/reference/lexical_analysis.html)\n",
      " |      in combination with the source code in :mod:`pandas.core.computation.parsing`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6),\n",
      " |      ...                    'B': range(10, 0, -2),\n",
      " |      ...                    'C C': range(10, 5, -1)})\n",
      " |      >>> df\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |      1  2   8    9\n",
      " |      2  3   6    8\n",
      " |      3  4   4    7\n",
      " |      4  5   2    6\n",
      " |      >>> df.query('A > B')\n",
      " |         A  B  C C\n",
      " |      4  5  2    6\n",
      " |\n",
      " |      The previous expression is equivalent to\n",
      " |\n",
      " |      >>> df[df.A > df.B]\n",
      " |         A  B  C C\n",
      " |      4  5  2    6\n",
      " |\n",
      " |      For columns with spaces in their name, you can use backtick quoting.\n",
      " |\n",
      " |      >>> df.query('B == `C C`')\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |\n",
      " |      The previous expression is equivalent to\n",
      " |\n",
      " |      >>> df[df.B == df['C C']]\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |\n",
      " |  radd(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Addition of dataframe and other, element-wise (binary operator `radd`).\n",
      " |\n",
      " |      Equivalent to ``other + dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `add`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  rdiv = rtruediv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  reindex(self, labels=None, *, index=None, columns=None, axis: 'Axis | None' = None, method: 'ReindexMethod | None' = None, copy: 'bool | None' = None, level: 'Level | None' = None, fill_value: 'Scalar | None' = nan, limit: 'int | None' = None, tolerance=None) -> 'DataFrame'\n",
      " |      Conform DataFrame to new index with optional filling logic.\n",
      " |\n",
      " |      Places NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      ``copy=False``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |\n",
      " |      labels : array-like, optional\n",
      " |          New labels / index to conform the axis specified by 'axis' to.\n",
      " |      index : array-like, optional\n",
      " |          New labels for the index. Preferably an Index object to avoid\n",
      " |          duplicating data.\n",
      " |      columns : array-like, optional\n",
      " |          New labels for the columns. Preferably an Index object to avoid\n",
      " |          duplicating data.\n",
      " |      axis : int or str, optional\n",
      " |          Axis to target. Can be either the axis name ('index', 'columns')\n",
      " |          or number (0, 1).\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |\n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: Propagate last valid observation forward to next\n",
      " |            valid.\n",
      " |          * backfill / bfill: Use next valid observation to fill gap.\n",
      " |          * nearest: Use nearest valid observations to fill gap.\n",
      " |\n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : scalar, default np.nan\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |\n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with changed index.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |\n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |\n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |\n",
      " |      Create a dataframe with some fictional data.\n",
      " |\n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n",
      " |      ...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |\n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |\n",
      " |      >>> new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...              'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |\n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |\n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |\n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |\n",
      " |      We can also reindex the columns.\n",
      " |\n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |\n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |\n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |\n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |\n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |\n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |\n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |\n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |\n",
      " |      For example, to back-propagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |\n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29   100.0\n",
      " |      2009-12-30   100.0\n",
      " |      2009-12-31   100.0\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |\n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |\n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |\n",
      " |  rename(self, mapper: 'Renamer | None' = None, *, index: 'Renamer | None' = None, columns: 'Renamer | None' = None, axis: 'Axis | None' = None, copy: 'bool | None' = None, inplace: 'bool' = False, level: 'Level | None' = None, errors: 'IgnoreRaise' = 'ignore') -> 'DataFrame | None'\n",
      " |      Rename columns or index labels.\n",
      " |\n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |\n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : dict-like or function\n",
      " |          Dict-like or function transformations to apply to\n",
      " |          that axis' values. Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index`` and\n",
      " |          ``columns``.\n",
      " |      index : dict-like or function\n",
      " |          Alternative to specifying axis (``mapper, axis=0``\n",
      " |          is equivalent to ``index=mapper``).\n",
      " |      columns : dict-like or function\n",
      " |          Alternative to specifying axis (``mapper, axis=1``\n",
      " |          is equivalent to ``columns=mapper``).\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to target with ``mapper``. Can be either the axis name\n",
      " |          ('index', 'columns') or number (0, 1). The default is 'index'.\n",
      " |      copy : bool, default True\n",
      " |          Also copy underlying data.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |          If True then value of copy is ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of a MultiIndex, only rename labels in the specified\n",
      " |          level.\n",
      " |      errors : {'ignore', 'raise'}, default 'ignore'\n",
      " |          If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,\n",
      " |          or `columns` contains labels that are not present in the Index\n",
      " |          being transformed.\n",
      " |          If 'ignore', existing keys will be renamed and extra keys will be\n",
      " |          ignored.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with the renamed axis labels or None if ``inplace=True``.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any of the labels is not found in the selected axis and\n",
      " |          \"errors='raise'\".\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename_axis : Set the name of the axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.rename`` supports two calling conventions\n",
      " |\n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |\n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |\n",
      " |      Rename columns using a mapping:\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n",
      " |         a  c\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |\n",
      " |      Rename index using a mapping:\n",
      " |\n",
      " |      >>> df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\n",
      " |         A  B\n",
      " |      x  1  4\n",
      " |      y  2  5\n",
      " |      z  3  6\n",
      " |\n",
      " |      Cast index labels to a different type:\n",
      " |\n",
      " |      >>> df.index\n",
      " |      RangeIndex(start=0, stop=3, step=1)\n",
      " |      >>> df.rename(index=str).index\n",
      " |      Index(['0', '1', '2'], dtype='object')\n",
      " |\n",
      " |      >>> df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"}, errors=\"raise\")\n",
      " |      Traceback (most recent call last):\n",
      " |      KeyError: ['C'] not found in axis\n",
      " |\n",
      " |      Using axis-style parameters:\n",
      " |\n",
      " |      >>> df.rename(str.lower, axis='columns')\n",
      " |         a  b\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |\n",
      " |      >>> df.rename({1: 2, 2: 4}, axis='index')\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      2  2  5\n",
      " |      4  3  6\n",
      " |\n",
      " |  reorder_levels(self, order: 'Sequence[int | str]', axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      Rearrange index levels using input order. May not drop or duplicate levels.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int or list of str\n",
      " |          List representing new level order. Reference level by number\n",
      " |          (position) or by key (label).\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Where to reorder levels.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {\n",
      " |      ...     \"class\": [\"Mammals\", \"Mammals\", \"Reptiles\"],\n",
      " |      ...     \"diet\": [\"Omnivore\", \"Carnivore\", \"Carnivore\"],\n",
      " |      ...     \"species\": [\"Humans\", \"Dogs\", \"Snakes\"],\n",
      " |      ... }\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"class\", \"diet\", \"species\"])\n",
      " |      >>> df = df.set_index([\"class\", \"diet\"])\n",
      " |      >>> df\n",
      " |                                        species\n",
      " |      class      diet\n",
      " |      Mammals    Omnivore                Humans\n",
      " |                 Carnivore                 Dogs\n",
      " |      Reptiles   Carnivore               Snakes\n",
      " |\n",
      " |      Let's reorder the levels of the index:\n",
      " |\n",
      " |      >>> df.reorder_levels([\"diet\", \"class\"])\n",
      " |                                        species\n",
      " |      diet      class\n",
      " |      Omnivore  Mammals                  Humans\n",
      " |      Carnivore Mammals                    Dogs\n",
      " |                Reptiles                 Snakes\n",
      " |\n",
      " |  reset_index(self, level: 'IndexLabel | None' = None, *, drop: 'bool' = False, inplace: 'bool' = False, col_level: 'Hashable' = 0, col_fill: 'Hashable' = '', allow_duplicates: 'bool | lib.NoDefault' = <no_default>, names: 'Hashable | Sequence[Hashable] | None' = None) -> 'DataFrame | None'\n",
      " |      Reset the index, or a level of it.\n",
      " |\n",
      " |      Reset the index of the DataFrame, and use the default one instead.\n",
      " |      If the DataFrame has a MultiIndex, this method can remove one or more\n",
      " |      levels.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default None\n",
      " |          Only remove the given levels from the index. Removes all levels by\n",
      " |          default.\n",
      " |      drop : bool, default False\n",
      " |          Do not try to insert index into dataframe columns. This resets\n",
      " |          the index to the default integer index.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      col_level : int or str, default 0\n",
      " |          If the columns have multiple levels, determines which level the\n",
      " |          labels are inserted into. By default it is inserted into the first\n",
      " |          level.\n",
      " |      col_fill : object, default ''\n",
      " |          If the columns have multiple levels, determines how the other\n",
      " |          levels are named. If None then the index name is repeated.\n",
      " |      allow_duplicates : bool, optional, default lib.no_default\n",
      " |          Allow duplicate column labels to be created.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |      names : int, str or 1-dimensional list, default None\n",
      " |          Using the given string, rename the DataFrame column which contains the\n",
      " |          index data. If the DataFrame has a MultiIndex, this has to be a list or\n",
      " |          tuple with length equal to the number of levels.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with the new index or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Opposite of reset_index.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird', 389.0),\n",
      " |      ...                    ('bird', 24.0),\n",
      " |      ...                    ('mammal', 80.5),\n",
      " |      ...                    ('mammal', np.nan)],\n",
      " |      ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n",
      " |      ...                   columns=('class', 'max_speed'))\n",
      " |      >>> df\n",
      " |               class  max_speed\n",
      " |      falcon    bird      389.0\n",
      " |      parrot    bird       24.0\n",
      " |      lion    mammal       80.5\n",
      " |      monkey  mammal        NaN\n",
      " |\n",
      " |      When we reset the index, the old index is added as a column, and a\n",
      " |      new sequential index is used:\n",
      " |\n",
      " |      >>> df.reset_index()\n",
      " |          index   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |\n",
      " |      We can use the `drop` parameter to avoid the old index being added as\n",
      " |      a column:\n",
      " |\n",
      " |      >>> df.reset_index(drop=True)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      1    bird       24.0\n",
      " |      2  mammal       80.5\n",
      " |      3  mammal        NaN\n",
      " |\n",
      " |      You can also use `reset_index` with `MultiIndex`.\n",
      " |\n",
      " |      >>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),\n",
      " |      ...                                    ('bird', 'parrot'),\n",
      " |      ...                                    ('mammal', 'lion'),\n",
      " |      ...                                    ('mammal', 'monkey')],\n",
      " |      ...                                   names=['class', 'name'])\n",
      " |      >>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),\n",
      " |      ...                                      ('species', 'type')])\n",
      " |      >>> df = pd.DataFrame([(389.0, 'fly'),\n",
      " |      ...                    (24.0, 'fly'),\n",
      " |      ...                    (80.5, 'run'),\n",
      " |      ...                    (np.nan, 'jump')],\n",
      " |      ...                   index=index,\n",
      " |      ...                   columns=columns)\n",
      " |      >>> df\n",
      " |                     speed species\n",
      " |                       max    type\n",
      " |      class  name\n",
      " |      bird   falcon  389.0     fly\n",
      " |             parrot   24.0     fly\n",
      " |      mammal lion     80.5     run\n",
      " |             monkey    NaN    jump\n",
      " |\n",
      " |      Using the `names` parameter, choose a name for the index column:\n",
      " |\n",
      " |      >>> df.reset_index(names=['classes', 'names'])\n",
      " |        classes   names  speed species\n",
      " |                           max    type\n",
      " |      0    bird  falcon  389.0     fly\n",
      " |      1    bird  parrot   24.0     fly\n",
      " |      2  mammal    lion   80.5     run\n",
      " |      3  mammal  monkey    NaN    jump\n",
      " |\n",
      " |      If the index has multiple levels, we can reset a subset of them:\n",
      " |\n",
      " |      >>> df.reset_index(level='class')\n",
      " |               class  speed species\n",
      " |                        max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |\n",
      " |      If we are not dropping the index, by default, it is placed in the top\n",
      " |      level. We can place it in another level:\n",
      " |\n",
      " |      >>> df.reset_index(level='class', col_level=1)\n",
      " |                      speed species\n",
      " |               class    max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |\n",
      " |      When the index is inserted under another level, we can specify under\n",
      " |      which one with the parameter `col_fill`:\n",
      " |\n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='species')\n",
      " |                    species  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |\n",
      " |      If we specify a nonexistent level for `col_fill`, it is created:\n",
      " |\n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='genus')\n",
      " |                      genus  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |\n",
      " |  rfloordiv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Integer division of dataframe and other, element-wise (binary operator `rfloordiv`).\n",
      " |\n",
      " |      Equivalent to ``other // dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `floordiv`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  rmod(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Modulo of dataframe and other, element-wise (binary operator `rmod`).\n",
      " |\n",
      " |      Equivalent to ``other % dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `mod`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  rmul(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Multiplication of dataframe and other, element-wise (binary operator `rmul`).\n",
      " |\n",
      " |      Equivalent to ``other * dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `mul`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  round(self, decimals: 'int | dict[IndexLabel, int] | Series' = 0, *args, **kwargs) -> 'DataFrame'\n",
      " |      Round a DataFrame to a variable number of decimal places.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int, dict, Series\n",
      " |          Number of decimal places to round each column to. If an int is\n",
      " |          given, round each column to the same number of places.\n",
      " |          Otherwise dict and Series round to variable numbers of places.\n",
      " |          Column names should be in the keys if `decimals` is a\n",
      " |          dict-like, or in the index if `decimals` is a Series. Any\n",
      " |          columns not included in `decimals` will be left as is. Elements\n",
      " |          of `decimals` which are not columns of the input will be\n",
      " |          ignored.\n",
      " |      *args\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame with the affected columns rounded to the specified\n",
      " |          number of decimal places.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around : Round a numpy array to the given number of decimals.\n",
      " |      Series.round : Round a Series to the given number of decimals.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df\n",
      " |          dogs  cats\n",
      " |      0  0.21  0.32\n",
      " |      1  0.01  0.67\n",
      " |      2  0.66  0.03\n",
      " |      3  0.21  0.18\n",
      " |\n",
      " |      By providing an integer each column is rounded to the same number\n",
      " |      of decimal places\n",
      " |\n",
      " |      >>> df.round(1)\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.3\n",
      " |      1   0.0   0.7\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.2\n",
      " |\n",
      " |      With a dict, the number of places for specific columns can be\n",
      " |      specified with the column names as key and the number of decimal\n",
      " |      places as value\n",
      " |\n",
      " |      >>> df.round({'dogs': 1, 'cats': 0})\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.0\n",
      " |      1   0.0   1.0\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.0\n",
      " |\n",
      " |      Using a Series, the number of places for specific columns can be\n",
      " |      specified with the column names as index and the number of\n",
      " |      decimal places as value\n",
      " |\n",
      " |      >>> decimals = pd.Series([0, 1], index=['cats', 'dogs'])\n",
      " |      >>> df.round(decimals)\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.0\n",
      " |      1   0.0   1.0\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.0\n",
      " |\n",
      " |  rpow(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Exponential power of dataframe and other, element-wise (binary operator `rpow`).\n",
      " |\n",
      " |      Equivalent to ``other ** dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `pow`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  rsub(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Subtraction of dataframe and other, element-wise (binary operator `rsub`).\n",
      " |\n",
      " |      Equivalent to ``other - dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `sub`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  rtruediv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Floating division of dataframe and other, element-wise (binary operator `rtruediv`).\n",
      " |\n",
      " |      Equivalent to ``other / dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `truediv`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  select_dtypes(self, include=None, exclude=None) -> 'Self'\n",
      " |      Return a subset of the DataFrame's columns based on the column dtypes.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      include, exclude : scalar or list-like\n",
      " |          A selection of dtypes or strings to be included/excluded. At least\n",
      " |          one of these parameters must be supplied.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The subset of the frame including the dtypes in ``include`` and\n",
      " |          excluding the dtypes in ``exclude``.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If both of ``include`` and ``exclude`` are empty\n",
      " |          * If ``include`` and ``exclude`` have overlapping elements\n",
      " |          * If any kind of string dtype is passed in.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.dtypes: Return Series with the data type of each column.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      * To select all *numeric* types, use ``np.number`` or ``'number'``\n",
      " |      * To select strings you must use the ``object`` dtype, but note that\n",
      " |        this will return *all* object dtype columns. With\n",
      " |        ``pd.options.future.infer_string`` enabled, using ``\"str\"`` will\n",
      " |        work to select all string columns.\n",
      " |      * See the `numpy dtype hierarchy\n",
      " |        <https://numpy.org/doc/stable/reference/arrays.scalars.html>`__\n",
      " |      * To select datetimes, use ``np.datetime64``, ``'datetime'`` or\n",
      " |        ``'datetime64'``\n",
      " |      * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or\n",
      " |        ``'timedelta64'``\n",
      " |      * To select Pandas categorical dtypes, use ``'category'``\n",
      " |      * To select Pandas datetimetz dtypes, use ``'datetimetz'``\n",
      " |        or ``'datetime64[ns, tz]'``\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 2] * 3,\n",
      " |      ...                    'b': [True, False] * 3,\n",
      " |      ...                    'c': [1.0, 2.0] * 3})\n",
      " |      >>> df\n",
      " |              a      b  c\n",
      " |      0       1   True  1.0\n",
      " |      1       2  False  2.0\n",
      " |      2       1   True  1.0\n",
      " |      3       2  False  2.0\n",
      " |      4       1   True  1.0\n",
      " |      5       2  False  2.0\n",
      " |\n",
      " |      >>> df.select_dtypes(include='bool')\n",
      " |         b\n",
      " |      0  True\n",
      " |      1  False\n",
      " |      2  True\n",
      " |      3  False\n",
      " |      4  True\n",
      " |      5  False\n",
      " |\n",
      " |      >>> df.select_dtypes(include=['float64'])\n",
      " |         c\n",
      " |      0  1.0\n",
      " |      1  2.0\n",
      " |      2  1.0\n",
      " |      3  2.0\n",
      " |      4  1.0\n",
      " |      5  2.0\n",
      " |\n",
      " |      >>> df.select_dtypes(exclude=['int64'])\n",
      " |             b    c\n",
      " |      0   True  1.0\n",
      " |      1  False  2.0\n",
      " |      2   True  1.0\n",
      " |      3  False  2.0\n",
      " |      4   True  1.0\n",
      " |      5  False  2.0\n",
      " |\n",
      " |  sem(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, ddof: 'int' = 1, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |\n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          .. warning::\n",
      " |\n",
      " |              The behavior of DataFrame.sem with ``axis=None`` is deprecated,\n",
      " |              in a future version this will reduce over both axes and return a scalar\n",
      " |              To retain the old behavior, pass axis=0 (or do not pass axis).\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |\n",
      " |                  Examples\n",
      " |                  --------\n",
      " |                  >>> s = pd.Series([1, 2, 3])\n",
      " |                  >>> s.sem().round(6)\n",
      " |                  0.57735\n",
      " |\n",
      " |                  With a DataFrame\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])\n",
      " |                  >>> df\n",
      " |                         a   b\n",
      " |                  tiger  1   2\n",
      " |                  zebra  2   3\n",
      " |                  >>> df.sem()\n",
      " |                  a   0.5\n",
      " |                  b   0.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  Using axis=1\n",
      " |\n",
      " |                  >>> df.sem(axis=1)\n",
      " |                  tiger   0.5\n",
      " |                  zebra   0.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  In this case, `numeric_only` should be set to `True`\n",
      " |                  to avoid getting an error.\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},\n",
      " |                  ...                   index=['tiger', 'zebra'])\n",
      " |                  >>> df.sem(numeric_only=True)\n",
      " |                  a   0.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |  set_axis(self, labels, *, axis: 'Axis' = 0, copy: 'bool | None' = None) -> 'DataFrame'\n",
      " |      Assign desired index to given axis.\n",
      " |\n",
      " |      Indexes for column or row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows. For `Series`\n",
      " |          this parameter is unused and defaults to 0.\n",
      " |\n",
      " |      copy : bool, default True\n",
      " |          Whether to make a copy of the underlying data.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          An object of type DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename_axis : Alter the name of the index or columns.\n",
      " |\n",
      " |              Examples\n",
      " |              --------\n",
      " |              >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |\n",
      " |              Change the row labels.\n",
      " |\n",
      " |              >>> df.set_axis(['a', 'b', 'c'], axis='index')\n",
      " |                 A  B\n",
      " |              a  1  4\n",
      " |              b  2  5\n",
      " |              c  3  6\n",
      " |\n",
      " |              Change the column labels.\n",
      " |\n",
      " |              >>> df.set_axis(['I', 'II'], axis='columns')\n",
      " |                 I  II\n",
      " |              0  1   4\n",
      " |              1  2   5\n",
      " |              2  3   6\n",
      " |\n",
      " |  set_index(self, keys, *, drop: 'bool' = True, append: 'bool' = False, inplace: 'bool' = False, verify_integrity: 'bool' = False) -> 'DataFrame | None'\n",
      " |      Set the DataFrame index using existing columns.\n",
      " |\n",
      " |      Set the DataFrame index (row labels) using one or more existing\n",
      " |      columns or arrays (of the correct length). The index can replace the\n",
      " |      existing index or expand on it.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keys : label or array-like or list of labels/arrays\n",
      " |          This parameter can be either a single column key, a single array of\n",
      " |          the same length as the calling DataFrame, or a list containing an\n",
      " |          arbitrary combination of column keys and arrays. Here, \"array\"\n",
      " |          encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and\n",
      " |          instances of :class:`~collections.abc.Iterator`.\n",
      " |      drop : bool, default True\n",
      " |          Delete columns to be used as the new index.\n",
      " |      append : bool, default False\n",
      " |          Whether to append columns to existing index.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      verify_integrity : bool, default False\n",
      " |          Check the new index for duplicates. Otherwise defer the check until\n",
      " |          necessary. Setting to False will improve the performance of this\n",
      " |          method.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          Changed row labels or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.reset_index : Opposite of set_index.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'month': [1, 4, 7, 10],\n",
      " |      ...                    'year': [2012, 2014, 2013, 2014],\n",
      " |      ...                    'sale': [55, 40, 84, 31]})\n",
      " |      >>> df\n",
      " |         month  year  sale\n",
      " |      0      1  2012    55\n",
      " |      1      4  2014    40\n",
      " |      2      7  2013    84\n",
      " |      3     10  2014    31\n",
      " |\n",
      " |      Set the index to become the 'month' column:\n",
      " |\n",
      " |      >>> df.set_index('month')\n",
      " |             year  sale\n",
      " |      month\n",
      " |      1      2012    55\n",
      " |      4      2014    40\n",
      " |      7      2013    84\n",
      " |      10     2014    31\n",
      " |\n",
      " |      Create a MultiIndex using columns 'year' and 'month':\n",
      " |\n",
      " |      >>> df.set_index(['year', 'month'])\n",
      " |                  sale\n",
      " |      year  month\n",
      " |      2012  1     55\n",
      " |      2014  4     40\n",
      " |      2013  7     84\n",
      " |      2014  10    31\n",
      " |\n",
      " |      Create a MultiIndex using an Index and a column:\n",
      " |\n",
      " |      >>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])\n",
      " |               month  sale\n",
      " |         year\n",
      " |      1  2012  1      55\n",
      " |      2  2014  4      40\n",
      " |      3  2013  7      84\n",
      " |      4  2014  10     31\n",
      " |\n",
      " |      Create a MultiIndex using two Series:\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> df.set_index([s, s**2])\n",
      " |            month  year  sale\n",
      " |      1 1       1  2012    55\n",
      " |      2 4       4  2014    40\n",
      " |      3 9       7  2013    84\n",
      " |      4 16     10  2014    31\n",
      " |\n",
      " |  shift(self, periods: 'int | Sequence[int]' = 1, freq: 'Frequency | None' = None, axis: 'Axis' = 0, fill_value: 'Hashable' = <no_default>, suffix: 'str | None' = None) -> 'DataFrame'\n",
      " |      Shift index by desired number of periods with an optional time `freq`.\n",
      " |\n",
      " |      When `freq` is not passed, shift the index without realigning the data.\n",
      " |      If `freq` is passed (in this case, the index must be date or datetime,\n",
      " |      or it will raise a `NotImplementedError`), the index will be\n",
      " |      increased using the periods and the `freq`. `freq` can be inferred\n",
      " |      when specified as \"infer\" as long as either freq or inferred_freq\n",
      " |      attribute is set in the index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int or Sequence\n",
      " |          Number of periods to shift. Can be positive or negative.\n",
      " |          If an iterable of ints, the data will be shifted once by each int.\n",
      " |          This is equivalent to shifting by one value at a time and\n",
      " |          concatenating all resulting frames. The resulting columns will have\n",
      " |          the shift suffixed to their column names. For multiple periods,\n",
      " |          axis must not be 1.\n",
      " |      freq : DateOffset, tseries.offsets, timedelta, or str, optional\n",
      " |          Offset to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          If `freq` is specified then the index values are shifted but the\n",
      " |          data is not realigned. That is, use `freq` if you would like to\n",
      " |          extend the index when shifting and preserve the original data.\n",
      " |          If `freq` is specified as \"infer\" then it will be inferred from\n",
      " |          the freq or inferred_freq attributes of the index. If neither of\n",
      " |          those attributes exist, a ValueError is thrown.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Shift direction. For `Series` this parameter is unused and defaults to 0.\n",
      " |      fill_value : object, optional\n",
      " |          The scalar value to use for newly introduced missing values.\n",
      " |          the default depends on the dtype of `self`.\n",
      " |          For numeric data, ``np.nan`` is used.\n",
      " |          For datetime, timedelta, or period data, etc. :attr:`NaT` is used.\n",
      " |          For extension dtypes, ``self.dtype.na_value`` is used.\n",
      " |      suffix : str, optional\n",
      " |          If str and periods is an iterable, this is added after the column\n",
      " |          name and before the shift value for each shifted column name.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Copy of input object, shifted.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.shift : Shift values of Index.\n",
      " |      DatetimeIndex.shift : Shift values of DatetimeIndex.\n",
      " |      PeriodIndex.shift : Shift values of PeriodIndex.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"Col1\": [10, 20, 15, 30, 45],\n",
      " |      ...                    \"Col2\": [13, 23, 18, 33, 48],\n",
      " |      ...                    \"Col3\": [17, 27, 22, 37, 52]},\n",
      " |      ...                   index=pd.date_range(\"2020-01-01\", \"2020-01-05\"))\n",
      " |      >>> df\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01    10    13    17\n",
      " |      2020-01-02    20    23    27\n",
      " |      2020-01-03    15    18    22\n",
      " |      2020-01-04    30    33    37\n",
      " |      2020-01-05    45    48    52\n",
      " |\n",
      " |      >>> df.shift(periods=3)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN   NaN   NaN\n",
      " |      2020-01-02   NaN   NaN   NaN\n",
      " |      2020-01-03   NaN   NaN   NaN\n",
      " |      2020-01-04  10.0  13.0  17.0\n",
      " |      2020-01-05  20.0  23.0  27.0\n",
      " |\n",
      " |      >>> df.shift(periods=1, axis=\"columns\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN    10    13\n",
      " |      2020-01-02   NaN    20    23\n",
      " |      2020-01-03   NaN    15    18\n",
      " |      2020-01-04   NaN    30    33\n",
      " |      2020-01-05   NaN    45    48\n",
      " |\n",
      " |      >>> df.shift(periods=3, fill_value=0)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01     0     0     0\n",
      " |      2020-01-02     0     0     0\n",
      " |      2020-01-03     0     0     0\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |\n",
      " |      >>> df.shift(periods=3, freq=\"D\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |\n",
      " |      >>> df.shift(periods=3, freq=\"infer\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |\n",
      " |      >>> df['Col1'].shift(periods=[0, 1, 2])\n",
      " |                  Col1_0  Col1_1  Col1_2\n",
      " |      2020-01-01      10     NaN     NaN\n",
      " |      2020-01-02      20    10.0     NaN\n",
      " |      2020-01-03      15    20.0    10.0\n",
      " |      2020-01-04      30    15.0    20.0\n",
      " |      2020-01-05      45    30.0    15.0\n",
      " |\n",
      " |  skew(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return unbiased skew over requested axis.\n",
      " |\n",
      " |      Normalized by N-1.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |\n",
      " |                  Examples\n",
      " |                  --------\n",
      " |                  >>> s = pd.Series([1, 2, 3])\n",
      " |                  >>> s.skew()\n",
      " |                  0.0\n",
      " |\n",
      " |                  With a DataFrame\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2, 3], 'b': [2, 3, 4], 'c': [1, 3, 5]},\n",
      " |                  ...                   index=['tiger', 'zebra', 'cow'])\n",
      " |                  >>> df\n",
      " |                          a   b   c\n",
      " |                  tiger   1   2   1\n",
      " |                  zebra   2   3   3\n",
      " |                  cow     3   4   5\n",
      " |                  >>> df.skew()\n",
      " |                  a   0.0\n",
      " |                  b   0.0\n",
      " |                  c   0.0\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  Using axis=1\n",
      " |\n",
      " |                  >>> df.skew(axis=1)\n",
      " |                  tiger   1.732051\n",
      " |                  zebra  -1.732051\n",
      " |                  cow     0.000000\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  In this case, `numeric_only` should be set to `True` to avoid\n",
      " |                  getting an error.\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2, 3], 'b': ['T', 'Z', 'X']},\n",
      " |                  ...                   index=['tiger', 'zebra', 'cow'])\n",
      " |                  >>> df.skew(numeric_only=True)\n",
      " |                  a   0.0\n",
      " |                  dtype: float64\n",
      " |\n",
      " |  sort_index(self, *, axis: 'Axis' = 0, level: 'IndexLabel | None' = None, ascending: 'bool | Sequence[bool]' = True, inplace: 'bool' = False, kind: 'SortKind' = 'quicksort', na_position: 'NaPosition' = 'last', sort_remaining: 'bool' = True, ignore_index: 'bool' = False, key: 'IndexKeyFunc | None' = None) -> 'DataFrame | None'\n",
      " |      Sort object by labels (along an axis).\n",
      " |\n",
      " |      Returns a new DataFrame sorted by label if `inplace` argument is\n",
      " |      ``False``, otherwise updates the original DataFrame and returns None.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis along which to sort.  The value 0 identifies the rows,\n",
      " |          and 1 identifies the columns.\n",
      " |      level : int or level name or list of ints or list of level names\n",
      " |          If not None, sort on values in specified index level(s).\n",
      " |      ascending : bool or list-like of bools, default True\n",
      " |          Sort ascending vs. descending. When the index is a MultiIndex the\n",
      " |          sort direction can be controlled for each level individually.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information. `mergesort` and `stable` are the only stable algorithms. For\n",
      " |          DataFrames, this option is only applied when sorting on a single\n",
      " |          column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |          Puts NaNs at the beginning if `first`; `last` puts NaNs at the end.\n",
      " |          Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          If True and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, , n - 1.\n",
      " |      key : callable, optional\n",
      " |          If not None, apply the key function to the index values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect an\n",
      " |          ``Index`` and return an ``Index`` of the same shape. For MultiIndex\n",
      " |          inputs, the key is applied *per level*.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          The original DataFrame sorted by the labels or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index : Sort Series by the index.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the value.\n",
      " |      Series.sort_values : Sort Series by the value.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df.sort_index()\n",
      " |           A\n",
      " |      1    4\n",
      " |      29   2\n",
      " |      100  1\n",
      " |      150  5\n",
      " |      234  3\n",
      " |\n",
      " |      By default, it sorts in ascending order, to sort in descending order,\n",
      " |      use ``ascending=False``\n",
      " |\n",
      " |      >>> df.sort_index(ascending=False)\n",
      " |           A\n",
      " |      234  3\n",
      " |      150  5\n",
      " |      100  1\n",
      " |      29   2\n",
      " |      1    4\n",
      " |\n",
      " |      A key function can be specified which is applied to the index before\n",
      " |      sorting. For a ``MultiIndex`` this is applied to each level separately.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"a\": [1, 2, 3, 4]}, index=['A', 'b', 'C', 'd'])\n",
      " |      >>> df.sort_index(key=lambda x: x.str.lower())\n",
      " |         a\n",
      " |      A  1\n",
      " |      b  2\n",
      " |      C  3\n",
      " |      d  4\n",
      " |\n",
      " |  sort_values(self, by: 'IndexLabel', *, axis: 'Axis' = 0, ascending: 'bool | list[bool] | tuple[bool, ...]' = True, inplace: 'bool' = False, kind: 'SortKind' = 'quicksort', na_position: 'str' = 'last', ignore_index: 'bool' = False, key: 'ValueKeyFunc | None' = None) -> 'DataFrame | None'\n",
      " |      Sort by the values along either axis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : str or list of str\n",
      " |          Name or list of names to sort by.\n",
      " |\n",
      " |          - if `axis` is 0 or `'index'` then `by` may contain index\n",
      " |            levels and/or column labels.\n",
      " |          - if `axis` is 1 or `'columns'` then `by` may contain column\n",
      " |            levels and/or index labels.\n",
      " |      axis : \"{0 or 'index', 1 or 'columns'}\", default 0\n",
      " |           Axis to be sorted.\n",
      " |      ascending : bool or list of bool, default True\n",
      " |           Sort ascending vs. descending. Specify list for multiple sort\n",
      " |           orders.  If this is a list of bools, must match the length of\n",
      " |           the by.\n",
      " |      inplace : bool, default False\n",
      " |           If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |           information. `mergesort` and `stable` are the only stable algorithms. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           Puts NaNs at the beginning if `first`; `last` puts NaNs at the\n",
      " |           end.\n",
      " |      ignore_index : bool, default False\n",
      " |           If True, the resulting axis will be labeled 0, 1, , n - 1.\n",
      " |      key : callable, optional\n",
      " |          Apply the key function to the values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect a\n",
      " |          ``Series`` and return a Series with the same shape as the input.\n",
      " |          It will be applied to each column in `by` independently.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with sorted values or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index : Sort a DataFrame by the index.\n",
      " |      Series.sort_values : Similar method for a Series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      " |      ...     'col2': [2, 1, 9, 8, 7, 4],\n",
      " |      ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      " |      ...     'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |        col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |\n",
      " |      Sort by col1\n",
      " |\n",
      " |      >>> df.sort_values(by=['col1'])\n",
      " |        col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      5    C     4     3    F\n",
      " |      4    D     7     2    e\n",
      " |      3  NaN     8     4    D\n",
      " |\n",
      " |      Sort by multiple columns\n",
      " |\n",
      " |      >>> df.sort_values(by=['col1', 'col2'])\n",
      " |        col1  col2  col3 col4\n",
      " |      1    A     1     1    B\n",
      " |      0    A     2     0    a\n",
      " |      2    B     9     9    c\n",
      " |      5    C     4     3    F\n",
      " |      4    D     7     2    e\n",
      " |      3  NaN     8     4    D\n",
      " |\n",
      " |      Sort Descending\n",
      " |\n",
      " |      >>> df.sort_values(by='col1', ascending=False)\n",
      " |        col1  col2  col3 col4\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      2    B     9     9    c\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      3  NaN     8     4    D\n",
      " |\n",
      " |      Putting NAs first\n",
      " |\n",
      " |      >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      " |        col1  col2  col3 col4\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      2    B     9     9    c\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |\n",
      " |      Sorting with a key function\n",
      " |\n",
      " |      >>> df.sort_values(by='col4', key=lambda col: col.str.lower())\n",
      " |         col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |\n",
      " |      Natural sort with the key argument,\n",
      " |      using the `natsort <https://github.com/SethMMorton/natsort>` package.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...    \"time\": ['0hr', '128hr', '72hr', '48hr', '96hr'],\n",
      " |      ...    \"value\": [10, 20, 30, 40, 50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          time  value\n",
      " |      0    0hr     10\n",
      " |      1  128hr     20\n",
      " |      2   72hr     30\n",
      " |      3   48hr     40\n",
      " |      4   96hr     50\n",
      " |      >>> from natsort import index_natsorted\n",
      " |      >>> df.sort_values(\n",
      " |      ...     by=\"time\",\n",
      " |      ...     key=lambda x: np.argsort(index_natsorted(df[\"time\"]))\n",
      " |      ... )\n",
      " |          time  value\n",
      " |      0    0hr     10\n",
      " |      3   48hr     40\n",
      " |      2   72hr     30\n",
      " |      4   96hr     50\n",
      " |      1  128hr     20\n",
      " |\n",
      " |  stack(self, level: 'IndexLabel' = -1, dropna: 'bool | lib.NoDefault' = <no_default>, sort: 'bool | lib.NoDefault' = <no_default>, future_stack: 'bool' = False)\n",
      " |      Stack the prescribed level(s) from columns to index.\n",
      " |\n",
      " |      Return a reshaped DataFrame or Series having a multi-level\n",
      " |      index with one or more new inner-most levels compared to the current\n",
      " |      DataFrame. The new inner-most levels are created by pivoting the\n",
      " |      columns of the current dataframe:\n",
      " |\n",
      " |        - if the columns have a single level, the output is a Series;\n",
      " |        - if the columns have multiple levels, the new index\n",
      " |          level(s) is (are) taken from the prescribed level(s) and\n",
      " |          the output is a DataFrame.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, list, default -1\n",
      " |          Level(s) to stack from the column axis onto the index\n",
      " |          axis, defined as one index or label, or a list of indices\n",
      " |          or labels.\n",
      " |      dropna : bool, default True\n",
      " |          Whether to drop rows in the resulting Frame/Series with\n",
      " |          missing values. Stacking a column level onto the index\n",
      " |          axis can create combinations of index and column values\n",
      " |          that are missing from the original dataframe. See Examples\n",
      " |          section.\n",
      " |      sort : bool, default True\n",
      " |          Whether to sort the levels of the resulting MultiIndex.\n",
      " |      future_stack : bool, default False\n",
      " |          Whether to use the new implementation that will replace the current\n",
      " |          implementation in pandas 3.0. When True, dropna and sort have no impact\n",
      " |          on the result and must remain unspecified. See :ref:`pandas 2.1.0 Release\n",
      " |          notes <whatsnew_210.enhancements.new_stack>` for more details.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or Series\n",
      " |          Stacked dataframe or series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Unstack prescribed level(s) from index axis\n",
      " |           onto column axis.\n",
      " |      DataFrame.pivot : Reshape dataframe from long format to wide\n",
      " |           format.\n",
      " |      DataFrame.pivot_table : Create a spreadsheet-style pivot table\n",
      " |           as a DataFrame.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The function is named by analogy with a collection of books\n",
      " |      being reorganized from being side by side on a horizontal\n",
      " |      position (the columns of the dataframe) to being stacked\n",
      " |      vertically on top of each other (in the index of the\n",
      " |      dataframe).\n",
      " |\n",
      " |      Reference :ref:`the user guide <reshaping.stacking>` for more examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Single level columns**\n",
      " |\n",
      " |      >>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=['weight', 'height'])\n",
      " |\n",
      " |      Stacking a dataframe with a single level column axis returns a Series:\n",
      " |\n",
      " |      >>> df_single_level_cols\n",
      " |           weight height\n",
      " |      cat       0      1\n",
      " |      dog       2      3\n",
      " |      >>> df_single_level_cols.stack(future_stack=True)\n",
      " |      cat  weight    0\n",
      " |           height    1\n",
      " |      dog  weight    2\n",
      " |           height    3\n",
      " |      dtype: int64\n",
      " |\n",
      " |      **Multi level columns: simple case**\n",
      " |\n",
      " |      >>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('weight', 'pounds')])\n",
      " |      >>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol1)\n",
      " |\n",
      " |      Stacking a dataframe with a multi-level column axis:\n",
      " |\n",
      " |      >>> df_multi_level_cols1\n",
      " |           weight\n",
      " |               kg    pounds\n",
      " |      cat       1        2\n",
      " |      dog       2        4\n",
      " |      >>> df_multi_level_cols1.stack(future_stack=True)\n",
      " |                  weight\n",
      " |      cat kg           1\n",
      " |          pounds       2\n",
      " |      dog kg           2\n",
      " |          pounds       4\n",
      " |\n",
      " |      **Missing values**\n",
      " |\n",
      " |      >>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('height', 'm')])\n",
      " |      >>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |\n",
      " |      It is common to have missing values when stacking a dataframe\n",
      " |      with multi-level columns, as the stacked dataframe typically\n",
      " |      has more values than the original dataframe. Missing values\n",
      " |      are filled with NaNs:\n",
      " |\n",
      " |      >>> df_multi_level_cols2\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    1.0    2.0\n",
      " |      dog    3.0    4.0\n",
      " |      >>> df_multi_level_cols2.stack(future_stack=True)\n",
      " |              weight  height\n",
      " |      cat kg     1.0     NaN\n",
      " |          m      NaN     2.0\n",
      " |      dog kg     3.0     NaN\n",
      " |          m      NaN     4.0\n",
      " |\n",
      " |      **Prescribing the level(s) to be stacked**\n",
      " |\n",
      " |      The first parameter controls which level or levels are stacked:\n",
      " |\n",
      " |      >>> df_multi_level_cols2.stack(0, future_stack=True)\n",
      " |                   kg    m\n",
      " |      cat weight  1.0  NaN\n",
      " |          height  NaN  2.0\n",
      " |      dog weight  3.0  NaN\n",
      " |          height  NaN  4.0\n",
      " |      >>> df_multi_level_cols2.stack([0, 1], future_stack=True)\n",
      " |      cat  weight  kg    1.0\n",
      " |           height  m     2.0\n",
      " |      dog  weight  kg    3.0\n",
      " |           height  m     4.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |  std(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, ddof: 'int' = 1, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |\n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          .. warning::\n",
      " |\n",
      " |              The behavior of DataFrame.std with ``axis=None`` is deprecated,\n",
      " |              in a future version this will reduce over both axes and return a scalar\n",
      " |              To retain the old behavior, pass axis=0 (or do not pass axis).\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the\n",
      " |      default `ddof=1`)\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n",
      " |      ...                    'age': [21, 25, 62, 43],\n",
      " |      ...                    'height': [1.61, 1.87, 1.49, 2.01]}\n",
      " |      ...                   ).set_index('person_id')\n",
      " |      >>> df\n",
      " |                 age  height\n",
      " |      person_id\n",
      " |      0           21    1.61\n",
      " |      1           25    1.87\n",
      " |      2           62    1.49\n",
      " |      3           43    2.01\n",
      " |\n",
      " |      The standard deviation of the columns can be found as follows:\n",
      " |\n",
      " |      >>> df.std()\n",
      " |      age       18.786076\n",
      " |      height     0.237417\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Alternatively, `ddof=0` can be set to normalize by N instead of N-1:\n",
      " |\n",
      " |      >>> df.std(ddof=0)\n",
      " |      age       16.269219\n",
      " |      height     0.205609\n",
      " |      dtype: float64\n",
      " |\n",
      " |  sub(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Subtraction of dataframe and other, element-wise (binary operator `sub`).\n",
      " |\n",
      " |      Equivalent to ``dataframe - other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rsub`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  subtract = sub(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  sum(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, min_count: 'int' = 0, **kwargs)\n",
      " |      Return the sum of the values over the requested axis.\n",
      " |\n",
      " |      This is equivalent to the method ``numpy.sum``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          .. warning::\n",
      " |\n",
      " |              The behavior of DataFrame.sum with ``axis=None`` is deprecated,\n",
      " |              in a future version this will reduce over both axes and return a scalar\n",
      " |              To retain the old behavior, pass axis=0 (or do not pass axis).\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |\n",
      " |      >>> s.sum()\n",
      " |      14\n",
      " |\n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |\n",
      " |      >>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |\n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |\n",
      " |      >>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
      " |      nan\n",
      " |\n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |\n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |\n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |\n",
      " |  swaplevel(self, i: 'Axis' = -2, j: 'Axis' = -1, axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      Swap levels i and j in a :class:`MultiIndex`.\n",
      " |\n",
      " |      Default is to swap the two innermost levels of the index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int or str\n",
      " |          Levels of the indices to be swapped. Can pass level name as string.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |                  The axis to swap levels on. 0 or 'index' for row-wise, 1 or\n",
      " |                  'columns' for column-wise.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame with levels swapped in MultiIndex.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\"Grade\": [\"A\", \"B\", \"A\", \"C\"]},\n",
      " |      ...     index=[\n",
      " |      ...         [\"Final exam\", \"Final exam\", \"Coursework\", \"Coursework\"],\n",
      " |      ...         [\"History\", \"Geography\", \"History\", \"Geography\"],\n",
      " |      ...         [\"January\", \"February\", \"March\", \"April\"],\n",
      " |      ...     ],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |                                          Grade\n",
      " |      Final exam  History     January      A\n",
      " |                  Geography   February     B\n",
      " |      Coursework  History     March        A\n",
      " |                  Geography   April        C\n",
      " |\n",
      " |      In the following example, we will swap the levels of the indices.\n",
      " |      Here, we will swap the levels column-wise, but levels can be swapped row-wise\n",
      " |      in a similar manner. Note that column-wise is the default behaviour.\n",
      " |      By not supplying any arguments for i and j, we swap the last and second to\n",
      " |      last indices.\n",
      " |\n",
      " |      >>> df.swaplevel()\n",
      " |                                          Grade\n",
      " |      Final exam  January     History         A\n",
      " |                  February    Geography       B\n",
      " |      Coursework  March       History         A\n",
      " |                  April       Geography       C\n",
      " |\n",
      " |      By supplying one argument, we can choose which index to swap the last\n",
      " |      index with. We can for example swap the first index with the last one as\n",
      " |      follows.\n",
      " |\n",
      " |      >>> df.swaplevel(0)\n",
      " |                                          Grade\n",
      " |      January     History     Final exam      A\n",
      " |      February    Geography   Final exam      B\n",
      " |      March       History     Coursework      A\n",
      " |      April       Geography   Coursework      C\n",
      " |\n",
      " |      We can also define explicitly which indices we want to swap by supplying values\n",
      " |      for both i and j. Here, we for example swap the first and second indices.\n",
      " |\n",
      " |      >>> df.swaplevel(0, 1)\n",
      " |                                          Grade\n",
      " |      History     Final exam  January         A\n",
      " |      Geography   Final exam  February        B\n",
      " |      History     Coursework  March           A\n",
      " |      Geography   Coursework  April           C\n",
      " |\n",
      " |  to_dict(self, orient: \"Literal['dict', 'list', 'series', 'split', 'tight', 'records', 'index']\" = 'dict', *, into: 'type[MutableMappingT] | MutableMappingT' = <class 'dict'>, index: 'bool' = True) -> 'MutableMappingT | list[MutableMappingT]'\n",
      " |      Convert the DataFrame to a dictionary.\n",
      " |\n",
      " |      The type of the key-value pairs can be customized with the parameters\n",
      " |      (see below).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      orient : str {'dict', 'list', 'series', 'split', 'tight', 'records', 'index'}\n",
      " |          Determines the type of the values of the dictionary.\n",
      " |\n",
      " |          - 'dict' (default) : dict like {column -> {index -> value}}\n",
      " |          - 'list' : dict like {column -> [values]}\n",
      " |          - 'series' : dict like {column -> Series(values)}\n",
      " |          - 'split' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\n",
      " |          - 'tight' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values],\n",
      " |            'index_names' -> [index.names], 'column_names' -> [column.names]}\n",
      " |          - 'records' : list like\n",
      " |            [{column -> value}, ... , {column -> value}]\n",
      " |          - 'index' : dict like {index -> {column -> value}}\n",
      " |\n",
      " |          .. versionadded:: 1.4.0\n",
      " |              'tight' as an allowed value for the ``orient`` argument\n",
      " |\n",
      " |      into : class, default dict\n",
      " |          The collections.abc.MutableMapping subclass used for all Mappings\n",
      " |          in the return value.  Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |\n",
      " |      index : bool, default True\n",
      " |          Whether to include the index item (and index_names item if `orient`\n",
      " |          is 'tight') in the returned dictionary. Can only be ``False``\n",
      " |          when `orient` is 'split' or 'tight'.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict, list or collections.abc.MutableMapping\n",
      " |          Return a collections.abc.MutableMapping object representing the\n",
      " |          DataFrame. The resulting transformation depends on the `orient`\n",
      " |          parameter.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict: Create a DataFrame from a dictionary.\n",
      " |      DataFrame.to_json: Convert a DataFrame to JSON format.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2],\n",
      " |      ...                    'col2': [0.5, 0.75]},\n",
      " |      ...                   index=['row1', 'row2'])\n",
      " |      >>> df\n",
      " |            col1  col2\n",
      " |      row1     1  0.50\n",
      " |      row2     2  0.75\n",
      " |      >>> df.to_dict()\n",
      " |      {'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}}\n",
      " |\n",
      " |      You can specify the return orientation.\n",
      " |\n",
      " |      >>> df.to_dict('series')\n",
      " |      {'col1': row1    1\n",
      " |               row2    2\n",
      " |      Name: col1, dtype: int64,\n",
      " |      'col2': row1    0.50\n",
      " |              row2    0.75\n",
      " |      Name: col2, dtype: float64}\n",
      " |\n",
      " |      >>> df.to_dict('split')\n",
      " |      {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1, 0.5], [2, 0.75]]}\n",
      " |\n",
      " |      >>> df.to_dict('records')\n",
      " |      [{'col1': 1, 'col2': 0.5}, {'col1': 2, 'col2': 0.75}]\n",
      " |\n",
      " |      >>> df.to_dict('index')\n",
      " |      {'row1': {'col1': 1, 'col2': 0.5}, 'row2': {'col1': 2, 'col2': 0.75}}\n",
      " |\n",
      " |      >>> df.to_dict('tight')\n",
      " |      {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1, 0.5], [2, 0.75]], 'index_names': [None], 'column_names': [None]}\n",
      " |\n",
      " |      You can also specify the mapping type.\n",
      " |\n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> df.to_dict(into=OrderedDict)\n",
      " |      OrderedDict([('col1', OrderedDict([('row1', 1), ('row2', 2)])),\n",
      " |                   ('col2', OrderedDict([('row1', 0.5), ('row2', 0.75)]))])\n",
      " |\n",
      " |      If you want a `defaultdict`, you need to initialize it:\n",
      " |\n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> df.to_dict('records', into=dd)\n",
      " |      [defaultdict(<class 'list'>, {'col1': 1, 'col2': 0.5}),\n",
      " |       defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\n",
      " |\n",
      " |  to_feather(self, path: 'FilePath | WriteBuffer[bytes]', **kwargs) -> 'None'\n",
      " |      Write a DataFrame to the binary Feather format.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, file-like object\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function. If a string or a path,\n",
      " |          it will be used as Root Directory path when writing a partitioned dataset.\n",
      " |      **kwargs :\n",
      " |          Additional keywords passed to :func:`pyarrow.feather.write_feather`.\n",
      " |          This includes the `compression`, `compression_level`, `chunksize`\n",
      " |          and `version` keywords.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function writes the dataframe as a `feather file\n",
      " |      <https://arrow.apache.org/docs/python/feather.html>`_. Requires a default\n",
      " |      index. For saving the DataFrame with your custom index use a method that\n",
      " |      supports custom indices e.g. `to_parquet`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]])\n",
      " |      >>> df.to_feather(\"file.feather\")  # doctest: +SKIP\n",
      " |\n",
      " |  to_gbq(self, destination_table: 'str', *, project_id: 'str | None' = None, chunksize: 'int | None' = None, reauth: 'bool' = False, if_exists: 'ToGbqIfexist' = 'fail', auth_local_webserver: 'bool' = True, table_schema: 'list[dict[str, str]] | None' = None, location: 'str | None' = None, progress_bar: 'bool' = True, credentials=None) -> 'None'\n",
      " |      Write a DataFrame to a Google BigQuery table.\n",
      " |\n",
      " |      .. deprecated:: 2.2.0\n",
      " |\n",
      " |         Please use ``pandas_gbq.to_gbq`` instead.\n",
      " |\n",
      " |      This function requires the `pandas-gbq package\n",
      " |      <https://pandas-gbq.readthedocs.io>`__.\n",
      " |\n",
      " |      See the `How to authenticate with Google BigQuery\n",
      " |      <https://pandas-gbq.readthedocs.io/en/latest/howto/authentication.html>`__\n",
      " |      guide for authentication instructions.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      destination_table : str\n",
      " |          Name of table to be written, in the form ``dataset.tablename``.\n",
      " |      project_id : str, optional\n",
      " |          Google BigQuery Account project ID. Optional when available from\n",
      " |          the environment.\n",
      " |      chunksize : int, optional\n",
      " |          Number of rows to be inserted in each chunk from the dataframe.\n",
      " |          Set to ``None`` to load the whole dataframe at once.\n",
      " |      reauth : bool, default False\n",
      " |          Force Google BigQuery to re-authenticate the user. This is useful\n",
      " |          if multiple accounts are used.\n",
      " |      if_exists : str, default 'fail'\n",
      " |          Behavior when the destination table exists. Value can be one of:\n",
      " |\n",
      " |          ``'fail'``\n",
      " |              If table exists raise pandas_gbq.gbq.TableCreationError.\n",
      " |          ``'replace'``\n",
      " |              If table exists, drop it, recreate it, and insert data.\n",
      " |          ``'append'``\n",
      " |              If table exists, insert data. Create if does not exist.\n",
      " |      auth_local_webserver : bool, default True\n",
      " |          Use the `local webserver flow`_ instead of the `console flow`_\n",
      " |          when getting user credentials.\n",
      " |\n",
      " |          .. _local webserver flow:\n",
      " |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server\n",
      " |          .. _console flow:\n",
      " |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console\n",
      " |\n",
      " |          *New in version 0.2.0 of pandas-gbq*.\n",
      " |\n",
      " |          .. versionchanged:: 1.5.0\n",
      " |             Default value is changed to ``True``. Google has deprecated the\n",
      " |             ``auth_local_webserver = False`` `\"out of band\" (copy-paste)\n",
      " |             flow\n",
      " |             <https://developers.googleblog.com/2022/02/making-oauth-flows-safer.html?m=1#disallowed-oob>`_.\n",
      " |      table_schema : list of dicts, optional\n",
      " |          List of BigQuery table fields to which according DataFrame\n",
      " |          columns conform to, e.g. ``[{'name': 'col1', 'type':\n",
      " |          'STRING'},...]``. If schema is not provided, it will be\n",
      " |          generated according to dtypes of DataFrame columns. See\n",
      " |          BigQuery API documentation on available names of a field.\n",
      " |\n",
      " |          *New in version 0.3.1 of pandas-gbq*.\n",
      " |      location : str, optional\n",
      " |          Location where the load job should run. See the `BigQuery locations\n",
      " |          documentation\n",
      " |          <https://cloud.google.com/bigquery/docs/dataset-locations>`__ for a\n",
      " |          list of available locations. The location must match that of the\n",
      " |          target dataset.\n",
      " |\n",
      " |          *New in version 0.5.0 of pandas-gbq*.\n",
      " |      progress_bar : bool, default True\n",
      " |          Use the library `tqdm` to show the progress bar for the upload,\n",
      " |          chunk by chunk.\n",
      " |\n",
      " |          *New in version 0.5.0 of pandas-gbq*.\n",
      " |      credentials : google.auth.credentials.Credentials, optional\n",
      " |          Credentials for accessing Google APIs. Use this parameter to\n",
      " |          override default credentials, such as to use Compute Engine\n",
      " |          :class:`google.auth.compute_engine.Credentials` or Service\n",
      " |          Account :class:`google.oauth2.service_account.Credentials`\n",
      " |          directly.\n",
      " |\n",
      " |          *New in version 0.8.0 of pandas-gbq*.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas_gbq.to_gbq : This function in the pandas-gbq library.\n",
      " |      read_gbq : Read a DataFrame from Google BigQuery.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Example taken from `Google BigQuery documentation\n",
      " |      <https://cloud.google.com/bigquery/docs/samples/bigquery-pandas-gbq-to-gbq-simple>`_\n",
      " |\n",
      " |      >>> project_id = \"my-project\"\n",
      " |      >>> table_id = 'my_dataset.my_table'\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...                   \"my_string\": [\"a\", \"b\", \"c\"],\n",
      " |      ...                   \"my_int64\": [1, 2, 3],\n",
      " |      ...                   \"my_float64\": [4.0, 5.0, 6.0],\n",
      " |      ...                   \"my_bool1\": [True, False, True],\n",
      " |      ...                   \"my_bool2\": [False, True, False],\n",
      " |      ...                   \"my_dates\": pd.date_range(\"now\", periods=3),\n",
      " |      ...                   }\n",
      " |      ...                   )\n",
      " |\n",
      " |      >>> df.to_gbq(table_id, project_id=project_id)  # doctest: +SKIP\n",
      " |\n",
      " |  to_html(self, buf: 'FilePath | WriteBuffer[str] | None' = None, *, columns: 'Axes | None' = None, col_space: 'ColspaceArgType | None' = None, header: 'bool' = True, index: 'bool' = True, na_rep: 'str' = 'NaN', formatters: 'FormattersType | None' = None, float_format: 'FloatFormatType | None' = None, sparsify: 'bool | None' = None, index_names: 'bool' = True, justify: 'str | None' = None, max_rows: 'int | None' = None, max_cols: 'int | None' = None, show_dimensions: 'bool | str' = False, decimal: 'str' = '.', bold_rows: 'bool' = True, classes: 'str | list | tuple | None' = None, escape: 'bool' = True, notebook: 'bool' = False, border: 'int | bool | None' = None, table_id: 'str | None' = None, render_links: 'bool' = False, encoding: 'str | None' = None) -> 'str | None'\n",
      " |      Render a DataFrame as an HTML table.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : array-like, optional, default None\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : str or int, list or dict of int or str, optional\n",
      " |          The minimum width of each column in CSS length units.  An int is assumed to be px units..\n",
      " |      header : bool, optional\n",
      " |          Whether to print column labels, default True.\n",
      " |      index : bool, optional, default True\n",
      " |          Whether to print index (row) labels.\n",
      " |      na_rep : str, optional, default 'NaN'\n",
      " |          String representation of ``NaN`` to use.\n",
      " |      formatters : list, tuple or dict of one-param. functions, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name.\n",
      " |          The result of each function must be a unicode string.\n",
      " |          List/tuple must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional, default None\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats. This function must return a unicode string and will be\n",
      " |          applied only to the non-``NaN`` elements, with ``NaN`` being\n",
      " |          handled by ``na_rep``.\n",
      " |      sparsify : bool, optional, default True\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row.\n",
      " |      index_names : bool, optional, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |\n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to display in the console.\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to display in the console.\n",
      " |      show_dimensions : bool, default False\n",
      " |          Display DataFrame dimensions (number of rows by number of columns).\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |\n",
      " |      bold_rows : bool, default True\n",
      " |          Make the row labels bold in the output.\n",
      " |      classes : str or list or tuple, default None\n",
      " |          CSS class(es) to apply to the resulting html table.\n",
      " |      escape : bool, default True\n",
      " |          Convert the characters <, >, and & to HTML-safe sequences.\n",
      " |      notebook : {True, False}, default False\n",
      " |          Whether the generated HTML is for IPython Notebook.\n",
      " |      border : int\n",
      " |          A ``border=border`` attribute is included in the opening\n",
      " |          `<table>` tag. Default ``pd.options.display.html.border``.\n",
      " |      table_id : str, optional\n",
      " |          A css id is included in the opening `<table>` tag if specified.\n",
      " |      render_links : bool, default False\n",
      " |          Convert URLs to HTML links.\n",
      " |      encoding : str, default \"utf-8\"\n",
      " |          Set character encoding.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_string : Convert DataFrame to a string.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [4, 3]})\n",
      " |      >>> html_string = '''<table border=\"1\" class=\"dataframe\">\n",
      " |      ...   <thead>\n",
      " |      ...     <tr style=\"text-align: right;\">\n",
      " |      ...       <th></th>\n",
      " |      ...       <th>col1</th>\n",
      " |      ...       <th>col2</th>\n",
      " |      ...     </tr>\n",
      " |      ...   </thead>\n",
      " |      ...   <tbody>\n",
      " |      ...     <tr>\n",
      " |      ...       <th>0</th>\n",
      " |      ...       <td>1</td>\n",
      " |      ...       <td>4</td>\n",
      " |      ...     </tr>\n",
      " |      ...     <tr>\n",
      " |      ...       <th>1</th>\n",
      " |      ...       <td>2</td>\n",
      " |      ...       <td>3</td>\n",
      " |      ...     </tr>\n",
      " |      ...   </tbody>\n",
      " |      ... </table>'''\n",
      " |      >>> assert html_string == df.to_html()\n",
      " |\n",
      " |  to_markdown(self, buf: 'FilePath | WriteBuffer[str] | None' = None, *, mode: 'str' = 'wt', index: 'bool' = True, storage_options: 'StorageOptions | None' = None, **kwargs) -> 'str | None'\n",
      " |      Print DataFrame in Markdown-friendly format.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      mode : str, optional\n",
      " |          Mode in which file is opened, \"wt\" by default.\n",
      " |      index : bool, optional, default True\n",
      " |          Add index (row) labels.\n",
      " |\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to `tabulate                 <https://pypi.org/project/tabulate>`_.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          DataFrame in Markdown-friendly format.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requires the `tabulate <https://pypi.org/project/tabulate>`_ package.\n",
      " |\n",
      " |      Examples\n",
      " |              --------\n",
      " |              >>> df = pd.DataFrame(\n",
      " |              ...     data={\"animal_1\": [\"elk\", \"pig\"], \"animal_2\": [\"dog\", \"quetzal\"]}\n",
      " |              ... )\n",
      " |              >>> print(df.to_markdown())\n",
      " |              |    | animal_1   | animal_2   |\n",
      " |              |---:|:-----------|:-----------|\n",
      " |              |  0 | elk        | dog        |\n",
      " |              |  1 | pig        | quetzal    |\n",
      " |\n",
      " |              Output markdown with a tabulate option.\n",
      " |\n",
      " |              >>> print(df.to_markdown(tablefmt=\"grid\"))\n",
      " |              +----+------------+------------+\n",
      " |              |    | animal_1   | animal_2   |\n",
      " |              +====+============+============+\n",
      " |              |  0 | elk        | dog        |\n",
      " |              +----+------------+------------+\n",
      " |              |  1 | pig        | quetzal    |\n",
      " |              +----+------------+------------+\n",
      " |\n",
      " |  to_numpy(self, dtype: 'npt.DTypeLike | None' = None, copy: 'bool' = False, na_value: 'object' = <no_default>) -> 'np.ndarray'\n",
      " |      Convert the DataFrame to a NumPy array.\n",
      " |\n",
      " |      By default, the dtype of the returned array will be the common NumPy\n",
      " |      dtype of all types in the DataFrame. For example, if the dtypes are\n",
      " |      ``float16`` and ``float32``, the results dtype will be ``float32``.\n",
      " |      This may require copying data and coercing values, which may be\n",
      " |      expensive.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype, optional\n",
      " |          The dtype to pass to :meth:`numpy.asarray`.\n",
      " |      copy : bool, default False\n",
      " |          Whether to ensure that the returned value is not a view on\n",
      " |          another array. Note that ``copy=False`` does not *ensure* that\n",
      " |          ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\n",
      " |          a copy is made, even if not strictly necessary.\n",
      " |      na_value : Any, optional\n",
      " |          The value to use for missing values. The default value depends\n",
      " |          on `dtype` and the dtypes of the DataFrame columns.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.to_numpy : Similar method for Series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()\n",
      " |      array([[1, 3],\n",
      " |             [2, 4]])\n",
      " |\n",
      " |      With heterogeneous data, the lowest common type will have to\n",
      " |      be used.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\n",
      " |      >>> df.to_numpy()\n",
      " |      array([[1. , 3. ],\n",
      " |             [2. , 4.5]])\n",
      " |\n",
      " |      For a mix of numeric and non-numeric types, the output array will\n",
      " |      have object dtype.\n",
      " |\n",
      " |      >>> df['C'] = pd.date_range('2000', periods=2)\n",
      " |      >>> df.to_numpy()\n",
      " |      array([[1, 3.0, Timestamp('2000-01-01 00:00:00')],\n",
      " |             [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object)\n",
      " |\n",
      " |  to_orc(self, path: 'FilePath | WriteBuffer[bytes] | None' = None, *, engine: \"Literal['pyarrow']\" = 'pyarrow', index: 'bool | None' = None, engine_kwargs: 'dict[str, Any] | None' = None) -> 'bytes | None'\n",
      " |      Write a DataFrame to the ORC format.\n",
      " |\n",
      " |      .. versionadded:: 1.5.0\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, file-like object or None, default None\n",
      " |          If a string, it will be used as Root Directory path\n",
      " |          when writing a partitioned dataset. By file-like object,\n",
      " |          we refer to objects with a write() method, such as a file handle\n",
      " |          (e.g. via builtin open function). If path is None,\n",
      " |          a bytes object is returned.\n",
      " |      engine : {'pyarrow'}, default 'pyarrow'\n",
      " |          ORC library to use.\n",
      " |      index : bool, optional\n",
      " |          If ``True``, include the dataframe's index(es) in the file output.\n",
      " |          If ``False``, they will not be written to the file.\n",
      " |          If ``None``, similar to ``infer`` the dataframe's index(es)\n",
      " |          will be saved. However, instead of being saved as values,\n",
      " |          the RangeIndex will be stored as a range in the metadata so it\n",
      " |          doesn't require much space and is faster. Other indexes will\n",
      " |          be included as columns in the file output.\n",
      " |      engine_kwargs : dict[str, Any] or None, default None\n",
      " |          Additional keyword arguments passed to :func:`pyarrow.orc.write_table`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bytes if no path argument is provided else None\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          Dtype of one or more columns is category, unsigned integers, interval,\n",
      " |          period or sparse.\n",
      " |      ValueError\n",
      " |          engine is not pyarrow.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_orc : Read a ORC file.\n",
      " |      DataFrame.to_parquet : Write a parquet file.\n",
      " |      DataFrame.to_csv : Write a csv file.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_hdf : Write to hdf.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Before using this function you should read the :ref:`user guide about\n",
      " |        ORC <io.orc>` and :ref:`install optional dependencies <install.warn_orc>`.\n",
      " |      * This function requires `pyarrow <https://arrow.apache.org/docs/python/>`_\n",
      " |        library.\n",
      " |      * For supported dtypes please refer to `supported ORC features in Arrow\n",
      " |        <https://arrow.apache.org/docs/cpp/orc.html#data-types>`__.\n",
      " |      * Currently timezones in datetime columns are not preserved when a\n",
      " |        dataframe is converted into ORC files.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [4, 3]})\n",
      " |      >>> df.to_orc('df.orc')  # doctest: +SKIP\n",
      " |      >>> pd.read_orc('df.orc')  # doctest: +SKIP\n",
      " |         col1  col2\n",
      " |      0     1     4\n",
      " |      1     2     3\n",
      " |\n",
      " |      If you want to get a buffer to the orc content you can write it to io.BytesIO\n",
      " |\n",
      " |      >>> import io\n",
      " |      >>> b = io.BytesIO(df.to_orc())  # doctest: +SKIP\n",
      " |      >>> b.seek(0)  # doctest: +SKIP\n",
      " |      0\n",
      " |      >>> content = b.read()  # doctest: +SKIP\n",
      " |\n",
      " |  to_parquet(self, path: 'FilePath | WriteBuffer[bytes] | None' = None, *, engine: \"Literal['auto', 'pyarrow', 'fastparquet']\" = 'auto', compression: 'str | None' = 'snappy', index: 'bool | None' = None, partition_cols: 'list[str] | None' = None, storage_options: 'StorageOptions | None' = None, **kwargs) -> 'bytes | None'\n",
      " |      Write a DataFrame to the binary parquet format.\n",
      " |\n",
      " |      This function writes the dataframe as a `parquet file\n",
      " |      <https://parquet.apache.org/>`_. You can choose different parquet\n",
      " |      backends, and have the option of compression. See\n",
      " |      :ref:`the user guide <io.parquet>` for more details.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function. If None, the result is\n",
      " |          returned as bytes. If a string or path, it will be used as Root Directory\n",
      " |          path when writing a partitioned dataset.\n",
      " |      engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
      " |          Parquet library to use. If 'auto', then the option\n",
      " |          ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n",
      " |          behavior is to try 'pyarrow', falling back to 'fastparquet' if\n",
      " |          'pyarrow' is unavailable.\n",
      " |      compression : str or None, default 'snappy'\n",
      " |          Name of the compression to use. Use ``None`` for no compression.\n",
      " |          Supported options: 'snappy', 'gzip', 'brotli', 'lz4', 'zstd'.\n",
      " |      index : bool, default None\n",
      " |          If ``True``, include the dataframe's index(es) in the file output.\n",
      " |          If ``False``, they will not be written to the file.\n",
      " |          If ``None``, similar to ``True`` the dataframe's index(es)\n",
      " |          will be saved. However, instead of being saved as values,\n",
      " |          the RangeIndex will be stored as a range in the metadata so it\n",
      " |          doesn't require much space and is faster. Other indexes will\n",
      " |          be included as columns in the file output.\n",
      " |      partition_cols : list, optional, default None\n",
      " |          Column names by which to partition the dataset.\n",
      " |          Columns are partitioned in the order they are given.\n",
      " |          Must be None if path is not a string.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional arguments passed to the parquet library. See\n",
      " |          :ref:`pandas io <io.parquet>` for more details.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bytes if no path argument is provided else None\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_parquet : Read a parquet file.\n",
      " |      DataFrame.to_orc : Write an orc file.\n",
      " |      DataFrame.to_csv : Write a csv file.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_hdf : Write to hdf.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function requires either the `fastparquet\n",
      " |      <https://pypi.org/project/fastparquet>`_ or `pyarrow\n",
      " |      <https://arrow.apache.org/docs/python/>`_ library.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.to_parquet('df.parquet.gzip',\n",
      " |      ...               compression='gzip')  # doctest: +SKIP\n",
      " |      >>> pd.read_parquet('df.parquet.gzip')  # doctest: +SKIP\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |\n",
      " |      If you want to get a buffer to the parquet content you can use a io.BytesIO\n",
      " |      object, as long as you don't use partition_cols, which creates multiple files.\n",
      " |\n",
      " |      >>> import io\n",
      " |      >>> f = io.BytesIO()\n",
      " |      >>> df.to_parquet(f)\n",
      " |      >>> f.seek(0)\n",
      " |      0\n",
      " |      >>> content = f.read()\n",
      " |\n",
      " |  to_period(self, freq: 'Frequency | None' = None, axis: 'Axis' = 0, copy: 'bool | None' = None) -> 'DataFrame'\n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex.\n",
      " |\n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default\n",
      " |          Frequency of the PeriodIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default).\n",
      " |      copy : bool, default True\n",
      " |          If False then underlying input data is not copied.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The DataFrame has a PeriodIndex.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.to_datetime(\n",
      " |      ...     [\n",
      " |      ...         \"2001-03-31 00:00:00\",\n",
      " |      ...         \"2002-05-31 00:00:00\",\n",
      " |      ...         \"2003-08-31 00:00:00\",\n",
      " |      ...     ]\n",
      " |      ... )\n",
      " |\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2001-03-31', '2002-05-31', '2003-08-31'],\n",
      " |      dtype='datetime64[ns]', freq=None)\n",
      " |\n",
      " |      >>> idx.to_period(\"M\")\n",
      " |      PeriodIndex(['2001-03', '2002-05', '2003-08'], dtype='period[M]')\n",
      " |\n",
      " |      For the yearly frequency\n",
      " |\n",
      " |      >>> idx.to_period(\"Y\")\n",
      " |      PeriodIndex(['2001', '2002', '2003'], dtype='period[Y-DEC]')\n",
      " |\n",
      " |  to_records(self, index: 'bool' = True, column_dtypes=None, index_dtypes=None) -> 'np.rec.recarray'\n",
      " |      Convert DataFrame to a NumPy record array.\n",
      " |\n",
      " |      Index will be included as the first field of the record array if\n",
      " |      requested.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Include index in resulting record array, stored in 'index'\n",
      " |          field or using the index label, if set.\n",
      " |      column_dtypes : str, type, dict, default None\n",
      " |          If a string or type, the data type to store all columns. If\n",
      " |          a dictionary, a mapping of column names and indices (zero-indexed)\n",
      " |          to specific data types.\n",
      " |      index_dtypes : str, type, dict, default None\n",
      " |          If a string or type, the data type to store all index levels. If\n",
      " |          a dictionary, a mapping of index level names and indices\n",
      " |          (zero-indexed) to specific data types.\n",
      " |\n",
      " |          This mapping is applied only if `index=True`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.rec.recarray\n",
      " |          NumPy ndarray with the DataFrame labels as fields and each row\n",
      " |          of the DataFrame as entries.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records: Convert structured or record ndarray\n",
      " |          to DataFrame.\n",
      " |      numpy.rec.recarray: An ndarray that allows field access using\n",
      " |          attributes, analogous to typed columns in a\n",
      " |          spreadsheet.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},\n",
      " |      ...                   index=['a', 'b'])\n",
      " |      >>> df\n",
      " |         A     B\n",
      " |      a  1  0.50\n",
      " |      b  2  0.75\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |\n",
      " |      If the DataFrame index has no label then the recarray field name\n",
      " |      is set to 'index'. If the index has a label then this is used as the\n",
      " |      field name:\n",
      " |\n",
      " |      >>> df.index = df.index.rename(\"I\")\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('I', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |\n",
      " |      The index can be excluded from the record array:\n",
      " |\n",
      " |      >>> df.to_records(index=False)\n",
      " |      rec.array([(1, 0.5 ), (2, 0.75)],\n",
      " |                dtype=[('A', '<i8'), ('B', '<f8')])\n",
      " |\n",
      " |      Data types can be specified for the columns:\n",
      " |\n",
      " |      >>> df.to_records(column_dtypes={\"A\": \"int32\"})\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('I', 'O'), ('A', '<i4'), ('B', '<f8')])\n",
      " |\n",
      " |      As well as for the index:\n",
      " |\n",
      " |      >>> df.to_records(index_dtypes=\"<S2\")\n",
      " |      rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n",
      " |                dtype=[('I', 'S2'), ('A', '<i8'), ('B', '<f8')])\n",
      " |\n",
      " |      >>> index_dtypes = f\"<S{df.index.str.len().max()}\"\n",
      " |      >>> df.to_records(index_dtypes=index_dtypes)\n",
      " |      rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n",
      " |                dtype=[('I', 'S1'), ('A', '<i8'), ('B', '<f8')])\n",
      " |\n",
      " |  to_stata(self, path: 'FilePath | WriteBuffer[bytes]', *, convert_dates: 'dict[Hashable, str] | None' = None, write_index: 'bool' = True, byteorder: 'ToStataByteorder | None' = None, time_stamp: 'datetime.datetime | None' = None, data_label: 'str | None' = None, variable_labels: 'dict[Hashable, str] | None' = None, version: 'int | None' = 114, convert_strl: 'Sequence[Hashable] | None' = None, compression: 'CompressionOptions' = 'infer', storage_options: 'StorageOptions | None' = None, value_labels: 'dict[Hashable, dict[float, str]] | None' = None) -> 'None'\n",
      " |      Export DataFrame object to Stata dta format.\n",
      " |\n",
      " |      Writes the DataFrame to a Stata dataset file.\n",
      " |      \"dta\" files contain a Stata dataset.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, or buffer\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function.\n",
      " |\n",
      " |      convert_dates : dict\n",
      " |          Dictionary mapping columns containing datetime types to stata\n",
      " |          internal format to use when writing the dates. Options are 'tc',\n",
      " |          'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\n",
      " |          or a name. Datetime columns that do not have a conversion type\n",
      " |          specified will be converted to 'tc'. Raises NotImplementedError if\n",
      " |          a datetime column has timezone information.\n",
      " |      write_index : bool\n",
      " |          Write the index to Stata dataset.\n",
      " |      byteorder : str\n",
      " |          Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`.\n",
      " |      time_stamp : datetime\n",
      " |          A datetime to use as file creation date.  Default is the current\n",
      " |          time.\n",
      " |      data_label : str, optional\n",
      " |          A label for the data set.  Must be 80 characters or smaller.\n",
      " |      variable_labels : dict\n",
      " |          Dictionary containing columns as keys and variable labels as\n",
      " |          values. Each label must be 80 characters or smaller.\n",
      " |      version : {114, 117, 118, 119, None}, default 114\n",
      " |          Version to use in the output dta file. Set to None to let pandas\n",
      " |          decide between 118 or 119 formats depending on the number of\n",
      " |          columns in the frame. Version 114 can be read by Stata 10 and\n",
      " |          later. Version 117 can be read by Stata 13 or later. Version 118\n",
      " |          is supported in Stata 14 and later. Version 119 is supported in\n",
      " |          Stata 15 and later. Version 114 limits string variables to 244\n",
      " |          characters or fewer while versions 117 and later allow strings\n",
      " |          with lengths up to 2,000,000 characters. Versions 118 and 119\n",
      " |          support Unicode characters, and version 119 supports more than\n",
      " |          32,767 variables.\n",
      " |\n",
      " |          Version 119 should usually only be used when the number of\n",
      " |          variables exceeds the capacity of dta format 118. Exporting\n",
      " |          smaller datasets in format 119 may have unintended consequences,\n",
      " |          and, as of November 2020, Stata SE cannot read version 119 files.\n",
      " |\n",
      " |      convert_strl : list, optional\n",
      " |          List of column names to convert to string columns to Stata StrL\n",
      " |          format. Only available if version is 117.  Storing strings in the\n",
      " |          StrL format can produce smaller dta files if strings have more than\n",
      " |          8 characters and values are repeated.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      " |          other key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |\n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      value_labels : dict of dicts\n",
      " |          Dictionary containing columns as keys and dictionaries of column value\n",
      " |          to labels as values. Labels for a single variable must be 32,000\n",
      " |          characters or smaller.\n",
      " |\n",
      " |          .. versionadded:: 1.4.0\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          * If datetimes contain timezone information\n",
      " |          * Column dtype is not representable in Stata\n",
      " |      ValueError\n",
      " |          * Columns listed in convert_dates are neither datetime64[ns]\n",
      " |            or datetime.datetime\n",
      " |          * Column listed in convert_dates is not in DataFrame\n",
      " |          * Categorical label contains more than 32,000 characters\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_stata : Import Stata data files.\n",
      " |      io.stata.StataWriter : Low-level writer for Stata data files.\n",
      " |      io.stata.StataWriter117 : Low-level writer for version 117 files.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['falcon', 'parrot', 'falcon',\n",
      " |      ...                               'parrot'],\n",
      " |      ...                    'speed': [350, 18, 361, 15]})\n",
      " |      >>> df.to_stata('animals.dta')  # doctest: +SKIP\n",
      " |\n",
      " |  to_string(self, buf: 'FilePath | WriteBuffer[str] | None' = None, *, columns: 'Axes | None' = None, col_space: 'int | list[int] | dict[Hashable, int] | None' = None, header: 'bool | SequenceNotStr[str]' = True, index: 'bool' = True, na_rep: 'str' = 'NaN', formatters: 'fmt.FormattersType | None' = None, float_format: 'fmt.FloatFormatType | None' = None, sparsify: 'bool | None' = None, index_names: 'bool' = True, justify: 'str | None' = None, max_rows: 'int | None' = None, max_cols: 'int | None' = None, show_dimensions: 'bool' = False, decimal: 'str' = '.', line_width: 'int | None' = None, min_rows: 'int | None' = None, max_colwidth: 'int | None' = None, encoding: 'str | None' = None) -> 'str | None'\n",
      " |      Render a DataFrame to a console-friendly tabular output.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : array-like, optional, default None\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : int, list or dict of int, optional\n",
      " |          The minimum width of each column. If a list of ints is given every integers corresponds with one column. If a dict is given, the key references the column, while the value defines the space to use..\n",
      " |      header : bool or list of str, optional\n",
      " |          Write out the column names. If a list of columns is given, it is assumed to be aliases for the column names.\n",
      " |      index : bool, optional, default True\n",
      " |          Whether to print index (row) labels.\n",
      " |      na_rep : str, optional, default 'NaN'\n",
      " |          String representation of ``NaN`` to use.\n",
      " |      formatters : list, tuple or dict of one-param. functions, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name.\n",
      " |          The result of each function must be a unicode string.\n",
      " |          List/tuple must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional, default None\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats. This function must return a unicode string and will be\n",
      " |          applied only to the non-``NaN`` elements, with ``NaN`` being\n",
      " |          handled by ``na_rep``.\n",
      " |      sparsify : bool, optional, default True\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row.\n",
      " |      index_names : bool, optional, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |\n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to display in the console.\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to display in the console.\n",
      " |      show_dimensions : bool, default False\n",
      " |          Display DataFrame dimensions (number of rows by number of columns).\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |\n",
      " |      line_width : int, optional\n",
      " |          Width to wrap a line in characters.\n",
      " |      min_rows : int, optional\n",
      " |          The number of rows to display in the console in a truncated repr\n",
      " |          (when number of rows is above `max_rows`).\n",
      " |      max_colwidth : int, optional\n",
      " |          Max width to truncate each column in characters. By default, no limit.\n",
      " |      encoding : str, default \"utf-8\"\n",
      " |          Set character encoding.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_html : Convert DataFrame to HTML.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> print(df.to_string())\n",
      " |         col1  col2\n",
      " |      0     1     4\n",
      " |      1     2     5\n",
      " |      2     3     6\n",
      " |\n",
      " |  to_timestamp(self, freq: 'Frequency | None' = None, how: 'ToTimestampHow' = 'start', axis: 'Axis' = 0, copy: 'bool | None' = None) -> 'DataFrame'\n",
      " |      Cast to DatetimeIndex of timestamps, at *beginning* of period.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default frequency of PeriodIndex\n",
      " |          Desired frequency.\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default).\n",
      " |      copy : bool, default True\n",
      " |          If False then underlying input data is not copied.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The DataFrame has a DatetimeIndex.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.PeriodIndex(['2023', '2024'], freq='Y')\n",
      " |      >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df1 = pd.DataFrame(data=d, index=idx)\n",
      " |      >>> df1\n",
      " |            col1   col2\n",
      " |      2023     1      3\n",
      " |      2024     2      4\n",
      " |\n",
      " |      The resulting timestamps will be at the beginning of the year in this case\n",
      " |\n",
      " |      >>> df1 = df1.to_timestamp()\n",
      " |      >>> df1\n",
      " |                  col1   col2\n",
      " |      2023-01-01     1      3\n",
      " |      2024-01-01     2      4\n",
      " |      >>> df1.index\n",
      " |      DatetimeIndex(['2023-01-01', '2024-01-01'], dtype='datetime64[ns]', freq=None)\n",
      " |\n",
      " |      Using `freq` which is the offset that the Timestamps will have\n",
      " |\n",
      " |      >>> df2 = pd.DataFrame(data=d, index=idx)\n",
      " |      >>> df2 = df2.to_timestamp(freq='M')\n",
      " |      >>> df2\n",
      " |                  col1   col2\n",
      " |      2023-01-31     1      3\n",
      " |      2024-01-31     2      4\n",
      " |      >>> df2.index\n",
      " |      DatetimeIndex(['2023-01-31', '2024-01-31'], dtype='datetime64[ns]', freq=None)\n",
      " |\n",
      " |  to_xml(self, path_or_buffer: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, *, index: 'bool' = True, root_name: 'str | None' = 'data', row_name: 'str | None' = 'row', na_rep: 'str | None' = None, attr_cols: 'list[str] | None' = None, elem_cols: 'list[str] | None' = None, namespaces: 'dict[str | None, str] | None' = None, prefix: 'str | None' = None, encoding: 'str' = 'utf-8', xml_declaration: 'bool | None' = True, pretty_print: 'bool | None' = True, parser: 'XMLParsers | None' = 'lxml', stylesheet: 'FilePath | ReadBuffer[str] | ReadBuffer[bytes] | None' = None, compression: 'CompressionOptions' = 'infer', storage_options: 'StorageOptions | None' = None) -> 'str | None'\n",
      " |      Render a DataFrame to an XML document.\n",
      " |\n",
      " |      .. versionadded:: 1.3.0\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buffer : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a ``write()`` function. If None, the result is returned\n",
      " |          as a string.\n",
      " |      index : bool, default True\n",
      " |          Whether to include index in XML document.\n",
      " |      root_name : str, default 'data'\n",
      " |          The name of root element in XML document.\n",
      " |      row_name : str, default 'row'\n",
      " |          The name of row element in XML document.\n",
      " |      na_rep : str, optional\n",
      " |          Missing data representation.\n",
      " |      attr_cols : list-like, optional\n",
      " |          List of columns to write as attributes in row element.\n",
      " |          Hierarchical columns will be flattened with underscore\n",
      " |          delimiting the different levels.\n",
      " |      elem_cols : list-like, optional\n",
      " |          List of columns to write as children in row element. By default,\n",
      " |          all columns output as children of row element. Hierarchical\n",
      " |          columns will be flattened with underscore delimiting the\n",
      " |          different levels.\n",
      " |      namespaces : dict, optional\n",
      " |          All namespaces to be defined in root element. Keys of dict\n",
      " |          should be prefix names and values of dict corresponding URIs.\n",
      " |          Default namespaces should be given empty string key. For\n",
      " |          example, ::\n",
      " |\n",
      " |              namespaces = {\"\": \"https://example.com\"}\n",
      " |\n",
      " |      prefix : str, optional\n",
      " |          Namespace prefix to be used for every element and/or attribute\n",
      " |          in document. This should be one of the keys in ``namespaces``\n",
      " |          dict.\n",
      " |      encoding : str, default 'utf-8'\n",
      " |          Encoding of the resulting document.\n",
      " |      xml_declaration : bool, default True\n",
      " |          Whether to include the XML declaration at start of document.\n",
      " |      pretty_print : bool, default True\n",
      " |          Whether output should be pretty printed with indentation and\n",
      " |          line breaks.\n",
      " |      parser : {'lxml','etree'}, default 'lxml'\n",
      " |          Parser module to use for building of tree. Only 'lxml' and\n",
      " |          'etree' are supported. With 'lxml', the ability to use XSLT\n",
      " |          stylesheet is supported.\n",
      " |      stylesheet : str, path object or file-like object, optional\n",
      " |          A URL, file-like object, or a raw string containing an XSLT\n",
      " |          script used to transform the raw XML output. Script should use\n",
      " |          layout of elements and attributes from original output. This\n",
      " |          argument requires ``lxml`` to be installed. Only XSLT 1.0\n",
      " |          scripts and not later versions is currently supported.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buffer' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      " |          other key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |\n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If ``io`` is None, returns the resulting XML format as a\n",
      " |          string. Otherwise returns None.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_json : Convert the pandas object to a JSON string.\n",
      " |      to_html : Convert DataFrame to a html.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'shape': ['square', 'circle', 'triangle'],\n",
      " |      ...                    'degrees': [360, 360, 180],\n",
      " |      ...                    'sides': [4, np.nan, 3]})\n",
      " |\n",
      " |      >>> df.to_xml()  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <data>\n",
      " |        <row>\n",
      " |          <index>0</index>\n",
      " |          <shape>square</shape>\n",
      " |          <degrees>360</degrees>\n",
      " |          <sides>4.0</sides>\n",
      " |        </row>\n",
      " |        <row>\n",
      " |          <index>1</index>\n",
      " |          <shape>circle</shape>\n",
      " |          <degrees>360</degrees>\n",
      " |          <sides/>\n",
      " |        </row>\n",
      " |        <row>\n",
      " |          <index>2</index>\n",
      " |          <shape>triangle</shape>\n",
      " |          <degrees>180</degrees>\n",
      " |          <sides>3.0</sides>\n",
      " |        </row>\n",
      " |      </data>\n",
      " |\n",
      " |      >>> df.to_xml(attr_cols=[\n",
      " |      ...           'index', 'shape', 'degrees', 'sides'\n",
      " |      ...           ])  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <data>\n",
      " |        <row index=\"0\" shape=\"square\" degrees=\"360\" sides=\"4.0\"/>\n",
      " |        <row index=\"1\" shape=\"circle\" degrees=\"360\"/>\n",
      " |        <row index=\"2\" shape=\"triangle\" degrees=\"180\" sides=\"3.0\"/>\n",
      " |      </data>\n",
      " |\n",
      " |      >>> df.to_xml(namespaces={\"doc\": \"https://example.com\"},\n",
      " |      ...           prefix=\"doc\")  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <doc:data xmlns:doc=\"https://example.com\">\n",
      " |        <doc:row>\n",
      " |          <doc:index>0</doc:index>\n",
      " |          <doc:shape>square</doc:shape>\n",
      " |          <doc:degrees>360</doc:degrees>\n",
      " |          <doc:sides>4.0</doc:sides>\n",
      " |        </doc:row>\n",
      " |        <doc:row>\n",
      " |          <doc:index>1</doc:index>\n",
      " |          <doc:shape>circle</doc:shape>\n",
      " |          <doc:degrees>360</doc:degrees>\n",
      " |          <doc:sides/>\n",
      " |        </doc:row>\n",
      " |        <doc:row>\n",
      " |          <doc:index>2</doc:index>\n",
      " |          <doc:shape>triangle</doc:shape>\n",
      " |          <doc:degrees>180</doc:degrees>\n",
      " |          <doc:sides>3.0</doc:sides>\n",
      " |        </doc:row>\n",
      " |      </doc:data>\n",
      " |\n",
      " |  transform(self, func: 'AggFuncType', axis: 'Axis' = 0, *args, **kwargs) -> 'DataFrame'\n",
      " |      Call ``func`` on self producing a DataFrame with the same axis shape as self.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list-like or dict-like\n",
      " |          Function to use for transforming the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply. If func\n",
      " |          is both list-like and dict-like, dict-like behavior takes precedence.\n",
      " |\n",
      " |          Accepted combinations are:\n",
      " |\n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list-like of functions and/or function names, e.g. ``[np.exp, 'sqrt']``\n",
      " |          - dict-like of axis labels -> functions, function names or list-like of such.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |              If 0 or 'index': apply function to each column.\n",
      " |              If 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame that must have the same length as self.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError : If the returned DataFrame has a different length than self.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.agg : Only perform aggregating type operations.\n",
      " |      DataFrame.apply : Invoke function on a DataFrame.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  1  2\n",
      " |      2  2  3\n",
      " |      >>> df.transform(lambda x: x + 1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  2  3\n",
      " |      2  3  4\n",
      " |\n",
      " |      Even though the resulting DataFrame must have the same length as the\n",
      " |      input DataFrame, it is possible to provide several input functions:\n",
      " |\n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |      >>> s.transform([np.sqrt, np.exp])\n",
      " |             sqrt        exp\n",
      " |      0  0.000000   1.000000\n",
      " |      1  1.000000   2.718282\n",
      " |      2  1.414214   7.389056\n",
      " |\n",
      " |      You can call transform on a GroupBy object:\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"Date\": [\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\",\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\"],\n",
      " |      ...     \"Data\": [5, 8, 6, 1, 50, 100, 60, 120],\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |               Date  Data\n",
      " |      0  2015-05-08     5\n",
      " |      1  2015-05-07     8\n",
      " |      2  2015-05-06     6\n",
      " |      3  2015-05-05     1\n",
      " |      4  2015-05-08    50\n",
      " |      5  2015-05-07   100\n",
      " |      6  2015-05-06    60\n",
      " |      7  2015-05-05   120\n",
      " |      >>> df.groupby('Date')['Data'].transform('sum')\n",
      " |      0     55\n",
      " |      1    108\n",
      " |      2     66\n",
      " |      3    121\n",
      " |      4     55\n",
      " |      5    108\n",
      " |      6     66\n",
      " |      7    121\n",
      " |      Name: Data, dtype: int64\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"c\": [1, 1, 1, 2, 2, 2, 2],\n",
      " |      ...     \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |         c type\n",
      " |      0  1    m\n",
      " |      1  1    n\n",
      " |      2  1    o\n",
      " |      3  2    m\n",
      " |      4  2    m\n",
      " |      5  2    n\n",
      " |      6  2    n\n",
      " |      >>> df['size'] = df.groupby('c')['type'].transform(len)\n",
      " |      >>> df\n",
      " |         c type size\n",
      " |      0  1    m    3\n",
      " |      1  1    n    3\n",
      " |      2  1    o    3\n",
      " |      3  2    m    4\n",
      " |      4  2    m    4\n",
      " |      5  2    n    4\n",
      " |      6  2    n    4\n",
      " |\n",
      " |  transpose(self, *args, copy: 'bool' = False) -> 'DataFrame'\n",
      " |      Transpose index and columns.\n",
      " |\n",
      " |      Reflect the DataFrame over its main diagonal by writing rows as columns\n",
      " |      and vice-versa. The property :attr:`.T` is an accessor to the method\n",
      " |      :meth:`transpose`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *args : tuple, optional\n",
      " |          Accepted for compatibility with NumPy.\n",
      " |      copy : bool, default False\n",
      " |          Whether to copy the data after transposing, even for DataFrames\n",
      " |          with a single dtype.\n",
      " |\n",
      " |          Note that a copy is always required for mixed dtype DataFrames,\n",
      " |          or for DataFrames with any extension types.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The transposed DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.transpose : Permute the dimensions of a given array.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Transposing a DataFrame with mixed dtypes will result in a homogeneous\n",
      " |      DataFrame with the `object` dtype. In such a case, a copy of the data\n",
      " |      is always made.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Square DataFrame with homogeneous dtype**\n",
      " |\n",
      " |      >>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df1 = pd.DataFrame(data=d1)\n",
      " |      >>> df1\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |\n",
      " |      >>> df1_transposed = df1.T  # or df1.transpose()\n",
      " |      >>> df1_transposed\n",
      " |            0  1\n",
      " |      col1  1  2\n",
      " |      col2  3  4\n",
      " |\n",
      " |      When the dtype is homogeneous in the original DataFrame, we get a\n",
      " |      transposed DataFrame with the same dtype:\n",
      " |\n",
      " |      >>> df1.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      >>> df1_transposed.dtypes\n",
      " |      0    int64\n",
      " |      1    int64\n",
      " |      dtype: object\n",
      " |\n",
      " |      **Non-square DataFrame with mixed dtypes**\n",
      " |\n",
      " |      >>> d2 = {'name': ['Alice', 'Bob'],\n",
      " |      ...       'score': [9.5, 8],\n",
      " |      ...       'employed': [False, True],\n",
      " |      ...       'kids': [0, 0]}\n",
      " |      >>> df2 = pd.DataFrame(data=d2)\n",
      " |      >>> df2\n",
      " |          name  score  employed  kids\n",
      " |      0  Alice    9.5     False     0\n",
      " |      1    Bob    8.0      True     0\n",
      " |\n",
      " |      >>> df2_transposed = df2.T  # or df2.transpose()\n",
      " |      >>> df2_transposed\n",
      " |                    0     1\n",
      " |      name      Alice   Bob\n",
      " |      score       9.5   8.0\n",
      " |      employed  False  True\n",
      " |      kids          0     0\n",
      " |\n",
      " |      When the DataFrame has mixed dtypes, we get a transposed DataFrame with\n",
      " |      the `object` dtype:\n",
      " |\n",
      " |      >>> df2.dtypes\n",
      " |      name         object\n",
      " |      score       float64\n",
      " |      employed       bool\n",
      " |      kids          int64\n",
      " |      dtype: object\n",
      " |      >>> df2_transposed.dtypes\n",
      " |      0    object\n",
      " |      1    object\n",
      " |      dtype: object\n",
      " |\n",
      " |  truediv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      " |\n",
      " |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rtruediv`.\n",
      " |\n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `floordiv`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |\n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |\n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |\n",
      " |      Divide by constant with reverse version.\n",
      " |\n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |\n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |\n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |\n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |\n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |\n",
      " |      Multiply a dictionary by axis.\n",
      " |\n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |\n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |\n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |\n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |\n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |\n",
      " |      Divide by a MultiIndex by level.\n",
      " |\n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |\n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |\n",
      " |  unstack(self, level: 'IndexLabel' = -1, fill_value=None, sort: 'bool' = True)\n",
      " |      Pivot a level of the (necessarily hierarchical) index labels.\n",
      " |\n",
      " |      Returns a DataFrame having a new level of column labels whose inner-most level\n",
      " |      consists of the pivoted index labels.\n",
      " |\n",
      " |      If the index is not a MultiIndex, the output will be a Series\n",
      " |      (the analogue of stack when the columns are not a MultiIndex).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list of these, default -1 (last level)\n",
      " |          Level(s) of index to unstack, can pass level name.\n",
      " |      fill_value : int, str or dict\n",
      " |          Replace NaN with this value if the unstack produces missing values.\n",
      " |      sort : bool, default True\n",
      " |          Sort the level(s) in the resulting MultiIndex columns.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot a table based on column values.\n",
      " |      DataFrame.stack : Pivot a level of the column labels (inverse operation\n",
      " |          from `unstack`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.stacking>` for more examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n",
      " |      ...                                    ('two', 'a'), ('two', 'b')])\n",
      " |      >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n",
      " |      >>> s\n",
      " |      one  a   1.0\n",
      " |           b   2.0\n",
      " |      two  a   3.0\n",
      " |           b   4.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a   b\n",
      " |      one  1.0  2.0\n",
      " |      two  3.0  4.0\n",
      " |\n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a  1.0   3.0\n",
      " |      b  2.0   4.0\n",
      " |\n",
      " |      >>> df = s.unstack(level=0)\n",
      " |      >>> df.unstack()\n",
      " |      one  a  1.0\n",
      " |           b  2.0\n",
      " |      two  a  3.0\n",
      " |           b  4.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |  update(self, other, join: 'UpdateJoin' = 'left', overwrite: 'bool' = True, filter_func=None, errors: 'IgnoreRaise' = 'ignore') -> 'None'\n",
      " |      Modify in place using non-NA values from another DataFrame.\n",
      " |\n",
      " |      Aligns on indices. There is no return value.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, or object coercible into a DataFrame\n",
      " |          Should have at least one matching index/column label\n",
      " |          with the original DataFrame. If a Series is passed,\n",
      " |          its name attribute must be set, and that will be\n",
      " |          used as the column name to align with the original DataFrame.\n",
      " |      join : {'left'}, default 'left'\n",
      " |          Only left join is implemented, keeping the index and columns of the\n",
      " |          original object.\n",
      " |      overwrite : bool, default True\n",
      " |          How to handle non-NA values for overlapping keys:\n",
      " |\n",
      " |          * True: overwrite original DataFrame's values\n",
      " |            with values from `other`.\n",
      " |          * False: only update values that are NA in\n",
      " |            the original DataFrame.\n",
      " |\n",
      " |      filter_func : callable(1d-array) -> bool 1d-array, optional\n",
      " |          Can choose to replace values other than NA. Return True for values\n",
      " |          that should be updated.\n",
      " |      errors : {'raise', 'ignore'}, default 'ignore'\n",
      " |          If 'raise', will raise a ValueError if the DataFrame and `other`\n",
      " |          both contain non-NA data in the same place.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |          This method directly changes calling object.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * When `errors='raise'` and there's overlapping non-NA data.\n",
      " |          * When `errors` is not either `'ignore'` or `'raise'`\n",
      " |      NotImplementedError\n",
      " |          * If `join != 'left'`\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      dict.update : Similar method for dictionaries.\n",
      " |      DataFrame.merge : For column(s)-on-column(s) operations.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, 5, 6],\n",
      " |      ...                        'C': [7, 8, 9]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |\n",
      " |      The DataFrame's length does not increase as a result of the update,\n",
      " |      only values at matching index/column labels are updated.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  e\n",
      " |      2  c  f\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'f']}, index=[0, 2])\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  y\n",
      " |      2  c  f\n",
      " |\n",
      " |      For Series, its name attribute must be set.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_column = pd.Series(['d', 'e', 'f'], name='B')\n",
      " |      >>> df.update(new_column)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  e\n",
      " |      2  c  f\n",
      " |\n",
      " |      If `other` contains NaNs the corresponding values are not updated\n",
      " |      in the original dataframe.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400., 500., 600.]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A      B\n",
      " |      0  1    4.0\n",
      " |      1  2  500.0\n",
      " |      2  3    6.0\n",
      " |\n",
      " |  value_counts(self, subset: 'IndexLabel | None' = None, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, dropna: 'bool' = True) -> 'Series'\n",
      " |      Return a Series containing the frequency of each distinct row in the Dataframe.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : label or list of labels, optional\n",
      " |          Columns to use when counting unique combinations.\n",
      " |      normalize : bool, default False\n",
      " |          Return proportions rather than frequencies.\n",
      " |      sort : bool, default True\n",
      " |          Sort by frequencies when True. Sort by DataFrame column values when False.\n",
      " |      ascending : bool, default False\n",
      " |          Sort in ascending order.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include counts of rows that contain NA values.\n",
      " |\n",
      " |          .. versionadded:: 1.3.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.value_counts: Equivalent method on Series.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The returned Series will have a MultiIndex with one level per input\n",
      " |      column but an Index (non-multi) for a single label. By default, rows\n",
      " |      that contain any NA values are omitted from the result. By default,\n",
      " |      the resulting Series will be in descending order so that the first\n",
      " |      element is the most frequently-occurring row.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0]},\n",
      " |      ...                   index=['falcon', 'dog', 'cat', 'ant'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings\n",
      " |      falcon         2          2\n",
      " |      dog            4          0\n",
      " |      cat            4          0\n",
      " |      ant            6          0\n",
      " |\n",
      " |      >>> df.value_counts()\n",
      " |      num_legs  num_wings\n",
      " |      4         0            2\n",
      " |      2         2            1\n",
      " |      6         0            1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      >>> df.value_counts(sort=False)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      4         0            2\n",
      " |      6         0            1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      >>> df.value_counts(ascending=True)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      6         0            1\n",
      " |      4         0            2\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      >>> df.value_counts(normalize=True)\n",
      " |      num_legs  num_wings\n",
      " |      4         0            0.50\n",
      " |      2         2            0.25\n",
      " |      6         0            0.25\n",
      " |      Name: proportion, dtype: float64\n",
      " |\n",
      " |      With `dropna` set to `False` we can also count rows with NA values.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'first_name': ['John', 'Anne', 'John', 'Beth'],\n",
      " |      ...                    'middle_name': ['Smith', pd.NA, pd.NA, 'Louise']})\n",
      " |      >>> df\n",
      " |        first_name middle_name\n",
      " |      0       John       Smith\n",
      " |      1       Anne        <NA>\n",
      " |      2       John        <NA>\n",
      " |      3       Beth      Louise\n",
      " |\n",
      " |      >>> df.value_counts()\n",
      " |      first_name  middle_name\n",
      " |      Beth        Louise         1\n",
      " |      John        Smith          1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      >>> df.value_counts(dropna=False)\n",
      " |      first_name  middle_name\n",
      " |      Anne        NaN            1\n",
      " |      Beth        Louise         1\n",
      " |      John        Smith          1\n",
      " |                  NaN            1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      >>> df.value_counts(\"first_name\")\n",
      " |      first_name\n",
      " |      John    2\n",
      " |      Anne    1\n",
      " |      Beth    1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |  var(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, ddof: 'int' = 1, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |\n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          .. warning::\n",
      " |\n",
      " |              The behavior of DataFrame.var with ``axis=None`` is deprecated,\n",
      " |              in a future version this will reduce over both axes and return a scalar\n",
      " |              To retain the old behavior, pass axis=0 (or do not pass axis).\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n",
      " |      ...                    'age': [21, 25, 62, 43],\n",
      " |      ...                    'height': [1.61, 1.87, 1.49, 2.01]}\n",
      " |      ...                   ).set_index('person_id')\n",
      " |      >>> df\n",
      " |                 age  height\n",
      " |      person_id\n",
      " |      0           21    1.61\n",
      " |      1           25    1.87\n",
      " |      2           62    1.49\n",
      " |      3           43    2.01\n",
      " |\n",
      " |      >>> df.var()\n",
      " |      age       352.916667\n",
      " |      height      0.056367\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Alternatively, ``ddof=0`` can be set to normalize by N instead of N-1:\n",
      " |\n",
      " |      >>> df.var(ddof=0)\n",
      " |      age       264.687500\n",
      " |      height      0.042275\n",
      " |      dtype: float64\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |\n",
      " |  from_dict(data: 'dict', orient: 'FromDictOrient' = 'columns', dtype: 'Dtype | None' = None, columns: 'Axes | None' = None) -> 'DataFrame' from builtins.type\n",
      " |      Construct DataFrame from dict of array-like or dicts.\n",
      " |\n",
      " |      Creates DataFrame object from dictionary by columns or by index\n",
      " |      allowing dtype specification.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : dict\n",
      " |          Of the form {field : array-like} or {field : dict}.\n",
      " |      orient : {'columns', 'index', 'tight'}, default 'columns'\n",
      " |          The \"orientation\" of the data. If the keys of the passed dict\n",
      " |          should be the columns of the resulting DataFrame, pass 'columns'\n",
      " |          (default). Otherwise if the keys should be rows, pass 'index'.\n",
      " |          If 'tight', assume a dict with keys ['index', 'columns', 'data',\n",
      " |          'index_names', 'column_names'].\n",
      " |\n",
      " |          .. versionadded:: 1.4.0\n",
      " |             'tight' as an allowed value for the ``orient`` argument\n",
      " |\n",
      " |      dtype : dtype, default None\n",
      " |          Data type to force after DataFrame construction, otherwise infer.\n",
      " |      columns : list, default None\n",
      " |          Column labels to use when ``orient='index'``. Raises a ValueError\n",
      " |          if used with ``orient='columns'`` or ``orient='tight'``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records : DataFrame from structured ndarray, sequence\n",
      " |          of tuples or dicts, or DataFrame.\n",
      " |      DataFrame : DataFrame object creation using constructor.\n",
      " |      DataFrame.to_dict : Convert the DataFrame to a dictionary.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default the keys of the dict become the DataFrame columns:\n",
      " |\n",
      " |      >>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |\n",
      " |      Specify ``orient='index'`` to create the DataFrame using dictionary\n",
      " |      keys as rows:\n",
      " |\n",
      " |      >>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index')\n",
      " |             0  1  2  3\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |\n",
      " |      When using the 'index' orientation, the column names can be\n",
      " |      specified manually:\n",
      " |\n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index',\n",
      " |      ...                        columns=['A', 'B', 'C', 'D'])\n",
      " |             A  B  C  D\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |\n",
      " |      Specify ``orient='tight'`` to create the DataFrame using a 'tight'\n",
      " |      format:\n",
      " |\n",
      " |      >>> data = {'index': [('a', 'b'), ('a', 'c')],\n",
      " |      ...         'columns': [('x', 1), ('y', 2)],\n",
      " |      ...         'data': [[1, 3], [2, 4]],\n",
      " |      ...         'index_names': ['n1', 'n2'],\n",
      " |      ...         'column_names': ['z1', 'z2']}\n",
      " |      >>> pd.DataFrame.from_dict(data, orient='tight')\n",
      " |      z1     x  y\n",
      " |      z2     1  2\n",
      " |      n1 n2\n",
      " |      a  b   1  3\n",
      " |         c   2  4\n",
      " |\n",
      " |  from_records(data, index=None, exclude=None, columns=None, coerce_float: 'bool' = False, nrows: 'int | None' = None) -> 'DataFrame' from builtins.type\n",
      " |      Convert structured or record ndarray to DataFrame.\n",
      " |\n",
      " |      Creates a DataFrame object from a structured ndarray, sequence of\n",
      " |      tuples or dicts, or DataFrame.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : structured ndarray, sequence of tuples or dicts, or DataFrame\n",
      " |          Structured input data.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |              Passing a DataFrame is deprecated.\n",
      " |      index : str, list of fields, array-like\n",
      " |          Field of array to use as the index, alternately a specific set of\n",
      " |          input labels to use.\n",
      " |      exclude : sequence, default None\n",
      " |          Columns or fields to exclude.\n",
      " |      columns : sequence, default None\n",
      " |          Column names to use. If the passed data do not have names\n",
      " |          associated with them, this argument provides names for the\n",
      " |          columns. Otherwise this argument indicates the order of the columns\n",
      " |          in the result (any names not found in the data will become all-NA\n",
      " |          columns).\n",
      " |      coerce_float : bool, default False\n",
      " |          Attempt to convert values of non-string, non-numeric objects (like\n",
      " |          decimal.Decimal) to floating point, useful for SQL result sets.\n",
      " |      nrows : int, default None\n",
      " |          Number of rows to read if data is an iterator.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict : DataFrame from dict of array-like or dicts.\n",
      " |      DataFrame : DataFrame object creation using constructor.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Data can be provided as a structured ndarray:\n",
      " |\n",
      " |      >>> data = np.array([(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')],\n",
      " |      ...                 dtype=[('col_1', 'i4'), ('col_2', 'U1')])\n",
      " |      >>> pd.DataFrame.from_records(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |\n",
      " |      Data can be provided as a list of dicts:\n",
      " |\n",
      " |      >>> data = [{'col_1': 3, 'col_2': 'a'},\n",
      " |      ...         {'col_1': 2, 'col_2': 'b'},\n",
      " |      ...         {'col_1': 1, 'col_2': 'c'},\n",
      " |      ...         {'col_1': 0, 'col_2': 'd'}]\n",
      " |      >>> pd.DataFrame.from_records(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |\n",
      " |      Data can be provided as a list of tuples with corresponding columns:\n",
      " |\n",
      " |      >>> data = [(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')]\n",
      " |      >>> pd.DataFrame.from_records(data, columns=['col_1', 'col_2'])\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  T\n",
      " |      The transpose of the DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The transposed DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.transpose : Transpose index and columns.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |\n",
      " |      >>> df.T\n",
      " |            0  1\n",
      " |      col1  1  2\n",
      " |      col2  3  4\n",
      " |\n",
      " |  axes\n",
      " |      Return a list representing the axes of the DataFrame.\n",
      " |\n",
      " |      It has the row axis labels and column axis labels as the only members.\n",
      " |      They are returned in that order.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.axes\n",
      " |      [RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],\n",
      " |      dtype='object')]\n",
      " |\n",
      " |  shape\n",
      " |      Return a tuple representing the dimensionality of the DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.shape : Tuple of array dimensions.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.shape\n",
      " |      (2, 2)\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],\n",
      " |      ...                    'col3': [5, 6]})\n",
      " |      >>> df.shape\n",
      " |      (2, 3)\n",
      " |\n",
      " |  style\n",
      " |      Returns a Styler object.\n",
      " |\n",
      " |      Contains methods for building a styled HTML representation of the DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      io.formats.style.Styler : Helps style a DataFrame or Series according to the\n",
      " |          data with HTML and CSS.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3]})\n",
      " |      >>> df.style  # doctest: +SKIP\n",
      " |\n",
      " |      Please see\n",
      " |      `Table Visualization <../../user_guide/style.ipynb>`_ for more examples.\n",
      " |\n",
      " |  values\n",
      " |      Return a Numpy representation of the DataFrame.\n",
      " |\n",
      " |      .. warning::\n",
      " |\n",
      " |         We recommend using :meth:`DataFrame.to_numpy` instead.\n",
      " |\n",
      " |      Only the values in the DataFrame will be returned, the axes labels\n",
      " |      will be removed.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The values of the DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_numpy : Recommended alternative to this method.\n",
      " |      DataFrame.index : Retrieve the index labels.\n",
      " |      DataFrame.columns : Retrieving the column names.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |\n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcast to\n",
      " |      int32. By :func:`numpy.find_common_type` convention, mixing int64\n",
      " |      and uint64 will result in a float64 dtype.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      A DataFrame where all columns are the same type (e.g., int64) results\n",
      " |      in an array of the same type.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'age':    [ 3,  29],\n",
      " |      ...                    'height': [94, 170],\n",
      " |      ...                    'weight': [31, 115]})\n",
      " |      >>> df\n",
      " |         age  height  weight\n",
      " |      0    3      94      31\n",
      " |      1   29     170     115\n",
      " |      >>> df.dtypes\n",
      " |      age       int64\n",
      " |      height    int64\n",
      " |      weight    int64\n",
      " |      dtype: object\n",
      " |      >>> df.values\n",
      " |      array([[  3,  94,  31],\n",
      " |             [ 29, 170, 115]])\n",
      " |\n",
      " |      A DataFrame with mixed type columns(e.g., str/object, int64, float32)\n",
      " |      results in an ndarray of the broadest type that accommodates these\n",
      " |      mixed types (e.g., object).\n",
      " |\n",
      " |      >>> df2 = pd.DataFrame([('parrot',   24.0, 'second'),\n",
      " |      ...                     ('lion',     80.5, 1),\n",
      " |      ...                     ('monkey', np.nan, None)],\n",
      " |      ...                   columns=('name', 'max_speed', 'rank'))\n",
      " |      >>> df2.dtypes\n",
      " |      name          object\n",
      " |      max_speed    float64\n",
      " |      rank          object\n",
      " |      dtype: object\n",
      " |      >>> df2.values\n",
      " |      array([['parrot', 24.0, 'second'],\n",
      " |             ['lion', 80.5, 1],\n",
      " |             ['monkey', nan, None]], dtype=object)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  columns\n",
      " |      The column labels of the DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
      " |      >>> df\n",
      " |           A  B\n",
      " |      0    1  3\n",
      " |      1    2  4\n",
      " |      >>> df.columns\n",
      " |      Index(['A', 'B'], dtype='object')\n",
      " |\n",
      " |  index\n",
      " |      The index (row labels) of the DataFrame.\n",
      " |\n",
      " |      The index of a DataFrame is a series of labels that identify each row.\n",
      " |      The labels can be integers, strings, or any other hashable type. The index\n",
      " |      is used for label-based access and alignment, and can be accessed or\n",
      " |      modified using this attribute.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Index\n",
      " |          The index labels of the DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.columns : The column labels of the DataFrame.\n",
      " |      DataFrame.to_numpy : Convert the DataFrame to a NumPy array.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Aritra'],\n",
      " |      ...                    'Age': [25, 30, 35],\n",
      " |      ...                    'Location': ['Seattle', 'New York', 'Kona']},\n",
      " |      ...                   index=([10, 20, 30]))\n",
      " |      >>> df.index\n",
      " |      Index([10, 20, 30], dtype='int64')\n",
      " |\n",
      " |      In this example, we create a DataFrame with 3 rows and 3 columns,\n",
      " |      including Name, Age, and Location information. We set the index labels to\n",
      " |      be the integers 10, 20, and 30. We then access the `index` attribute of the\n",
      " |      DataFrame, which returns an `Index` object containing the index labels.\n",
      " |\n",
      " |      >>> df.index = [100, 200, 300]\n",
      " |      >>> df\n",
      " |          Name  Age Location\n",
      " |      100  Alice   25  Seattle\n",
      " |      200    Bob   30 New York\n",
      " |      300  Aritra  35    Kona\n",
      " |\n",
      " |      In this example, we modify the index labels of the DataFrame by assigning\n",
      " |      a new list of labels to the `index` attribute. The DataFrame is then\n",
      " |      updated with the new labels, and the output shows the modified DataFrame.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {'_AXIS_ORDERS': \"list[Literal['index', 'columns']]\"...\n",
      " |\n",
      " |  __pandas_priority__ = 4000\n",
      " |\n",
      " |  plot = <class 'pandas.plotting._core.PlotAccessor'>\n",
      " |      Make plots of Series or DataFrame.\n",
      " |\n",
      " |      Uses the backend specified by the\n",
      " |      option ``plotting.backend``. By default, matplotlib is used.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or DataFrame\n",
      " |          The object for which the method is called.\n",
      " |      x : label or position, default None\n",
      " |          Only used if data is a DataFrame.\n",
      " |      y : label, position or list of label, positions, default None\n",
      " |          Allows plotting of one column versus another. Only used if data is a\n",
      " |          DataFrame.\n",
      " |      kind : str\n",
      " |          The kind of plot to produce:\n",
      " |\n",
      " |          - 'line' : line plot (default)\n",
      " |          - 'bar' : vertical bar plot\n",
      " |          - 'barh' : horizontal bar plot\n",
      " |          - 'hist' : histogram\n",
      " |          - 'box' : boxplot\n",
      " |          - 'kde' : Kernel Density Estimation plot\n",
      " |          - 'density' : same as 'kde'\n",
      " |          - 'area' : area plot\n",
      " |          - 'pie' : pie plot\n",
      " |          - 'scatter' : scatter plot (DataFrame only)\n",
      " |          - 'hexbin' : hexbin plot (DataFrame only)\n",
      " |      ax : matplotlib axes object, default None\n",
      " |          An axes of the current figure.\n",
      " |      subplots : bool or sequence of iterables, default False\n",
      " |          Whether to group columns into subplots:\n",
      " |\n",
      " |          - ``False`` : No subplots will be used\n",
      " |          - ``True`` : Make separate subplots for each column.\n",
      " |          - sequence of iterables of column labels: Create a subplot for each\n",
      " |            group of columns. For example `[('a', 'c'), ('b', 'd')]` will\n",
      " |            create 2 subplots: one with columns 'a' and 'c', and one\n",
      " |            with columns 'b' and 'd'. Remaining columns that aren't specified\n",
      " |            will be plotted in additional subplots (one per column).\n",
      " |\n",
      " |            .. versionadded:: 1.5.0\n",
      " |\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case ``subplots=True``, share x axis and set some x axis labels\n",
      " |          to invisible; defaults to True if ax is None otherwise False if\n",
      " |          an ax is passed in; Be aware, that passing in both an ax and\n",
      " |          ``sharex=True`` will alter all x axis labels for all axis in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case ``subplots=True``, share y axis and set some y axis labels to invisible.\n",
      " |      layout : tuple, optional\n",
      " |          (rows, columns) for the layout of subplots.\n",
      " |      figsize : a tuple (width, height) in inches\n",
      " |          Size of a figure object.\n",
      " |      use_index : bool, default True\n",
      " |          Use index as ticks for x axis.\n",
      " |      title : str or list\n",
      " |          Title to use for the plot. If a string is passed, print the string\n",
      " |          at the top of the figure. If a list is passed and `subplots` is\n",
      " |          True, print each item in the list above the corresponding subplot.\n",
      " |      grid : bool, default None (matlab style default)\n",
      " |          Axis grid lines.\n",
      " |      legend : bool or {'reverse'}\n",
      " |          Place legend on axis subplots.\n",
      " |      style : list or dict\n",
      " |          The matplotlib line style per column.\n",
      " |      logx : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on x axis.\n",
      " |\n",
      " |      logy : bool or 'sym' default False\n",
      " |          Use log scaling or symlog scaling on y axis.\n",
      " |\n",
      " |      loglog : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on both x and y axes.\n",
      " |\n",
      " |      xticks : sequence\n",
      " |          Values to use for the xticks.\n",
      " |      yticks : sequence\n",
      " |          Values to use for the yticks.\n",
      " |      xlim : 2-tuple/list\n",
      " |          Set the x limits of the current axes.\n",
      " |      ylim : 2-tuple/list\n",
      " |          Set the y limits of the current axes.\n",
      " |      xlabel : label, optional\n",
      " |          Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\n",
      " |          x-column name for planar plots.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |\n",
      " |              Now applicable to histograms.\n",
      " |\n",
      " |      ylabel : label, optional\n",
      " |          Name to use for the ylabel on y-axis. Default will show no ylabel, or the\n",
      " |          y-column name for planar plots.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |\n",
      " |              Now applicable to histograms.\n",
      " |\n",
      " |      rot : float, default None\n",
      " |          Rotation for ticks (xticks for vertical, yticks for horizontal\n",
      " |          plots).\n",
      " |      fontsize : float, default None\n",
      " |          Font size for xticks and yticks.\n",
      " |      colormap : str or matplotlib colormap object, default None\n",
      " |          Colormap to select colors from. If string, load colormap with that\n",
      " |          name from matplotlib.\n",
      " |      colorbar : bool, optional\n",
      " |          If True, plot colorbar (only relevant for 'scatter' and 'hexbin'\n",
      " |          plots).\n",
      " |      position : float\n",
      " |          Specify relative alignments for bar plot layout.\n",
      " |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |          (center).\n",
      " |      table : bool, Series or DataFrame, default False\n",
      " |          If True, draw a table using the data in the DataFrame and the data\n",
      " |          will be transposed to meet matplotlib's default layout.\n",
      " |          If a Series or DataFrame is passed, use passed data to draw a\n",
      " |          table.\n",
      " |      yerr : DataFrame, Series, array-like, dict and str\n",
      " |          See :ref:`Plotting with Error Bars <visualization.errorbars>` for\n",
      " |          detail.\n",
      " |      xerr : DataFrame, Series, array-like, dict and str\n",
      " |          Equivalent to yerr.\n",
      " |      stacked : bool, default False in line and bar plots, and True in area plot\n",
      " |          If True, create stacked plot.\n",
      " |      secondary_y : bool or sequence, default False\n",
      " |          Whether to plot on the secondary y-axis if a list/tuple, which\n",
      " |          columns to plot on secondary y-axis.\n",
      " |      mark_right : bool, default True\n",
      " |          When using a secondary_y axis, automatically mark the column\n",
      " |          labels with \"(right)\" in the legend.\n",
      " |      include_bool : bool, default is False\n",
      " |          If True, boolean values can be plotted.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      **kwargs\n",
      " |          Options to pass to matplotlib plotting method.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`matplotlib.axes.Axes` or numpy.ndarray of them\n",
      " |          If the backend is not the default matplotlib one, the return value\n",
      " |          will be the object returned by the backend.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      - See matplotlib documentation online for more on this subject\n",
      " |      - If `kind` = 'bar' or 'barh', you can specify relative alignments\n",
      " |        for bar plot layout by `position` keyword.\n",
      " |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |        (center)\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> ser = pd.Series([1, 2, 3, 3])\n",
      " |          >>> plot = ser.plot(kind='hist', title=\"My plot\")\n",
      " |\n",
      " |      For DataFrame:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> df = pd.DataFrame({'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...                   'width': [0.7, 0.2, 0.15, 0.2, 1.1]},\n",
      " |          ...                   index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> plot = df.plot(title=\"DataFrame Plot\")\n",
      " |\n",
      " |      For SeriesGroupBy:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> lst = [-1, -2, -3, 1, 2, 3]\n",
      " |          >>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)\n",
      " |          >>> plot = ser.groupby(lambda x: x > 0).plot(title=\"SeriesGroupBy Plot\")\n",
      " |\n",
      " |      For DataFrameGroupBy:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> df = pd.DataFrame({\"col1\" : [1, 2, 3, 4],\n",
      " |          ...                   \"col2\" : [\"A\", \"B\", \"A\", \"B\"]})\n",
      " |          >>> plot = df.groupby(\"col2\").plot(kind=\"bar\", title=\"DataFrameGroupBy Plot\")\n",
      " |\n",
      " |\n",
      " |  sparse = <class 'pandas.core.arrays.sparse.accessor.SparseFrameAccesso...\n",
      " |      DataFrame accessor for sparse data.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"a\": [1, 2, 0, 0],\n",
      " |      ...                   \"b\": [3, 0, 0, 4]}, dtype=\"Sparse[int]\")\n",
      " |      >>> df.sparse.density\n",
      " |      0.5\n",
      " |\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |\n",
      " |  __abs__(self) -> 'Self'\n",
      " |\n",
      " |  __array__(self, dtype: 'npt.DTypeLike | None' = None, copy: 'bool_t | None' = None) -> 'np.ndarray'\n",
      " |\n",
      " |  __array_ufunc__(self, ufunc: 'np.ufunc', method: 'str', *inputs: 'Any', **kwargs: 'Any')\n",
      " |\n",
      " |  __bool__ = __nonzero__(self) -> 'NoReturn'\n",
      " |\n",
      " |  __contains__(self, key) -> 'bool_t'\n",
      " |      True if the key is in the info axis\n",
      " |\n",
      " |  __copy__(self, deep: 'bool_t' = True) -> 'Self'\n",
      " |\n",
      " |  __deepcopy__(self, memo=None) -> 'Self'\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      memo, default None\n",
      " |          Standard signature. Unused\n",
      " |\n",
      " |  __delitem__(self, key) -> 'None'\n",
      " |      Delete item\n",
      " |\n",
      " |  __finalize__(self, other, method: 'str | None' = None, **kwargs) -> 'Self'\n",
      " |      Propagate metadata from other to self.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : str, optional\n",
      " |          A passed method name providing context on where ``__finalize__``\n",
      " |          was called.\n",
      " |\n",
      " |          .. warning::\n",
      " |\n",
      " |             The value passed as `method` are not currently considered\n",
      " |             stable across pandas releases.\n",
      " |\n",
      " |  __getattr__(self, name: 'str')\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |\n",
      " |  __getstate__(self) -> 'dict[str, Any]'\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __iadd__(self, other) -> 'Self'\n",
      " |\n",
      " |  __iand__(self, other) -> 'Self'\n",
      " |\n",
      " |  __ifloordiv__(self, other) -> 'Self'\n",
      " |\n",
      " |  __imod__(self, other) -> 'Self'\n",
      " |\n",
      " |  __imul__(self, other) -> 'Self'\n",
      " |\n",
      " |  __invert__(self) -> 'Self'\n",
      " |\n",
      " |  __ior__(self, other) -> 'Self'\n",
      " |\n",
      " |  __ipow__(self, other) -> 'Self'\n",
      " |\n",
      " |  __isub__(self, other) -> 'Self'\n",
      " |\n",
      " |  __iter__(self) -> 'Iterator'\n",
      " |      Iterate over info axis.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |          Info axis as iterator.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
      " |      >>> for x in df:\n",
      " |      ...     print(x)\n",
      " |      A\n",
      " |      B\n",
      " |\n",
      " |  __itruediv__(self, other) -> 'Self'\n",
      " |\n",
      " |  __ixor__(self, other) -> 'Self'\n",
      " |\n",
      " |  __neg__(self) -> 'Self'\n",
      " |\n",
      " |  __nonzero__(self) -> 'NoReturn'\n",
      " |\n",
      " |  __pos__(self) -> 'Self'\n",
      " |\n",
      " |  __round__(self, decimals: 'int' = 0) -> 'Self'\n",
      " |\n",
      " |  __setattr__(self, name: 'str', value) -> 'None'\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |\n",
      " |  __setstate__(self, state) -> 'None'\n",
      " |\n",
      " |  abs(self) -> 'Self'\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |\n",
      " |      This function only applies to elements that are all numeric.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : Calculate the absolute value element-wise.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |\n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |\n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |\n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |\n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |\n",
      " |  add_prefix(self, prefix: 'str', axis: 'Axis | None' = None) -> 'Self'\n",
      " |      Prefix labels with string `prefix`.\n",
      " |\n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Axis to add prefix on\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |\n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |\n",
      " |  add_suffix(self, suffix: 'str', axis: 'Axis | None' = None) -> 'Self'\n",
      " |      Suffix labels with string `suffix`.\n",
      " |\n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Axis to add suffix on\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |\n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |\n",
      " |  align(self, other: 'NDFrameT', join: 'AlignJoin' = 'outer', axis: 'Axis | None' = None, level: 'Level | None' = None, copy: 'bool_t | None' = None, fill_value: 'Hashable | None' = None, method: 'FillnaOptions | None | lib.NoDefault' = <no_default>, limit: 'int | None | lib.NoDefault' = <no_default>, fill_axis: 'Axis | lib.NoDefault' = <no_default>, broadcast_axis: 'Axis | None | lib.NoDefault' = <no_default>) -> 'tuple[Self, NDFrameT]'\n",
      " |      Align two objects on their axes with the specified join method.\n",
      " |\n",
      " |      Join method is specified for each axis Index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |          Type of alignment to be performed.\n",
      " |\n",
      " |          * left: use only keys from left frame, preserve key order.\n",
      " |          * right: use only keys from right frame, preserve key order.\n",
      " |          * outer: use union of keys from both frames, sort keys lexicographically.\n",
      " |          * inner: use intersection of keys from both frames,\n",
      " |            preserve the order of the left keys.\n",
      " |\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None).\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      copy : bool, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      fill_value : scalar, default np.nan\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series:\n",
      " |\n",
      " |          - pad / ffill: propagate last valid observation forward to next valid.\n",
      " |          - backfill / bfill: use NEXT valid observation to fill gap.\n",
      " |\n",
      " |          .. deprecated:: 2.1\n",
      " |\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |\n",
      " |          .. deprecated:: 2.1\n",
      " |\n",
      " |      fill_axis : {0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame, default 0\n",
      " |          Filling axis, method and limit.\n",
      " |\n",
      " |          .. deprecated:: 2.1\n",
      " |\n",
      " |      broadcast_axis : {0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions.\n",
      " |\n",
      " |          .. deprecated:: 2.1\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple of (Series/DataFrame, type of other)\n",
      " |          Aligned objects.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [[1, 2, 3, 4], [6, 7, 8, 9]], columns=[\"D\", \"B\", \"E\", \"A\"], index=[1, 2]\n",
      " |      ... )\n",
      " |      >>> other = pd.DataFrame(\n",
      " |      ...     [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],\n",
      " |      ...     columns=[\"A\", \"B\", \"C\", \"D\"],\n",
      " |      ...     index=[2, 3, 4],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |         D  B  E  A\n",
      " |      1  1  2  3  4\n",
      " |      2  6  7  8  9\n",
      " |      >>> other\n",
      " |          A    B    C    D\n",
      " |      2   10   20   30   40\n",
      " |      3   60   70   80   90\n",
      " |      4  600  700  800  900\n",
      " |\n",
      " |      Align on columns:\n",
      " |\n",
      " |      >>> left, right = df.align(other, join=\"outer\", axis=1)\n",
      " |      >>> left\n",
      " |         A  B   C  D  E\n",
      " |      1  4  2 NaN  1  3\n",
      " |      2  9  7 NaN  6  8\n",
      " |      >>> right\n",
      " |          A    B    C    D   E\n",
      " |      2   10   20   30   40 NaN\n",
      " |      3   60   70   80   90 NaN\n",
      " |      4  600  700  800  900 NaN\n",
      " |\n",
      " |      We can also align on the index:\n",
      " |\n",
      " |      >>> left, right = df.align(other, join=\"outer\", axis=0)\n",
      " |      >>> left\n",
      " |          D    B    E    A\n",
      " |      1  1.0  2.0  3.0  4.0\n",
      " |      2  6.0  7.0  8.0  9.0\n",
      " |      3  NaN  NaN  NaN  NaN\n",
      " |      4  NaN  NaN  NaN  NaN\n",
      " |      >>> right\n",
      " |          A      B      C      D\n",
      " |      1    NaN    NaN    NaN    NaN\n",
      " |      2   10.0   20.0   30.0   40.0\n",
      " |      3   60.0   70.0   80.0   90.0\n",
      " |      4  600.0  700.0  800.0  900.0\n",
      " |\n",
      " |      Finally, the default `axis=None` will align on both index and columns:\n",
      " |\n",
      " |      >>> left, right = df.align(other, join=\"outer\", axis=None)\n",
      " |      >>> left\n",
      " |           A    B   C    D    E\n",
      " |      1  4.0  2.0 NaN  1.0  3.0\n",
      " |      2  9.0  7.0 NaN  6.0  8.0\n",
      " |      3  NaN  NaN NaN  NaN  NaN\n",
      " |      4  NaN  NaN NaN  NaN  NaN\n",
      " |      >>> right\n",
      " |             A      B      C      D   E\n",
      " |      1    NaN    NaN    NaN    NaN NaN\n",
      " |      2   10.0   20.0   30.0   40.0 NaN\n",
      " |      3   60.0   70.0   80.0   90.0 NaN\n",
      " |      4  600.0  700.0  800.0  900.0 NaN\n",
      " |\n",
      " |  asfreq(self, freq: 'Frequency', method: 'FillnaOptions | None' = None, how: \"Literal['start', 'end'] | None\" = None, normalize: 'bool_t' = False, fill_value: 'Hashable | None' = None) -> 'Self'\n",
      " |      Convert time series to specified frequency.\n",
      " |\n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency.\n",
      " |\n",
      " |      If the index of this Series/DataFrame is a :class:`~pandas.PeriodIndex`, the new index\n",
      " |      is the result of transforming the original index with\n",
      " |      :meth:`PeriodIndex.asfreq <pandas.PeriodIndex.asfreq>` (so the original index\n",
      " |      will map one-to-one to the new index).\n",
      " |\n",
      " |      Otherwise, the new index will be equivalent to ``pd.date_range(start, end,\n",
      " |      freq=freq)`` where ``start`` and ``end`` are, respectively, the first and\n",
      " |      last entries in the original index (see :func:`pandas.date_range`). The\n",
      " |      values corresponding to any timesteps in the new index which were not present\n",
      " |      in the original index will be null (``NaN``), unless a method for filling\n",
      " |      such unknowns is provided (see the ``method`` parameter below).\n",
      " |\n",
      " |      The :meth:`resample` method is more appropriate if an operation on each group of\n",
      " |      timesteps (such as an aggregate) is necessary to represent the data at the new\n",
      " |      frequency.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset or str\n",
      " |          Frequency DateOffset or string.\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |\n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill.\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only (see PeriodIndex.asfreq).\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight.\n",
      " |      fill_value : scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Series/DataFrame object reindexed to the specified frequency.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex : Conform DataFrame to new index with optional filling logic.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |\n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='min')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s': series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |\n",
      " |      Upsample the series into 30 second bins.\n",
      " |\n",
      " |      >>> df.asfreq(freq='30s')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |\n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |\n",
      " |      >>> df.asfreq(freq='30s', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |\n",
      " |      Upsample again, providing a ``method``.\n",
      " |\n",
      " |      >>> df.asfreq(freq='30s', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |\n",
      " |  asof(self, where, subset=None)\n",
      " |      Return the last row(s) without any NaNs before `where`.\n",
      " |\n",
      " |      The last row (for each element in `where`, if list) without any\n",
      " |      NaN is taken.\n",
      " |      In case of a :class:`~pandas.DataFrame`, the last row without NaN\n",
      " |      considering only the subset of columns (if not `None`)\n",
      " |\n",
      " |      If there is no good value, NaN is returned for a Series or\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array-like of dates\n",
      " |          Date(s) before which the last row(s) are returned.\n",
      " |      subset : str or array-like of str, default `None`\n",
      " |          For DataFrame, if not `None`, only use these columns to\n",
      " |          check for NaNs.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series, or DataFrame\n",
      " |\n",
      " |          The return can be:\n",
      " |\n",
      " |          * scalar : when `self` is a Series and `where` is a scalar\n",
      " |          * Series: when `self` is a Series and `where` is an array-like,\n",
      " |            or when `self` is a DataFrame and `where` is a scalar\n",
      " |          * DataFrame : when `self` is a DataFrame and `where` is an\n",
      " |            array-like\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof : Perform an asof merge. Similar to left join.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted. Raises if this is not the case.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      A Series and a scalar `where`.\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])\n",
      " |      >>> s\n",
      " |      10    1.0\n",
      " |      20    2.0\n",
      " |      30    NaN\n",
      " |      40    4.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.asof(20)\n",
      " |      2.0\n",
      " |\n",
      " |      For a sequence `where`, a Series is returned. The first value is\n",
      " |      NaN, because the first element of `where` is before the first\n",
      " |      index value.\n",
      " |\n",
      " |      >>> s.asof([5, 20])\n",
      " |      5     NaN\n",
      " |      20    2.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Missing values are not considered. The following is ``2.0``, not\n",
      " |      NaN, even though NaN is at the index location for ``30``.\n",
      " |\n",
      " |      >>> s.asof(30)\n",
      " |      2.0\n",
      " |\n",
      " |      Take all columns into consideration\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'a': [10., 20., 30., 40., 50.],\n",
      " |      ...                    'b': [None, None, None, None, 500]},\n",
      " |      ...                   index=pd.DatetimeIndex(['2018-02-27 09:01:00',\n",
      " |      ...                                           '2018-02-27 09:02:00',\n",
      " |      ...                                           '2018-02-27 09:03:00',\n",
      " |      ...                                           '2018-02-27 09:04:00',\n",
      " |      ...                                           '2018-02-27 09:05:00']))\n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']))\n",
      " |                            a   b\n",
      " |      2018-02-27 09:03:30 NaN NaN\n",
      " |      2018-02-27 09:04:30 NaN NaN\n",
      " |\n",
      " |      Take a single column into consideration\n",
      " |\n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']),\n",
      " |      ...         subset=['a'])\n",
      " |                              a   b\n",
      " |      2018-02-27 09:03:30  30.0 NaN\n",
      " |      2018-02-27 09:04:30  40.0 NaN\n",
      " |\n",
      " |  astype(self, dtype, copy: 'bool_t | None' = None, errors: 'IgnoreRaise' = 'raise') -> 'Self'\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str, data type, Series or Mapping of column name -> data type\n",
      " |          Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to\n",
      " |          cast entire pandas object to the same type. Alternatively, use a\n",
      " |          mapping, e.g. {col: dtype, ...}, where col is a column label and dtype is\n",
      " |          a numpy.dtype or Python type to cast one or more of the DataFrame's\n",
      " |          columns to column-specific types.\n",
      " |      copy : bool, default True\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |\n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. versionchanged:: 2.0.0\n",
      " |\n",
      " |          Using ``astype`` to convert from timezone-naive dtype to\n",
      " |          timezone-aware dtype will raise an exception.\n",
      " |          Use :meth:`Series.dt.tz_localize` instead.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create a DataFrame:\n",
      " |\n",
      " |      >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |\n",
      " |      Cast all columns to int32:\n",
      " |\n",
      " |      >>> df.astype('int32').dtypes\n",
      " |      col1    int32\n",
      " |      col2    int32\n",
      " |      dtype: object\n",
      " |\n",
      " |      Cast col1 to int32 using a dictionary:\n",
      " |\n",
      " |      >>> df.astype({'col1': 'int32'}).dtypes\n",
      " |      col1    int32\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |\n",
      " |      Create a series:\n",
      " |\n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Convert to categorical type:\n",
      " |\n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int32): [1, 2]\n",
      " |\n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |\n",
      " |      >>> from pandas.api.types import CategoricalDtype\n",
      " |      >>> cat_dtype = CategoricalDtype(\n",
      " |      ...     categories=[2, 1], ordered=True)\n",
      " |      >>> ser.astype(cat_dtype)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |\n",
      " |      Create a series of dates:\n",
      " |\n",
      " |      >>> ser_date = pd.Series(pd.date_range('20200101', periods=3))\n",
      " |      >>> ser_date\n",
      " |      0   2020-01-01\n",
      " |      1   2020-01-02\n",
      " |      2   2020-01-03\n",
      " |      dtype: datetime64[ns]\n",
      " |\n",
      " |  at_time(self, time, asof: 'bool_t' = False, axis: 'Axis | None' = None) -> 'Self'\n",
      " |      Select values at particular time of day (e.g., 9:30AM).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or str\n",
      " |          The values to select.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12h')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |\n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |\n",
      " |  backfill(self, *, axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast: 'dict | None | lib.NoDefault' = <no_default>) -> 'Self | None'\n",
      " |      Fill NA/NaN values by using the next valid observation to fill the gap.\n",
      " |\n",
      " |      .. deprecated:: 2.0\n",
      " |\n",
      " |          Series/DataFrame.backfill is deprecated. Use Series/DataFrame.bfill instead.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Please see examples for :meth:`DataFrame.bfill` or :meth:`Series.bfill`.\n",
      " |\n",
      " |  between_time(self, start_time, end_time, inclusive: 'IntervalClosedType' = 'both', axis: 'Axis | None' = None) -> 'Self'\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |\n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or str\n",
      " |          Initial time as a time filter limit.\n",
      " |      end_time : datetime.time or str\n",
      " |          End time as a time filter limit.\n",
      " |      inclusive : {\"both\", \"neither\", \"left\", \"right\"}, default \"both\"\n",
      " |          Include boundaries; whether to set each bound as closed or open.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine range time on index or columns value.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Data from the original object filtered to the specified dates range.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |\n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |\n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |\n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |\n",
      " |  bfill(self, *, axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, limit_area: \"Literal['inside', 'outside'] | None\" = None, downcast: 'dict | None | lib.NoDefault' = <no_default>) -> 'Self | None'\n",
      " |      Fill NA/NaN values by using the next valid observation to fill the gap.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\n",
      " |          Axis along which to fill missing values. For `Series`\n",
      " |          this parameter is unused and defaults to 0.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      limit_area : {`None`, 'inside', 'outside'}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |\n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |\n",
      " |          .. versionadded:: 2.2.0\n",
      " |\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |\n",
      " |          .. deprecated:: 2.2.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      >>> s = pd.Series([1, None, None, 2])\n",
      " |      >>> s.bfill()\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      2    2.0\n",
      " |      3    2.0\n",
      " |      dtype: float64\n",
      " |      >>> s.bfill(limit=1)\n",
      " |      0    1.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3    2.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      With DataFrame:\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [1, None, None, 4], 'B': [None, 5, None, 7]})\n",
      " |      >>> df\n",
      " |            A     B\n",
      " |      0   1.0   NaN\n",
      " |      1   NaN   5.0\n",
      " |      2   NaN   NaN\n",
      " |      3   4.0   7.0\n",
      " |      >>> df.bfill()\n",
      " |            A     B\n",
      " |      0   1.0   5.0\n",
      " |      1   4.0   5.0\n",
      " |      2   4.0   7.0\n",
      " |      3   4.0   7.0\n",
      " |      >>> df.bfill(limit=1)\n",
      " |            A     B\n",
      " |      0   1.0   5.0\n",
      " |      1   NaN   5.0\n",
      " |      2   4.0   7.0\n",
      " |      3   4.0   7.0\n",
      " |\n",
      " |  bool(self) -> 'bool_t'\n",
      " |      Return the bool of a single element Series or DataFrame.\n",
      " |\n",
      " |      .. deprecated:: 2.1.0\n",
      " |\n",
      " |         bool is deprecated and will be removed in future version of pandas.\n",
      " |         For ``Series`` use ``pandas.Series.item``.\n",
      " |\n",
      " |      This must be a boolean scalar value, either True or False. It will raise a\n",
      " |      ValueError if the Series or DataFrame does not have exactly 1 element, or that\n",
      " |      element is not boolean (integer values 0 and 1 will also raise an exception).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          The value in the Series or DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.astype : Change the data type of a Series, including to boolean.\n",
      " |      DataFrame.astype : Change the data type of a DataFrame, including to boolean.\n",
      " |      numpy.bool_ : NumPy boolean data type, used by pandas for boolean values.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      The method will only work for single element objects with a boolean value:\n",
      " |\n",
      " |      >>> pd.Series([True]).bool()  # doctest: +SKIP\n",
      " |      True\n",
      " |      >>> pd.Series([False]).bool()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |      >>> pd.DataFrame({'col': [True]}).bool()  # doctest: +SKIP\n",
      " |      True\n",
      " |      >>> pd.DataFrame({'col': [False]}).bool()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |      This is an alternative method and will only work\n",
      " |      for single element objects with a boolean value:\n",
      " |\n",
      " |      >>> pd.Series([True]).item()  # doctest: +SKIP\n",
      " |      True\n",
      " |      >>> pd.Series([False]).item()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |  clip(self, lower=None, upper=None, *, axis: 'Axis | None' = None, inplace: 'bool_t' = False, **kwargs) -> 'Self | None'\n",
      " |      Trim values at input threshold(s).\n",
      " |\n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array-like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      upper : float or array-like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |          For `Series` this parameter is unused and defaults to `None`.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.clip : Trim values at input threshold in series.\n",
      " |      DataFrame.clip : Trim values at input threshold in dataframe.\n",
      " |      numpy.clip : Clip (limit) the values in an array.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |\n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |\n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |\n",
      " |      Clips using specific lower and upper thresholds per column:\n",
      " |\n",
      " |      >>> df.clip([-2, -1], [4, 5])\n",
      " |          col_0  col_1\n",
      " |      0      4     -1\n",
      " |      1     -2     -1\n",
      " |      2      0      5\n",
      " |      3     -1      5\n",
      " |      4      4     -1\n",
      " |\n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |\n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |\n",
      " |      Clips using specific lower threshold per column element, with missing values:\n",
      " |\n",
      " |      >>> t = pd.Series([2, -4, np.nan, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2.0\n",
      " |      1   -4.0\n",
      " |      2    NaN\n",
      " |      3    6.0\n",
      " |      4    3.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> df.clip(t, axis=0)\n",
      " |      col_0  col_1\n",
      " |      0      9      2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |\n",
      " |  convert_dtypes(self, infer_objects: 'bool_t' = True, convert_string: 'bool_t' = True, convert_integer: 'bool_t' = True, convert_boolean: 'bool_t' = True, convert_floating: 'bool_t' = True, dtype_backend: 'DtypeBackend' = 'numpy_nullable') -> 'Self'\n",
      " |      Convert columns to the best possible dtypes using dtypes supporting ``pd.NA``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      infer_objects : bool, default True\n",
      " |          Whether object dtypes should be converted to the best possible types.\n",
      " |      convert_string : bool, default True\n",
      " |          Whether object dtypes should be converted to ``StringDtype()``.\n",
      " |      convert_integer : bool, default True\n",
      " |          Whether, if possible, conversion can be done to integer extension types.\n",
      " |      convert_boolean : bool, defaults True\n",
      " |          Whether object dtypes should be converted to ``BooleanDtypes()``.\n",
      " |      convert_floating : bool, defaults True\n",
      " |          Whether, if possible, conversion can be done to floating extension types.\n",
      " |          If `convert_integer` is also True, preference will be give to integer\n",
      " |          dtypes if the floats can be faithfully casted to integers.\n",
      " |      dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      " |          Back-end data type applied to the resultant :class:`DataFrame`\n",
      " |          (still experimental). Behaviour is as follows:\n",
      " |\n",
      " |          * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      " |            (default).\n",
      " |          * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      " |            DataFrame.\n",
      " |\n",
      " |          .. versionadded:: 2.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Copy of input object with new dtype.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      infer_objects : Infer dtypes of objects.\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, ``convert_dtypes`` will attempt to convert a Series (or each\n",
      " |      Series in a DataFrame) to dtypes that support ``pd.NA``. By using the options\n",
      " |      ``convert_string``, ``convert_integer``, ``convert_boolean`` and\n",
      " |      ``convert_floating``, it is possible to turn off individual conversions\n",
      " |      to ``StringDtype``, the integer extension types, ``BooleanDtype``\n",
      " |      or floating extension types, respectively.\n",
      " |\n",
      " |      For object-dtyped columns, if ``infer_objects`` is ``True``, use the inference\n",
      " |      rules as during normal Series/DataFrame construction.  Then, if possible,\n",
      " |      convert to ``StringDtype``, ``BooleanDtype`` or an appropriate integer\n",
      " |      or floating extension type, otherwise leave as ``object``.\n",
      " |\n",
      " |      If the dtype is integer, convert to an appropriate integer extension type.\n",
      " |\n",
      " |      If the dtype is numeric, and consists of all integers, convert to an\n",
      " |      appropriate integer extension type. Otherwise, convert to an\n",
      " |      appropriate floating extension type.\n",
      " |\n",
      " |      In the future, as new dtypes are added that support ``pd.NA``, the results\n",
      " |      of this method will change to support those new dtypes.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n",
      " |      ...         \"b\": pd.Series([\"x\", \"y\", \"z\"], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"c\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"d\": pd.Series([\"h\", \"i\", np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"e\": pd.Series([10, np.nan, 20], dtype=np.dtype(\"float\")),\n",
      " |      ...         \"f\": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(\"float\")),\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |\n",
      " |      Start with a DataFrame with default dtypes.\n",
      " |\n",
      " |      >>> df\n",
      " |         a  b      c    d     e      f\n",
      " |      0  1  x   True    h  10.0    NaN\n",
      " |      1  2  y  False    i   NaN  100.5\n",
      " |      2  3  z    NaN  NaN  20.0  200.0\n",
      " |\n",
      " |      >>> df.dtypes\n",
      " |      a      int32\n",
      " |      b     object\n",
      " |      c     object\n",
      " |      d     object\n",
      " |      e    float64\n",
      " |      f    float64\n",
      " |      dtype: object\n",
      " |\n",
      " |      Convert the DataFrame to use best possible dtypes.\n",
      " |\n",
      " |      >>> dfn = df.convert_dtypes()\n",
      " |      >>> dfn\n",
      " |         a  b      c     d     e      f\n",
      " |      0  1  x   True     h    10   <NA>\n",
      " |      1  2  y  False     i  <NA>  100.5\n",
      " |      2  3  z   <NA>  <NA>    20  200.0\n",
      " |\n",
      " |      >>> dfn.dtypes\n",
      " |      a             Int32\n",
      " |      b    string[python]\n",
      " |      c           boolean\n",
      " |      d    string[python]\n",
      " |      e             Int64\n",
      " |      f           Float64\n",
      " |      dtype: object\n",
      " |\n",
      " |      Start with a Series of strings and missing data represented by ``np.nan``.\n",
      " |\n",
      " |      >>> s = pd.Series([\"a\", \"b\", np.nan])\n",
      " |      >>> s\n",
      " |      0      a\n",
      " |      1      b\n",
      " |      2    NaN\n",
      " |      dtype: object\n",
      " |\n",
      " |      Obtain a Series with dtype ``StringDtype``.\n",
      " |\n",
      " |      >>> s.convert_dtypes()\n",
      " |      0       a\n",
      " |      1       b\n",
      " |      2    <NA>\n",
      " |      dtype: string\n",
      " |\n",
      " |  copy(self, deep: 'bool_t | None' = True) -> 'Self'\n",
      " |      Make a copy of this object's indices and data.\n",
      " |\n",
      " |      When ``deep=True`` (default), a new object will be created with a\n",
      " |      copy of the calling object's data and indices. Modifications to\n",
      " |      the data or indices of the copy will not be reflected in the\n",
      " |      original object (see notes below).\n",
      " |\n",
      " |      When ``deep=False``, a new object will be created without copying\n",
      " |      the calling object's data or index (only references to the data\n",
      " |      and index are copied). Any changes to the data of the original\n",
      " |      will be reflected in the shallow copy (and vice versa).\n",
      " |\n",
      " |      .. note::\n",
      " |          The ``deep=False`` behaviour as described above will change\n",
      " |          in pandas 3.0. `Copy-on-Write\n",
      " |          <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |          will be enabled by default, which means that the \"shallow\" copy\n",
      " |          is that is returned with ``deep=False`` will still avoid making\n",
      " |          an eager copy, but changes to the data of the original will *no*\n",
      " |          longer be reflected in the shallow copy (or vice versa). Instead,\n",
      " |          it makes use of a lazy (deferred) copy mechanism that will copy\n",
      " |          the data only when any changes to the original or shallow copy is\n",
      " |          made.\n",
      " |\n",
      " |          You can already get the future behavior and improvements through\n",
      " |          enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices nor the data are copied.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object type matches caller.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``deep=True``, data is copied but actual Python objects\n",
      " |      will not be copied recursively, only the reference to the object.\n",
      " |      This is in contrast to `copy.deepcopy` in the Standard Library,\n",
      " |      which recursively copies object data (see examples below).\n",
      " |\n",
      " |      While ``Index`` objects are copied when ``deep=True``, the underlying\n",
      " |      numpy array is not copied for performance reasons. Since ``Index`` is\n",
      " |      immutable, the underlying data can be safely shared and a copy\n",
      " |      is not needed.\n",
      " |\n",
      " |      Since pandas is not thread safe, see the\n",
      " |      :ref:`gotchas <gotchas.thread-safety>` when copying in a threading\n",
      " |      environment.\n",
      " |\n",
      " |      When ``copy_on_write`` in pandas config is set to ``True``, the\n",
      " |      ``copy_on_write`` config takes effect even when ``deep=False``.\n",
      " |      This means that any changes to the copied data would make a new copy\n",
      " |      of the data upon write (and vice versa). Changes made to either the\n",
      " |      original or copied variable would not be reflected in the counterpart.\n",
      " |      See :ref:`Copy_on_Write <copy_on_write>` for more information.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> s\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s_copy = s.copy()\n",
      " |      >>> s_copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      **Shallow copy versus default (deep) copy:**\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> shallow = s.copy(deep=False)\n",
      " |\n",
      " |      Shallow copy shares data and index with original.\n",
      " |\n",
      " |      >>> s is shallow\n",
      " |      False\n",
      " |      >>> s.values is shallow.values and s.index is shallow.index\n",
      " |      True\n",
      " |\n",
      " |      Deep copy has own copy of data and index.\n",
      " |\n",
      " |      >>> s is deep\n",
      " |      False\n",
      " |      >>> s.values is deep.values or s.index is deep.index\n",
      " |      False\n",
      " |\n",
      " |      Updates to the data shared by shallow copy and original is reflected\n",
      " |      in both (NOTE: this will no longer be true for pandas >= 3.0);\n",
      " |      deep copy remains unchanged.\n",
      " |\n",
      " |      >>> s.iloc[0] = 3\n",
      " |      >>> shallow.iloc[1] = 4\n",
      " |      >>> s\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> shallow\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> deep\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Note that when copying an object containing Python objects, a deep copy\n",
      " |      will copy the data, but will not do so recursively. Updating a nested\n",
      " |      data object will be reflected in the deep copy.\n",
      " |\n",
      " |      >>> s = pd.Series([[1, 2], [3, 4]])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> s[0][0] = 10\n",
      " |      >>> s\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |      >>> deep\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |\n",
      " |      **Copy-on-Write is set to true**, the shallow copy is not modified\n",
      " |      when the original data is changed:\n",
      " |\n",
      " |      >>> with pd.option_context(\"mode.copy_on_write\", True):\n",
      " |      ...     s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      ...     copy = s.copy(deep=False)\n",
      " |      ...     s.iloc[0] = 100\n",
      " |      ...     s\n",
      " |      a    100\n",
      " |      b      2\n",
      " |      dtype: int64\n",
      " |      >>> copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |  describe(self, percentiles=None, include=None, exclude=None) -> 'Self'\n",
      " |      Generate descriptive statistics.\n",
      " |\n",
      " |      Descriptive statistics include those that summarize the central\n",
      " |      tendency, dispersion and shape of a\n",
      " |      dataset's distribution, excluding ``NaN`` values.\n",
      " |\n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |\n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |\n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(exclude=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the observations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |\n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |\n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |\n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |\n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Describing a categorical ``Series``.\n",
      " |\n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |\n",
      " |      Describing a timestamp ``Series``.\n",
      " |\n",
      " |      >>> s = pd.Series([\n",
      " |      ...     np.datetime64(\"2000-01-01\"),\n",
      " |      ...     np.datetime64(\"2010-01-01\"),\n",
      " |      ...     np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                      3\n",
      " |      mean     2006-09-01 08:00:00\n",
      " |      min      2000-01-01 00:00:00\n",
      " |      25%      2004-12-31 12:00:00\n",
      " |      50%      2010-01-01 00:00:00\n",
      " |      75%      2010-01-01 00:00:00\n",
      " |      max      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |\n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d', 'e', 'f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                    })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |\n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |\n",
      " |      >>> df.describe(include='all')  # doctest: +SKIP\n",
      " |             categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      a\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |\n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |\n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |\n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |\n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |\n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |\n",
      " |      >>> df.describe(include=[object])  # doctest: +SKIP\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         a\n",
      " |      freq        1\n",
      " |\n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |\n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              d\n",
      " |      freq             1\n",
      " |\n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |\n",
      " |      >>> df.describe(exclude=[np.number])  # doctest: +SKIP\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      a\n",
      " |      freq             1      1\n",
      " |\n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |\n",
      " |      >>> df.describe(exclude=[object])  # doctest: +SKIP\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |\n",
      " |  droplevel(self, level: 'IndexLabel', axis: 'Axis' = 0) -> 'Self'\n",
      " |      Return Series/DataFrame with requested index / column level(s) removed.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list-like\n",
      " |          If a string is given, must be the name of a level\n",
      " |          If list-like, elements must be names or positional indexes\n",
      " |          of levels.\n",
      " |\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the level(s) is removed:\n",
      " |\n",
      " |          * 0 or 'index': remove level(s) in column.\n",
      " |          * 1 or 'columns': remove level(s) in row.\n",
      " |\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Series/DataFrame with requested index / column level(s) removed.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([\n",
      " |      ...     [1, 2, 3, 4],\n",
      " |      ...     [5, 6, 7, 8],\n",
      " |      ...     [9, 10, 11, 12]\n",
      " |      ... ]).set_index([0, 1]).rename_axis(['a', 'b'])\n",
      " |\n",
      " |      >>> df.columns = pd.MultiIndex.from_tuples([\n",
      " |      ...     ('c', 'e'), ('d', 'f')\n",
      " |      ... ], names=['level_1', 'level_2'])\n",
      " |\n",
      " |      >>> df\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |\n",
      " |      >>> df.droplevel('a')\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      b\n",
      " |      2        3   4\n",
      " |      6        7   8\n",
      " |      10      11  12\n",
      " |\n",
      " |      >>> df.droplevel('level_2', axis=1)\n",
      " |      level_1   c   d\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |\n",
      " |  equals(self, other: 'object') -> 'bool_t'\n",
      " |      Test whether two objects contain the same elements.\n",
      " |\n",
      " |      This function allows two Series or DataFrames to be compared against\n",
      " |      each other to see if they have the same shape and elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |\n",
      " |      The row/column index do not need to have the same type, as long\n",
      " |      as the values are considered equal. Corresponding columns and\n",
      " |      index must be of the same dtype.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |          The other Series or DataFrame to be compared with the first.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if all elements are the same in both objects, False\n",
      " |          otherwise.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.eq : Compare two Series objects of the same length\n",
      " |          and return a Series where each element is True if the element\n",
      " |          in each Series is equal, False otherwise.\n",
      " |      DataFrame.eq : Compare two DataFrame objects of the same shape and\n",
      " |          return a DataFrame where each element is True if the respective\n",
      " |          element in each DataFrame is equal, False otherwise.\n",
      " |      testing.assert_series_equal : Raises an AssertionError if left and\n",
      " |          right are not equal. Provides an easy interface to ignore\n",
      " |          inequality in dtypes, indexes and precision among others.\n",
      " |      testing.assert_frame_equal : Like assert_series_equal, but targets\n",
      " |          DataFrames.\n",
      " |      numpy.array_equal : Return True if two arrays have the same shape\n",
      " |          and elements, False otherwise.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> df\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |\n",
      " |      DataFrames df and exactly_equal have the same types and values for\n",
      " |      their elements and column labels, which will return True.\n",
      " |\n",
      " |      >>> exactly_equal = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> exactly_equal\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      >>> df.equals(exactly_equal)\n",
      " |      True\n",
      " |\n",
      " |      DataFrames df and different_column_type have the same element\n",
      " |      types and values, but have different types for the column labels,\n",
      " |      which will still return True.\n",
      " |\n",
      " |      >>> different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})\n",
      " |      >>> different_column_type\n",
      " |         1.0  2.0\n",
      " |      0   10   20\n",
      " |      >>> df.equals(different_column_type)\n",
      " |      True\n",
      " |\n",
      " |      DataFrames df and different_data_type have different types for the\n",
      " |      same values for their elements, and will return False even though\n",
      " |      their column labels are the same values and types.\n",
      " |\n",
      " |      >>> different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})\n",
      " |      >>> different_data_type\n",
      " |            1     2\n",
      " |      0  10.0  20.0\n",
      " |      >>> df.equals(different_data_type)\n",
      " |      False\n",
      " |\n",
      " |  ewm(self, com: 'float | None' = None, span: 'float | None' = None, halflife: 'float | TimedeltaConvertibleTypes | None' = None, alpha: 'float | None' = None, min_periods: 'int | None' = 0, adjust: 'bool_t' = True, ignore_na: 'bool_t' = False, axis: 'Axis | lib.NoDefault' = <no_default>, times: 'np.ndarray | DataFrame | Series | None' = None, method: \"Literal['single', 'table']\" = 'single') -> 'ExponentialMovingWindow'\n",
      " |      Provide exponentially weighted (EW) calculations.\n",
      " |\n",
      " |      Exactly one of ``com``, ``span``, ``halflife``, or ``alpha`` must be\n",
      " |      provided if ``times`` is not provided. If ``times`` is provided,\n",
      " |      ``halflife`` and one of ``com``, ``span`` or ``alpha`` may be provided.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass\n",
      " |\n",
      " |          :math:`\\alpha = 1 / (1 + com)`, for :math:`com \\geq 0`.\n",
      " |\n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span\n",
      " |\n",
      " |          :math:`\\alpha = 2 / (span + 1)`, for :math:`span \\geq 1`.\n",
      " |\n",
      " |      halflife : float, str, timedelta, optional\n",
      " |          Specify decay in terms of half-life\n",
      " |\n",
      " |          :math:`\\alpha = 1 - \\exp\\left(-\\ln(2) / halflife\\right)`, for\n",
      " |          :math:`halflife > 0`.\n",
      " |\n",
      " |          If ``times`` is specified, a timedelta convertible unit over which an\n",
      " |          observation decays to half its value. Only applicable to ``mean()``,\n",
      " |          and halflife value will not apply to the other functions.\n",
      " |\n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly\n",
      " |\n",
      " |          :math:`0 < \\alpha \\leq 1`.\n",
      " |\n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |\n",
      " |      adjust : bool, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average).\n",
      " |\n",
      " |          - When ``adjust=True`` (default), the EW function is calculated using weights\n",
      " |            :math:`w_i = (1 - \\alpha)^i`. For example, the EW moving average of the series\n",
      " |            [:math:`x_0, x_1, ..., x_t`] would be:\n",
      " |\n",
      " |          .. math::\n",
      " |              y_t = \\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2 x_{t-2} + ... + (1 -\n",
      " |              \\alpha)^t x_0}{1 + (1 - \\alpha) + (1 - \\alpha)^2 + ... + (1 - \\alpha)^t}\n",
      " |\n",
      " |          - When ``adjust=False``, the exponentially weighted function is calculated\n",
      " |            recursively:\n",
      " |\n",
      " |          .. math::\n",
      " |              \\begin{split}\n",
      " |                  y_0 &= x_0\\\\\n",
      " |                  y_t &= (1 - \\alpha) y_{t-1} + \\alpha x_t,\n",
      " |              \\end{split}\n",
      " |      ignore_na : bool, default False\n",
      " |          Ignore missing values when calculating weights.\n",
      " |\n",
      " |          - When ``ignore_na=False`` (default), weights are based on absolute positions.\n",
      " |            For example, the weights of :math:`x_0` and :math:`x_2` used in calculating\n",
      " |            the final weighted average of [:math:`x_0`, None, :math:`x_2`] are\n",
      " |            :math:`(1-\\alpha)^2` and :math:`1` if ``adjust=True``, and\n",
      " |            :math:`(1-\\alpha)^2` and :math:`\\alpha` if ``adjust=False``.\n",
      " |\n",
      " |          - When ``ignore_na=True``, weights are based\n",
      " |            on relative positions. For example, the weights of :math:`x_0` and :math:`x_2`\n",
      " |            used in calculating the final weighted average of\n",
      " |            [:math:`x_0`, None, :math:`x_2`] are :math:`1-\\alpha` and :math:`1` if\n",
      " |            ``adjust=True``, and :math:`1-\\alpha` and :math:`\\alpha` if ``adjust=False``.\n",
      " |\n",
      " |      axis : {0, 1}, default 0\n",
      " |          If ``0`` or ``'index'``, calculate across the rows.\n",
      " |\n",
      " |          If ``1`` or ``'columns'``, calculate across the columns.\n",
      " |\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |      times : np.ndarray, Series, default None\n",
      " |\n",
      " |          Only applicable to ``mean()``.\n",
      " |\n",
      " |          Times corresponding to the observations. Must be monotonically increasing and\n",
      " |          ``datetime64[ns]`` dtype.\n",
      " |\n",
      " |          If 1-D array like, a sequence with the same shape as the observations.\n",
      " |\n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          .. versionadded:: 1.4.0\n",
      " |\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |\n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |\n",
      " |          Only applicable to ``mean()``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.ExponentialMovingWindow\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      expanding : Provides expanding transformations.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.exponentially_weighted>`\n",
      " |      for further usage details and examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |\n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      >>> df.ewm(alpha=2 / 3).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |\n",
      " |      **adjust**\n",
      " |\n",
      " |      >>> df.ewm(com=0.5, adjust=True).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      >>> df.ewm(com=0.5, adjust=False).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.666667\n",
      " |      2  1.555556\n",
      " |      3  1.555556\n",
      " |      4  3.650794\n",
      " |\n",
      " |      **ignore_na**\n",
      " |\n",
      " |      >>> df.ewm(com=0.5, ignore_na=True).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.225000\n",
      " |      >>> df.ewm(com=0.5, ignore_na=False).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |\n",
      " |      **times**\n",
      " |\n",
      " |      Exponentially weighted mean with weights calculated with a timedelta ``halflife``\n",
      " |      relative to ``times``.\n",
      " |\n",
      " |      >>> times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']\n",
      " |      >>> df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.585786\n",
      " |      2  1.523889\n",
      " |      3  1.523889\n",
      " |      4  3.233686\n",
      " |\n",
      " |  expanding(self, min_periods: 'int' = 1, axis: 'Axis | lib.NoDefault' = <no_default>, method: \"Literal['single', 'table']\" = 'single') -> 'Expanding'\n",
      " |      Provide expanding window calculations.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |\n",
      " |      axis : int or str, default 0\n",
      " |          If ``0`` or ``'index'``, roll across the rows.\n",
      " |\n",
      " |          If ``1`` or ``'columns'``, roll across the columns.\n",
      " |\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |\n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |\n",
      " |          .. versionadded:: 1.3.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.Expanding\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.expanding>` for further usage details\n",
      " |      and examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |\n",
      " |      **min_periods**\n",
      " |\n",
      " |      Expanding sum with 1 vs 3 observations needed to calculate a value.\n",
      " |\n",
      " |      >>> df.expanding(1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |      >>> df.expanding(3).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  NaN\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |\n",
      " |  ffill(self, *, axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, limit_area: \"Literal['inside', 'outside'] | None\" = None, downcast: 'dict | None | lib.NoDefault' = <no_default>) -> 'Self | None'\n",
      " |      Fill NA/NaN values by propagating the last valid observation to next valid.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\n",
      " |          Axis along which to fill missing values. For `Series`\n",
      " |          this parameter is unused and defaults to 0.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      limit_area : {`None`, 'inside', 'outside'}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |\n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |\n",
      " |          .. versionadded:: 2.2.0\n",
      " |\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |\n",
      " |          .. deprecated:: 2.2.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, np.nan],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                   columns=list(\"ABCD\"))\n",
      " |      >>> df\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  NaN  NaN NaN  NaN\n",
      " |      3  NaN  3.0 NaN  4.0\n",
      " |\n",
      " |      >>> df.ffill()\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  3.0  4.0 NaN  1.0\n",
      " |      3  3.0  3.0 NaN  4.0\n",
      " |\n",
      " |      >>> ser = pd.Series([1, np.nan, 2, 3])\n",
      " |      >>> ser.ffill()\n",
      " |      0   1.0\n",
      " |      1   1.0\n",
      " |      2   2.0\n",
      " |      3   3.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |  fillna(self, value: 'Hashable | Mapping | Series | DataFrame | None' = None, *, method: 'FillnaOptions | None' = None, axis: 'Axis | None' = None, inplace: 'bool_t' = False, limit: 'int | None' = None, downcast: 'dict | None | lib.NoDefault' = <no_default>) -> 'Self | None'\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      " |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series:\n",
      " |\n",
      " |          * ffill: propagate last valid observation forward to next valid.\n",
      " |          * backfill / bfill: use next valid observation to fill gap.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |              Use ffill or bfill instead.\n",
      " |\n",
      " |      axis : {0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\n",
      " |          Axis along which to fill missing values. For `Series`\n",
      " |          this parameter is unused and defaults to 0.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |\n",
      " |          .. deprecated:: 2.2.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      ffill : Fill values by propagating the last valid observation to next valid.\n",
      " |      bfill : Fill values by using the next valid observation to fill the gap.\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex : Conform object to new index.\n",
      " |      asfreq : Convert TimeSeries to specified frequency.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, np.nan],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                   columns=list(\"ABCD\"))\n",
      " |      >>> df\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  NaN  NaN NaN  NaN\n",
      " |      3  NaN  3.0 NaN  4.0\n",
      " |\n",
      " |      Replace all NaN elements with 0s.\n",
      " |\n",
      " |      >>> df.fillna(0)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  0.0  0.0\n",
      " |      1  3.0  4.0  0.0  1.0\n",
      " |      2  0.0  0.0  0.0  0.0\n",
      " |      3  0.0  3.0  0.0  4.0\n",
      " |\n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |\n",
      " |      >>> values = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  2.0  0.0\n",
      " |      1  3.0  4.0  2.0  1.0\n",
      " |      2  0.0  1.0  2.0  3.0\n",
      " |      3  0.0  3.0  2.0  4.0\n",
      " |\n",
      " |      Only replace the first NaN element.\n",
      " |\n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  2.0  0.0\n",
      " |      1  3.0  4.0  NaN  1.0\n",
      " |      2  NaN  1.0  NaN  3.0\n",
      " |      3  NaN  3.0  NaN  4.0\n",
      " |\n",
      " |      When filling using a DataFrame, replacement happens along\n",
      " |      the same column names and same indices\n",
      " |\n",
      " |      >>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\n",
      " |      >>> df.fillna(df2)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  0.0  0.0\n",
      " |      1  3.0  4.0  0.0  1.0\n",
      " |      2  0.0  0.0  0.0  NaN\n",
      " |      3  0.0  3.0  0.0  4.0\n",
      " |\n",
      " |      Note that column D is not affected since it is not present in df2.\n",
      " |\n",
      " |  filter(self, items=None, like: 'str | None' = None, regex: 'str | None' = None, axis: 'Axis | None' = None) -> 'Self'\n",
      " |      Subset the dataframe rows or columns according to the specified index labels.\n",
      " |\n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          Keep labels from axis which are in items.\n",
      " |      like : str\n",
      " |          Keep labels from axis for which \"like in label == True\".\n",
      " |      regex : str (regular expression)\n",
      " |          Keep labels from axis for which re.search(regex, label) == True.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          The axis to filter on, expressed either as an index (int)\n",
      " |          or axis name (str). By default this is the info axis, 'columns' for\n",
      " |          DataFrame. For `Series` this parameter is unused and defaults to `None`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |\n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),\n",
      " |      ...                   index=['mouse', 'rabbit'],\n",
      " |      ...                   columns=['one', 'two', 'three'])\n",
      " |      >>> df\n",
      " |              one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |\n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |\n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |\n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |               one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |\n",
      " |  first(self, offset) -> 'Self'\n",
      " |      Select initial periods of time series data based on a date offset.\n",
      " |\n",
      " |      .. deprecated:: 2.1\n",
      " |          :meth:`.first` is deprecated and will be removed in a future version.\n",
      " |          Please create a mask and filter using `.loc` instead.\n",
      " |\n",
      " |      For a DataFrame with a sorted DatetimeIndex, this function can\n",
      " |      select the first few rows based on a date offset.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset or dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '1ME' will display all the rows having their index within the first month.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |\n",
      " |      Get the rows for the first 3 days:\n",
      " |\n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |\n",
      " |      Notice the data for 3 first calendar days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |\n",
      " |  first_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for first non-NA value or None, if no non-NA value is found.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of index\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      >>> s = pd.Series([None, 3, 4])\n",
      " |      >>> s.first_valid_index()\n",
      " |      1\n",
      " |      >>> s.last_valid_index()\n",
      " |      2\n",
      " |\n",
      " |      >>> s = pd.Series([None, None])\n",
      " |      >>> print(s.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(s.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If all elements in Series are NA/null, returns None.\n",
      " |\n",
      " |      >>> s = pd.Series()\n",
      " |      >>> print(s.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(s.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If Series is empty, returns None.\n",
      " |\n",
      " |      For DataFrame:\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [None, None, 2], 'B': [None, 3, 4]})\n",
      " |      >>> df\n",
      " |           A      B\n",
      " |      0  NaN    NaN\n",
      " |      1  NaN    3.0\n",
      " |      2  2.0    4.0\n",
      " |      >>> df.first_valid_index()\n",
      " |      1\n",
      " |      >>> df.last_valid_index()\n",
      " |      2\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [None, None, None], 'B': [None, None, None]})\n",
      " |      >>> df\n",
      " |           A      B\n",
      " |      0  None   None\n",
      " |      1  None   None\n",
      " |      2  None   None\n",
      " |      >>> print(df.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(df.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If all elements in DataFrame are NA/null, returns None.\n",
      " |\n",
      " |      >>> df = pd.DataFrame()\n",
      " |      >>> df\n",
      " |      Empty DataFrame\n",
      " |      Columns: []\n",
      " |      Index: []\n",
      " |      >>> print(df.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(df.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If DataFrame is empty, returns None.\n",
      " |\n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (ex: DataFrame column).\n",
      " |\n",
      " |      Returns default value if not found.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as items contained in object\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [\n",
      " |      ...         [24.3, 75.7, \"high\"],\n",
      " |      ...         [31, 87.8, \"high\"],\n",
      " |      ...         [22, 71.6, \"medium\"],\n",
      " |      ...         [35, 95, \"medium\"],\n",
      " |      ...     ],\n",
      " |      ...     columns=[\"temp_celsius\", \"temp_fahrenheit\", \"windspeed\"],\n",
      " |      ...     index=pd.date_range(start=\"2014-02-12\", end=\"2014-02-15\", freq=\"D\"),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> df\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |\n",
      " |      >>> df.get([\"temp_celsius\", \"windspeed\"])\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          24.3      high\n",
      " |      2014-02-13          31.0      high\n",
      " |      2014-02-14          22.0    medium\n",
      " |      2014-02-15          35.0    medium\n",
      " |\n",
      " |      >>> ser = df['windspeed']\n",
      " |      >>> ser.get('2014-02-13')\n",
      " |      'high'\n",
      " |\n",
      " |      If the key isn't found, the default value will be used.\n",
      " |\n",
      " |      >>> df.get([\"temp_celsius\", \"temp_kelvin\"], default=\"default_value\")\n",
      " |      'default_value'\n",
      " |\n",
      " |      >>> ser.get('2014-02-10', '[unknown]')\n",
      " |      '[unknown]'\n",
      " |\n",
      " |  head(self, n: 'int' = 5) -> 'Self'\n",
      " |      Return the first `n` rows.\n",
      " |\n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |\n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the last `|n|` rows, equivalent to ``df[:n]``.\n",
      " |\n",
      " |      If n is larger than the number of rows, this function returns all rows.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.tail: Returns the last `n` rows.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |\n",
      " |      Viewing the first 5 lines\n",
      " |\n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |\n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |\n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |\n",
      " |      For negative values of `n`\n",
      " |\n",
      " |      >>> df.head(-3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |\n",
      " |  infer_objects(self, copy: 'bool_t | None' = None) -> 'Self'\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |\n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, default True\n",
      " |          Whether to make a copy for non-object or non-inferable columns\n",
      " |          or Series.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to numeric type.\n",
      " |      convert_dtypes : Convert argument to best possible dtype.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |\n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |\n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |\n",
      " |  interpolate(self, method: 'InterpolateOptions' = 'linear', *, axis: 'Axis' = 0, limit: 'int | None' = None, inplace: 'bool_t' = False, limit_direction: \"Literal['forward', 'backward', 'both'] | None\" = None, limit_area: \"Literal['inside', 'outside'] | None\" = None, downcast: \"Literal['infer'] | None | lib.NoDefault\" = <no_default>, **kwargs) -> 'Self | None'\n",
      " |      Fill NaN values using an interpolation method.\n",
      " |\n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrame/Series with a MultiIndex.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, default 'linear'\n",
      " |          Interpolation technique to use. One of:\n",
      " |\n",
      " |          * 'linear': Ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |          * 'time': Works on daily and higher resolution data to interpolate\n",
      " |            given length of interval.\n",
      " |          * 'index', 'values': use the actual numerical values of the index.\n",
      " |          * 'pad': Fill in NaNs using existing values.\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'barycentric', 'polynomial': Passed to\n",
      " |            `scipy.interpolate.interp1d`, whereas 'spline' is passed to\n",
      " |            `scipy.interpolate.UnivariateSpline`. These methods use the numerical\n",
      " |            values of the index.  Both 'polynomial' and 'spline' require that\n",
      " |            you also specify an `order` (int), e.g.\n",
      " |            ``df.interpolate(method='polynomial', order=5)``. Note that,\n",
      " |            `slinear` method in Pandas refers to the Scipy first order `spline`\n",
      " |            instead of Pandas first order `spline`.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip', 'akima',\n",
      " |            'cubicspline': Wrappers around the SciPy interpolation methods of\n",
      " |            similar names. See `Notes`.\n",
      " |          * 'from_derivatives': Refers to\n",
      " |            `scipy.interpolate.BPoly.from_derivatives`.\n",
      " |\n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Axis to interpolate along. For `Series` this parameter is unused\n",
      " |          and defaults to 0.\n",
      " |      limit : int, optional\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than\n",
      " |          0.\n",
      " |      inplace : bool, default False\n",
      " |          Update the data in place if possible.\n",
      " |      limit_direction : {{'forward', 'backward', 'both'}}, Optional\n",
      " |          Consecutive NaNs will be filled in this direction.\n",
      " |\n",
      " |          If limit is specified:\n",
      " |              * If 'method' is 'pad' or 'ffill', 'limit_direction' must be 'forward'.\n",
      " |              * If 'method' is 'backfill' or 'bfill', 'limit_direction' must be\n",
      " |                'backwards'.\n",
      " |\n",
      " |          If 'limit' is not specified:\n",
      " |              * If 'method' is 'backfill' or 'bfill', the default is 'backward'\n",
      " |              * else the default is 'forward'\n",
      " |\n",
      " |          raises ValueError if `limit_direction` is 'forward' or 'both' and\n",
      " |              method is 'backfill' or 'bfill'.\n",
      " |          raises ValueError if `limit_direction` is 'backward' or 'both' and\n",
      " |              method is 'pad' or 'ffill'.\n",
      " |\n",
      " |      limit_area : {{`None`, 'inside', 'outside'}}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |\n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |\n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |\n",
      " |      ``**kwargs`` : optional\n",
      " |          Keyword arguments to pass on to the interpolating function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Returns the same object type as the caller, interpolated at\n",
      " |          some or all ``NaN`` values or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      fillna : Fill missing values using different methods.\n",
      " |      scipy.interpolate.Akima1DInterpolator : Piecewise cubic polynomials\n",
      " |          (Akima interpolator).\n",
      " |      scipy.interpolate.BPoly.from_derivatives : Piecewise polynomial in the\n",
      " |          Bernstein basis.\n",
      " |      scipy.interpolate.interp1d : Interpolate a 1-D function.\n",
      " |      scipy.interpolate.KroghInterpolator : Interpolate polynomial (Krogh\n",
      " |          interpolator).\n",
      " |      scipy.interpolate.PchipInterpolator : PCHIP 1-d monotonic cubic\n",
      " |          interpolation.\n",
      " |      scipy.interpolate.CubicSpline : Cubic spline data interpolator.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |      methods are wrappers around the respective SciPy implementations of\n",
      " |      similar names. These use the actual numerical values of the index.\n",
      " |      For more information on their behavior, see the\n",
      " |      `SciPy documentation\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Filling in ``NaN`` in a :class:`~pandas.Series` via linear\n",
      " |      interpolation.\n",
      " |\n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    NaN\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.interpolate()\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Filling in ``NaN`` in a Series via polynomial interpolation or splines:\n",
      " |      Both 'polynomial' and 'spline' methods require that you also specify\n",
      " |      an ``order`` (int).\n",
      " |\n",
      " |      >>> s = pd.Series([0, 2, np.nan, 8])\n",
      " |      >>> s.interpolate(method='polynomial', order=2)\n",
      " |      0    0.000000\n",
      " |      1    2.000000\n",
      " |      2    4.666667\n",
      " |      3    8.000000\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Fill the DataFrame forward (that is, going down) along each column\n",
      " |      using linear interpolation.\n",
      " |\n",
      " |      Note how the last entry in column 'a' is interpolated differently,\n",
      " |      because there is no entry after it to use for interpolation.\n",
      " |      Note how the first entry in column 'b' remains ``NaN``, because there\n",
      " |      is no entry before it to use for interpolation.\n",
      " |\n",
      " |      >>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),\n",
      " |      ...                    (np.nan, 2.0, np.nan, np.nan),\n",
      " |      ...                    (2.0, 3.0, np.nan, 9.0),\n",
      " |      ...                    (np.nan, 4.0, -4.0, 16.0)],\n",
      " |      ...                   columns=list('abcd'))\n",
      " |      >>> df\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  NaN  2.0  NaN   NaN\n",
      " |      2  2.0  3.0  NaN   9.0\n",
      " |      3  NaN  4.0 -4.0  16.0\n",
      " |      >>> df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  1.0  2.0 -2.0   5.0\n",
      " |      2  2.0  3.0 -3.0   9.0\n",
      " |      3  2.0  4.0 -4.0  16.0\n",
      " |\n",
      " |      Using polynomial interpolation.\n",
      " |\n",
      " |      >>> df['d'].interpolate(method='polynomial', order=2)\n",
      " |      0     1.0\n",
      " |      1     4.0\n",
      " |      2     9.0\n",
      " |      3    16.0\n",
      " |      Name: d, dtype: float64\n",
      " |\n",
      " |  keys(self) -> 'Index'\n",
      " |      Get the 'info axis' (see Indexing for more).\n",
      " |\n",
      " |      This is index for Series, columns for DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Info axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = pd.DataFrame(data={'A': [1, 2, 3], 'B': [0, 4, 8]},\n",
      " |      ...                  index=['a', 'b', 'c'])\n",
      " |      >>> d\n",
      " |         A  B\n",
      " |      a  1  0\n",
      " |      b  2  4\n",
      " |      c  3  8\n",
      " |      >>> d.keys()\n",
      " |      Index(['A', 'B'], dtype='object')\n",
      " |\n",
      " |  last(self, offset) -> 'Self'\n",
      " |      Select final periods of time series data based on a date offset.\n",
      " |\n",
      " |      .. deprecated:: 2.1\n",
      " |          :meth:`.last` is deprecated and will be removed in a future version.\n",
      " |          Please create a mask and filter using `.loc` instead.\n",
      " |\n",
      " |      For a DataFrame with a sorted DatetimeIndex, this function\n",
      " |      selects the last few rows based on a date offset.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset, dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '3D' will display all the rows having their index within the last 3 days.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. deprecated:: 2.1.0\n",
      " |          Please create a mask and filter using `.loc` instead\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |\n",
      " |      Get the rows for the last 3 days:\n",
      " |\n",
      " |      >>> ts.last('3D')  # doctest: +SKIP\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |\n",
      " |      Notice the data for 3 last calendar days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |\n",
      " |  last_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for last non-NA value or None, if no non-NA value is found.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of index\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      >>> s = pd.Series([None, 3, 4])\n",
      " |      >>> s.first_valid_index()\n",
      " |      1\n",
      " |      >>> s.last_valid_index()\n",
      " |      2\n",
      " |\n",
      " |      >>> s = pd.Series([None, None])\n",
      " |      >>> print(s.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(s.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If all elements in Series are NA/null, returns None.\n",
      " |\n",
      " |      >>> s = pd.Series()\n",
      " |      >>> print(s.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(s.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If Series is empty, returns None.\n",
      " |\n",
      " |      For DataFrame:\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [None, None, 2], 'B': [None, 3, 4]})\n",
      " |      >>> df\n",
      " |           A      B\n",
      " |      0  NaN    NaN\n",
      " |      1  NaN    3.0\n",
      " |      2  2.0    4.0\n",
      " |      >>> df.first_valid_index()\n",
      " |      1\n",
      " |      >>> df.last_valid_index()\n",
      " |      2\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [None, None, None], 'B': [None, None, None]})\n",
      " |      >>> df\n",
      " |           A      B\n",
      " |      0  None   None\n",
      " |      1  None   None\n",
      " |      2  None   None\n",
      " |      >>> print(df.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(df.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If all elements in DataFrame are NA/null, returns None.\n",
      " |\n",
      " |      >>> df = pd.DataFrame()\n",
      " |      >>> df\n",
      " |      Empty DataFrame\n",
      " |      Columns: []\n",
      " |      Index: []\n",
      " |      >>> print(df.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(df.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If DataFrame is empty, returns None.\n",
      " |\n",
      " |  mask(self, cond, other=<no_default>, *, inplace: 'bool_t' = False, axis: 'Axis | None' = None, level: 'Level | None' = None) -> 'Self | None'\n",
      " |      Replace values where the condition is True.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |          If not specified, entries will be filled with the corresponding\n",
      " |          NULL value (``np.nan`` for numpy dtypes, ``pd.NA`` for extension\n",
      " |          dtypes).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed. For `Series` this parameter is\n",
      " |          unused and defaults to 0.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where` : Return an object of same shape as\n",
      " |          self.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used. If the axis of ``other`` does not align with axis of\n",
      " |      ``cond`` Series/DataFrame, the misaligned index positions will be filled with\n",
      " |      True.\n",
      " |\n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |\n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |\n",
      " |      The dtype of the object takes precedence. The fill value is casted to\n",
      " |      the object's dtype, if this can be done losslessly.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> t = pd.Series([True, False])\n",
      " |      >>> s.where(t, 99)\n",
      " |      0     0\n",
      " |      1    99\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(t, 99)\n",
      " |      0    99\n",
      " |      1     1\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |\n",
      " |  pad(self, *, axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast: 'dict | None | lib.NoDefault' = <no_default>) -> 'Self | None'\n",
      " |      Fill NA/NaN values by propagating the last valid observation to next valid.\n",
      " |\n",
      " |      .. deprecated:: 2.0\n",
      " |\n",
      " |          Series/DataFrame.pad is deprecated. Use Series/DataFrame.ffill instead.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Please see examples for :meth:`DataFrame.ffill` or :meth:`Series.ffill`.\n",
      " |\n",
      " |  pct_change(self, periods: 'int' = 1, fill_method: 'FillnaOptions | None | lib.NoDefault' = <no_default>, limit: 'int | None | lib.NoDefault' = <no_default>, freq=None, **kwargs) -> 'Self'\n",
      " |      Fractional change between the current and a prior element.\n",
      " |\n",
      " |      Computes the fractional change from the immediately previous row by\n",
      " |      default. This is useful in comparing the fraction of change in a time\n",
      " |      series of elements.\n",
      " |\n",
      " |      .. note::\n",
      " |\n",
      " |          Despite the name of this method, it calculates fractional change\n",
      " |          (also known as per unit change or relative change) and not\n",
      " |          percentage change. If you need the percentage change, multiply\n",
      " |          these values by 100.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : {'backfill', 'bfill', 'pad', 'ffill', None}, default 'pad'\n",
      " |          How to handle NAs **before** computing percent changes.\n",
      " |\n",
      " |          .. deprecated:: 2.1\n",
      " |              All options of `fill_method` are deprecated except `fill_method=None`.\n",
      " |\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |\n",
      " |          .. deprecated:: 2.1\n",
      " |\n",
      " |      freq : DateOffset, timedelta, or str, optional\n",
      " |          Increment to use from time series API (e.g. 'ME' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |\n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |\n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.ffill().pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |\n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |\n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |\n",
      " |      >>> df.pct_change(axis='columns', periods=-1)\n",
      " |                2016      2015  2014\n",
      " |      GOOG  0.179241  0.094112   NaN\n",
      " |      APPL -0.252395 -0.011860   NaN\n",
      " |\n",
      " |  pipe(self, func: 'Callable[..., T] | tuple[Callable[..., T], str]', *args, **kwargs) -> 'T'\n",
      " |      Apply chainable functions that expect Series or DataFrames.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to the Series/DataFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the Series/DataFrame.\n",
      " |      *args : iterable, optional\n",
      " |          Positional arguments passed into ``func``.\n",
      " |      **kwargs : mapping, optional\n",
      " |          A dictionary of keyword arguments passed into ``func``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      the return type of ``func``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.map : Apply a function elementwise on a whole DataFrame.\n",
      " |      Series.map : Apply a mapping correspondence on a\n",
      " |          :class:`~pandas.Series`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Constructing a income DataFrame from a dictionary.\n",
      " |\n",
      " |      >>> data = [[8000, 1000], [9500, np.nan], [5000, 2000]]\n",
      " |      >>> df = pd.DataFrame(data, columns=['Salary', 'Others'])\n",
      " |      >>> df\n",
      " |         Salary  Others\n",
      " |      0    8000  1000.0\n",
      " |      1    9500     NaN\n",
      " |      2    5000  2000.0\n",
      " |\n",
      " |      Functions that perform tax reductions on an income DataFrame.\n",
      " |\n",
      " |      >>> def subtract_federal_tax(df):\n",
      " |      ...     return df * 0.9\n",
      " |      >>> def subtract_state_tax(df, rate):\n",
      " |      ...     return df * (1 - rate)\n",
      " |      >>> def subtract_national_insurance(df, rate, rate_increase):\n",
      " |      ...     new_rate = rate + rate_increase\n",
      " |      ...     return df * (1 - new_rate)\n",
      " |\n",
      " |      Instead of writing\n",
      " |\n",
      " |      >>> subtract_national_insurance(\n",
      " |      ...     subtract_state_tax(subtract_federal_tax(df), rate=0.12),\n",
      " |      ...     rate=0.05,\n",
      " |      ...     rate_increase=0.02)  # doctest: +SKIP\n",
      " |\n",
      " |      You can write\n",
      " |\n",
      " |      >>> (\n",
      " |      ...     df.pipe(subtract_federal_tax)\n",
      " |      ...     .pipe(subtract_state_tax, rate=0.12)\n",
      " |      ...     .pipe(subtract_national_insurance, rate=0.05, rate_increase=0.02)\n",
      " |      ... )\n",
      " |          Salary   Others\n",
      " |      0  5892.48   736.56\n",
      " |      1  6997.32      NaN\n",
      " |      2  3682.80  1473.12\n",
      " |\n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``national_insurance`` takes its data as ``df``\n",
      " |      in the second argument:\n",
      " |\n",
      " |      >>> def subtract_national_insurance(rate, df, rate_increase):\n",
      " |      ...     new_rate = rate + rate_increase\n",
      " |      ...     return df * (1 - new_rate)\n",
      " |      >>> (\n",
      " |      ...     df.pipe(subtract_federal_tax)\n",
      " |      ...     .pipe(subtract_state_tax, rate=0.12)\n",
      " |      ...     .pipe(\n",
      " |      ...         (subtract_national_insurance, 'df'),\n",
      " |      ...         rate=0.05,\n",
      " |      ...         rate_increase=0.02\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |          Salary   Others\n",
      " |      0  5892.48   736.56\n",
      " |      1  6997.32      NaN\n",
      " |      2  3682.80  1473.12\n",
      " |\n",
      " |  rank(self, axis: 'Axis' = 0, method: \"Literal['average', 'min', 'max', 'first', 'dense']\" = 'average', numeric_only: 'bool_t' = False, na_option: \"Literal['keep', 'top', 'bottom']\" = 'keep', ascending: 'bool_t' = True, pct: 'bool_t' = False) -> 'Self'\n",
      " |      Compute numerical data ranks (1 through n) along axis.\n",
      " |\n",
      " |      By default, equal values are assigned a rank that is the average of the\n",
      " |      ranks of those values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Index to direct ranking.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          How to rank the group of records that have the same value (i.e. ties):\n",
      " |\n",
      " |          * average: average rank of the group\n",
      " |          * min: lowest rank in the group\n",
      " |          * max: highest rank in the group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      " |\n",
      " |      numeric_only : bool, default False\n",
      " |          For DataFrame objects, rank only numeric columns if set to True.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |\n",
      " |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          How to rank NaN values:\n",
      " |\n",
      " |          * keep: assign NaN rank to NaN values\n",
      " |          * top: assign lowest rank to NaN values\n",
      " |          * bottom: assign highest rank to NaN values\n",
      " |\n",
      " |      ascending : bool, default True\n",
      " |          Whether or not the elements should be ranked in ascending order.\n",
      " |      pct : bool, default False\n",
      " |          Whether or not to display the returned rankings in percentile\n",
      " |          form.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          Return a Series or DataFrame with data ranks as values.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.groupby.DataFrameGroupBy.rank : Rank of values within each group.\n",
      " |      core.groupby.SeriesGroupBy.rank : Rank of values within each group.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n",
      " |      ...                                    'spider', 'snake'],\n",
      " |      ...                         'Number_legs': [4, 2, 4, 8, np.nan]})\n",
      " |      >>> df\n",
      " |          Animal  Number_legs\n",
      " |      0      cat          4.0\n",
      " |      1  penguin          2.0\n",
      " |      2      dog          4.0\n",
      " |      3   spider          8.0\n",
      " |      4    snake          NaN\n",
      " |\n",
      " |      Ties are assigned the mean of the ranks (by default) for the group.\n",
      " |\n",
      " |      >>> s = pd.Series(range(5), index=list(\"abcde\"))\n",
      " |      >>> s[\"d\"] = s[\"b\"]\n",
      " |      >>> s.rank()\n",
      " |      a    1.0\n",
      " |      b    2.5\n",
      " |      c    4.0\n",
      " |      d    2.5\n",
      " |      e    5.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      The following example shows how the method behaves with the above\n",
      " |      parameters:\n",
      " |\n",
      " |      * default_rank: this is the default behaviour obtained without using\n",
      " |        any parameter.\n",
      " |      * max_rank: setting ``method = 'max'`` the records that have the\n",
      " |        same values are ranked using the highest rank (e.g.: since 'cat'\n",
      " |        and 'dog' are both in the 2nd and 3rd position, rank 3 is assigned.)\n",
      " |      * NA_bottom: choosing ``na_option = 'bottom'``, if there are records\n",
      " |        with NaN values they are placed at the bottom of the ranking.\n",
      " |      * pct_rank: when setting ``pct = True``, the ranking is expressed as\n",
      " |        percentile rank.\n",
      " |\n",
      " |      >>> df['default_rank'] = df['Number_legs'].rank()\n",
      " |      >>> df['max_rank'] = df['Number_legs'].rank(method='max')\n",
      " |      >>> df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')\n",
      " |      >>> df['pct_rank'] = df['Number_legs'].rank(pct=True)\n",
      " |      >>> df\n",
      " |          Animal  Number_legs  default_rank  max_rank  NA_bottom  pct_rank\n",
      " |      0      cat          4.0           2.5       3.0        2.5     0.625\n",
      " |      1  penguin          2.0           1.0       1.0        1.0     0.250\n",
      " |      2      dog          4.0           2.5       3.0        2.5     0.625\n",
      " |      3   spider          8.0           4.0       4.0        4.0     1.000\n",
      " |      4    snake          NaN           NaN       NaN        5.0       NaN\n",
      " |\n",
      " |  reindex_like(self, other, method: \"Literal['backfill', 'bfill', 'pad', 'ffill', 'nearest'] | None\" = None, copy: 'bool_t | None' = None, limit: 'int | None' = None, tolerance=None) -> 'Self'\n",
      " |      Return an object with matching indices as other object.\n",
      " |\n",
      " |      Conform the object to the same index on all axes. Optional\n",
      " |      filling logic, placing NaN in locations having no value\n",
      " |      in the previous index. A new object is produced unless the\n",
      " |      new index is equivalent to the current one and copy=False.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object of the same data type\n",
      " |          Its row and column indices are used to define the new indices\n",
      " |          of this object.\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |\n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap.\n",
      " |\n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations must\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |\n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as caller, but with changed indices on each axis.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Same as calling\n",
      " |      ``.reindex(index=other.index, columns=other.columns,...)``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],\n",
      " |      ...                     [31, 87.8, 'high'],\n",
      " |      ...                     [22, 71.6, 'medium'],\n",
      " |      ...                     [35, 95, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'temp_fahrenheit',\n",
      " |      ...                             'windspeed'],\n",
      " |      ...                    index=pd.date_range(start='2014-02-12',\n",
      " |      ...                                        end='2014-02-15', freq='D'))\n",
      " |\n",
      " |      >>> df1\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |\n",
      " |      >>> df2 = pd.DataFrame([[28, 'low'],\n",
      " |      ...                     [30, 'low'],\n",
      " |      ...                     [35.1, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'windspeed'],\n",
      " |      ...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',\n",
      " |      ...                                            '2014-02-15']))\n",
      " |\n",
      " |      >>> df2\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          28.0       low\n",
      " |      2014-02-13          30.0       low\n",
      " |      2014-02-15          35.1    medium\n",
      " |\n",
      " |      >>> df2.reindex_like(df1)\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          28.0              NaN       low\n",
      " |      2014-02-13          30.0              NaN       low\n",
      " |      2014-02-14           NaN              NaN       NaN\n",
      " |      2014-02-15          35.1              NaN    medium\n",
      " |\n",
      " |  rename_axis(self, mapper: 'IndexLabel | lib.NoDefault' = <no_default>, *, index=<no_default>, columns=<no_default>, axis: 'Axis' = 0, copy: 'bool_t | None' = None, inplace: 'bool_t' = False) -> 'Self | None'\n",
      " |      Set the name of the axis for the index or columns.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set the axis name attribute.\n",
      " |      index, columns : scalar, list-like, dict-like or function, optional\n",
      " |          A scalar, list-like, dict-like or functions transformations to\n",
      " |          apply to that axis' values.\n",
      " |          Note that the ``columns`` parameter is not allowed if the\n",
      " |          object is a Series. This parameter only apply for DataFrame\n",
      " |          type objects.\n",
      " |\n",
      " |          Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index``\n",
      " |          and/or ``columns``.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to rename. For `Series` this parameter is unused and defaults to 0.\n",
      " |      copy : bool, default None\n",
      " |          Also copy underlying data.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      inplace : bool, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series, DataFrame, or None\n",
      " |          The same type as the caller or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rename : Alter Series index labels or name.\n",
      " |      DataFrame.rename : Alter DataFrame index labels or name.\n",
      " |      Index.rename : Set new names on index.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``DataFrame.rename_axis`` supports two calling conventions\n",
      " |\n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |\n",
      " |      The first calling convention will only modify the names of\n",
      " |      the index and/or the names of the Index object that is the columns.\n",
      " |      In this case, the parameter ``copy`` is ignored.\n",
      " |\n",
      " |      The second calling convention will modify the names of the\n",
      " |      corresponding index if mapper is a list or a scalar.\n",
      " |      However, if mapper is dict-like or a function, it will use the\n",
      " |      deprecated behavior of modifying the axis *labels*.\n",
      " |\n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> s = pd.Series([\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> s\n",
      " |      0       dog\n",
      " |      1       cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      >>> s.rename_axis(\"animal\")\n",
      " |      animal\n",
      " |      0    dog\n",
      " |      1    cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"num_legs\": [4, 4, 2],\n",
      " |      ...                    \"num_arms\": [0, 0, 2]},\n",
      " |      ...                   [\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"animal\")\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"limbs\", axis=\"columns\")\n",
      " |      >>> df\n",
      " |      limbs   num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |\n",
      " |      **MultiIndex**\n",
      " |\n",
      " |      >>> df.index = pd.MultiIndex.from_product([['mammal'],\n",
      " |      ...                                        ['dog', 'cat', 'monkey']],\n",
      " |      ...                                       names=['type', 'name'])\n",
      " |      >>> df\n",
      " |      limbs          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |\n",
      " |      >>> df.rename_axis(index={'type': 'class'})\n",
      " |      limbs          num_legs  num_arms\n",
      " |      class  name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |\n",
      " |      >>> df.rename_axis(columns=str.upper)\n",
      " |      LIMBS          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |\n",
      " |  replace(self, to_replace=None, value=<no_default>, *, inplace: 'bool_t' = False, limit: 'int | None' = None, regex: 'bool_t' = False, method: \"Literal['pad', 'ffill', 'bfill'] | lib.NoDefault\" = <no_default>) -> 'Self | None'\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |\n",
      " |      Values of the Series/DataFrame are replaced with other values dynamically.\n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |\n",
      " |          * numeric, str or regex:\n",
      " |\n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |\n",
      " |          * list of str, regex, or numeric:\n",
      " |\n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |\n",
      " |          * dict:\n",
      " |\n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                for different existing values. For example,\n",
      " |                ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                'y' with 'z'. To use a dict in this way, the optional `value`\n",
      " |                parameter should not be given.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                should be replaced in different columns. For example,\n",
      " |                ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                and the value 'z' in column 'b' and replaces these values\n",
      " |                with whatever is specified in `value`. The `value` parameter\n",
      " |                should not be ``None`` in this case. You can treat this as a\n",
      " |                special case of passing two lists except that you are\n",
      " |                specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                'a' for the value 'b' and replace it with NaN. The optional `value`\n",
      " |                parameter should not be specified to use a nested dict in this\n",
      " |                way. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |\n",
      " |          * None:\n",
      " |\n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or\n",
      " |                Series of such elements. If `value` is also ``None`` then\n",
      " |                this **must** be a nested dictionary or Series.\n",
      " |\n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |\n",
      " |      inplace : bool, default False\n",
      " |          If True, performs operation inplace and returns None.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill'}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Object after replacement.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |            ``None``.\n",
      " |\n",
      " |      TypeError\n",
      " |          * If `to_replace` is not a scalar, array-like, ``dict``, or ``None``\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |            into a regular expression or is a list, dict, ndarray, or\n",
      " |            Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |            the arguments to `to_replace` does not match the type of the\n",
      " |            value being replaced\n",
      " |\n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |            `value` but they are not the same length.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna : Fill NA values.\n",
      " |      DataFrame.fillna : Fill NA values.\n",
      " |      Series.where : Replace values based on boolean condition.\n",
      " |      DataFrame.where : Replace values based on boolean condition.\n",
      " |      DataFrame.map: Apply a function to a Dataframe elementwise.\n",
      " |      Series.map: Map values of Series according to an input mapping or function.\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point\n",
      " |        numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |        key(s) in the dict are the to_replace part and\n",
      " |        value(s) in the dict are the value parameter.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3, 4, 5])\n",
      " |      >>> s.replace(1, 5)\n",
      " |      0    5\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |          A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |\n",
      " |      **List-like `to_replace`**\n",
      " |\n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |\n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |\n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    3\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      dtype: int64\n",
      " |\n",
      " |      **dict-like `to_replace`**\n",
      " |\n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |              A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |\n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |              A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |\n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |              A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |\n",
      " |      **Regular expression `to_replace`**\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |\n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |\n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |\n",
      " |      >>> df.replace(regex={r'^ba.$': 'new', 'foo': 'xyz'})\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |\n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |\n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the peculiarities\n",
      " |      of the `to_replace` parameter:\n",
      " |\n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |\n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |\n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |\n",
      " |      When ``value`` is not explicitly passed and `to_replace` is a scalar, list\n",
      " |      or tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |\n",
      " |      >>> s.replace('a')\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |              The 'method' parameter and padding behavior are deprecated.\n",
      " |\n",
      " |      On the other hand, if ``None`` is explicitly passed for ``value``, it will\n",
      " |      be respected:\n",
      " |\n",
      " |      >>> s.replace('a', None)\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |\n",
      " |          .. versionchanged:: 1.4.0\n",
      " |              Previously the explicit ``None`` was silently ignored.\n",
      " |\n",
      " |      When ``regex=True``, ``value`` is not ``None`` and `to_replace` is a string,\n",
      " |      the replacement will be applied in all columns of the DataFrame.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'C': ['f', 'g', 'h', 'i', 'j']})\n",
      " |\n",
      " |      >>> df.replace(to_replace='^[a-g]', value='e', regex=True)\n",
      " |          A  B  C\n",
      " |      0  0  e  e\n",
      " |      1  1  e  e\n",
      " |      2  2  e  h\n",
      " |      3  3  e  i\n",
      " |      4  4  e  j\n",
      " |\n",
      " |      If ``value`` is not ``None`` and `to_replace` is a dictionary, the dictionary\n",
      " |      keys will be the DataFrame columns that the replacement will be applied.\n",
      " |\n",
      " |      >>> df.replace(to_replace={'B': '^[a-c]', 'C': '^[h-j]'}, value='e', regex=True)\n",
      " |          A  B  C\n",
      " |      0  0  e  f\n",
      " |      1  1  e  g\n",
      " |      2  2  e  e\n",
      " |      3  3  d  e\n",
      " |      4  4  e  e\n",
      " |\n",
      " |  resample(self, rule, axis: 'Axis | lib.NoDefault' = <no_default>, closed: \"Literal['right', 'left'] | None\" = None, label: \"Literal['right', 'left'] | None\" = None, convention: \"Literal['start', 'end', 's', 'e'] | lib.NoDefault\" = <no_default>, kind: \"Literal['timestamp', 'period'] | None | lib.NoDefault\" = <no_default>, on: 'Level | None' = None, level: 'Level | None' = None, origin: 'str | TimestampConvertibleTypes' = 'start_day', offset: 'TimedeltaConvertibleTypes | None' = None, group_keys: 'bool_t' = False) -> 'Resampler'\n",
      " |      Resample time-series data.\n",
      " |\n",
      " |      Convenience method for frequency conversion and resampling of time series.\n",
      " |      The object must have a datetime-like index (`DatetimeIndex`, `PeriodIndex`,\n",
      " |      or `TimedeltaIndex`), or the caller must pass the label of a datetime-like\n",
      " |      series/index to the ``on``/``level`` keyword parameter.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : DateOffset, Timedelta or str\n",
      " |          The offset string or object representing target conversion.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Which axis to use for up- or down-sampling. For `Series` this parameter\n",
      " |          is unused and defaults to 0. Must be\n",
      " |          `DatetimeIndex`, `TimedeltaIndex` or `PeriodIndex`.\n",
      " |\n",
      " |          .. deprecated:: 2.0.0\n",
      " |              Use frame.T.resample(...) instead.\n",
      " |      closed : {'right', 'left'}, default None\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'ME', 'YE', 'QE', 'BME',\n",
      " |          'BA', 'BQE', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}, default None\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'ME', 'YE', 'QE', 'BME',\n",
      " |          'BA', 'BQE', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}, default 'start'\n",
      " |          For `PeriodIndex` only, controls whether to use the start or\n",
      " |          end of `rule`.\n",
      " |\n",
      " |          .. deprecated:: 2.2.0\n",
      " |              Convert PeriodIndex to DatetimeIndex before resampling instead.\n",
      " |      kind : {'timestamp', 'period'}, optional, default None\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          `DateTimeIndex` or 'period' to convert it to a `PeriodIndex`.\n",
      " |          By default the input representation is retained.\n",
      " |\n",
      " |          .. deprecated:: 2.2.0\n",
      " |              Convert index to desired type explicitly instead.\n",
      " |\n",
      " |      on : str, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      level : str or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling. `level` must be datetime-like.\n",
      " |      origin : Timestamp or str, default 'start_day'\n",
      " |          The timestamp on which to adjust the grouping. The timezone of origin\n",
      " |          must match the timezone of the index.\n",
      " |          If string, must be one of the following:\n",
      " |\n",
      " |          - 'epoch': `origin` is 1970-01-01\n",
      " |          - 'start': `origin` is the first value of the timeseries\n",
      " |          - 'start_day': `origin` is the first day at midnight of the timeseries\n",
      " |\n",
      " |          - 'end': `origin` is the last value of the timeseries\n",
      " |          - 'end_day': `origin` is the ceiling midnight of the last day\n",
      " |\n",
      " |          .. versionadded:: 1.3.0\n",
      " |\n",
      " |          .. note::\n",
      " |\n",
      " |              Only takes effect for Tick-frequencies (i.e. fixed frequencies like\n",
      " |              days, hours, and minutes, rather than months or quarters).\n",
      " |      offset : Timedelta or str, default is None\n",
      " |          An offset timedelta added to the origin.\n",
      " |\n",
      " |      group_keys : bool, default False\n",
      " |          Whether to include the group keys in the result index when using\n",
      " |          ``.apply()`` on the resampled object.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |              Not specifying ``group_keys`` will retain values-dependent behavior\n",
      " |              from pandas 1.4 and earlier (see :ref:`pandas 1.5.0 Release notes\n",
      " |              <whatsnew_150.enhancements.resample_group_keys>` for examples).\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |\n",
      " |              ``group_keys`` now defaults to ``False``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.Resampler\n",
      " |          :class:`~pandas.core.Resampler` object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.resample : Resample a Series.\n",
      " |      DataFrame.resample : Resample a DataFrame.\n",
      " |      groupby : Group Series/DataFrame by mapping, function, label, or list of labels.\n",
      " |      asfreq : Reindex a Series/DataFrame with the given frequency without grouping.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling>`__\n",
      " |      for more.\n",
      " |\n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects>`__.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |\n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='min')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: min, dtype: int64\n",
      " |\n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |\n",
      " |      >>> series.resample('3min').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3min, dtype: int64\n",
      " |\n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |\n",
      " |      >>> series.resample('3min', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3min, dtype: int64\n",
      " |\n",
      " |      To include this value close the right side of the bin interval,\n",
      " |      as shown below.\n",
      " |\n",
      " |      >>> series.resample('3min', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3min, dtype: int64\n",
      " |\n",
      " |      Upsample the series into 30 second bins.\n",
      " |\n",
      " |      >>> series.resample('30s').asfreq()[0:5]   # Select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30s, dtype: float64\n",
      " |\n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``ffill`` method.\n",
      " |\n",
      " |      >>> series.resample('30s').ffill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30s, dtype: int64\n",
      " |\n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |\n",
      " |      >>> series.resample('30s').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30s, dtype: int64\n",
      " |\n",
      " |      Pass a custom function via ``apply``\n",
      " |\n",
      " |      >>> def custom_resampler(arraylike):\n",
      " |      ...     return np.sum(arraylike) + 5\n",
      " |      ...\n",
      " |      >>> series.resample('3min').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3min, dtype: int64\n",
      " |\n",
      " |      For DataFrame objects, the keyword `on` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |\n",
      " |      >>> d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...      'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> df['week_starting'] = pd.date_range('01/01/2018',\n",
      " |      ...                                     periods=8,\n",
      " |      ...                                     freq='W')\n",
      " |      >>> df\n",
      " |         price  volume week_starting\n",
      " |      0     10      50    2018-01-07\n",
      " |      1     11      60    2018-01-14\n",
      " |      2      9      40    2018-01-21\n",
      " |      3     13     100    2018-01-28\n",
      " |      4     14      50    2018-02-04\n",
      " |      5     18     100    2018-02-11\n",
      " |      6     17      40    2018-02-18\n",
      " |      7     19      50    2018-02-25\n",
      " |      >>> df.resample('ME', on='week_starting').mean()\n",
      " |                     price  volume\n",
      " |      week_starting\n",
      " |      2018-01-31     10.75    62.5\n",
      " |      2018-02-28     17.00    60.0\n",
      " |\n",
      " |      For a DataFrame with MultiIndex, the keyword `level` can be used to\n",
      " |      specify on which level the resampling needs to take place.\n",
      " |\n",
      " |      >>> days = pd.date_range('1/1/2000', periods=4, freq='D')\n",
      " |      >>> d2 = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...       'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df2 = pd.DataFrame(\n",
      " |      ...     d2,\n",
      " |      ...     index=pd.MultiIndex.from_product(\n",
      " |      ...         [days, ['morning', 'afternoon']]\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |      >>> df2\n",
      " |                            price  volume\n",
      " |      2000-01-01 morning       10      50\n",
      " |                 afternoon     11      60\n",
      " |      2000-01-02 morning        9      40\n",
      " |                 afternoon     13     100\n",
      " |      2000-01-03 morning       14      50\n",
      " |                 afternoon     18     100\n",
      " |      2000-01-04 morning       17      40\n",
      " |                 afternoon     19      50\n",
      " |      >>> df2.resample('D', level=0).sum()\n",
      " |                  price  volume\n",
      " |      2000-01-01     21     110\n",
      " |      2000-01-02     22     140\n",
      " |      2000-01-03     32     150\n",
      " |      2000-01-04     36      90\n",
      " |\n",
      " |      If you want to adjust the start of the bins based on a fixed timestamp:\n",
      " |\n",
      " |      >>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n",
      " |      >>> rng = pd.date_range(start, end, freq='7min')\n",
      " |      >>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n",
      " |      >>> ts\n",
      " |      2000-10-01 23:30:00     0\n",
      " |      2000-10-01 23:37:00     3\n",
      " |      2000-10-01 23:44:00     6\n",
      " |      2000-10-01 23:51:00     9\n",
      " |      2000-10-01 23:58:00    12\n",
      " |      2000-10-02 00:05:00    15\n",
      " |      2000-10-02 00:12:00    18\n",
      " |      2000-10-02 00:19:00    21\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 7min, dtype: int64\n",
      " |\n",
      " |      >>> ts.resample('17min').sum()\n",
      " |      2000-10-01 23:14:00     0\n",
      " |      2000-10-01 23:31:00     9\n",
      " |      2000-10-01 23:48:00    21\n",
      " |      2000-10-02 00:05:00    54\n",
      " |      2000-10-02 00:22:00    24\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |      >>> ts.resample('17min', origin='epoch').sum()\n",
      " |      2000-10-01 23:18:00     0\n",
      " |      2000-10-01 23:35:00    18\n",
      " |      2000-10-01 23:52:00    27\n",
      " |      2000-10-02 00:09:00    39\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |      >>> ts.resample('17min', origin='2000-01-01').sum()\n",
      " |      2000-10-01 23:24:00     3\n",
      " |      2000-10-01 23:41:00    15\n",
      " |      2000-10-01 23:58:00    45\n",
      " |      2000-10-02 00:15:00    45\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |      If you want to adjust the start of the bins with an `offset` Timedelta, the two\n",
      " |      following lines are equivalent:\n",
      " |\n",
      " |      >>> ts.resample('17min', origin='start').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |      >>> ts.resample('17min', offset='23h30min').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |      If you want to take the largest Timestamp as the end of the bins:\n",
      " |\n",
      " |      >>> ts.resample('17min', origin='end').sum()\n",
      " |      2000-10-01 23:35:00     0\n",
      " |      2000-10-01 23:52:00    18\n",
      " |      2000-10-02 00:09:00    27\n",
      " |      2000-10-02 00:26:00    63\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |      In contrast with the `start_day`, you can use `end_day` to take the ceiling\n",
      " |      midnight of the largest Timestamp as the end of the bins and drop the bins\n",
      " |      not containing data:\n",
      " |\n",
      " |      >>> ts.resample('17min', origin='end_day').sum()\n",
      " |      2000-10-01 23:38:00     3\n",
      " |      2000-10-01 23:55:00    15\n",
      " |      2000-10-02 00:12:00    45\n",
      " |      2000-10-02 00:29:00    45\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |  rolling(self, window: 'int | dt.timedelta | str | BaseOffset | BaseIndexer', min_periods: 'int | None' = None, center: 'bool_t' = False, win_type: 'str | None' = None, on: 'str | None' = None, axis: 'Axis | lib.NoDefault' = <no_default>, closed: 'IntervalClosedType | None' = None, step: 'int | None' = None, method: 'str' = 'single') -> 'Window | Rolling'\n",
      " |      Provide rolling window calculations.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, timedelta, str, offset, or BaseIndexer subclass\n",
      " |          Size of the moving window.\n",
      " |\n",
      " |          If an integer, the fixed number of observations used for\n",
      " |          each window.\n",
      " |\n",
      " |          If a timedelta, str, or offset, the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes.\n",
      " |          To learn more about the offsets & frequency strings, please see `this link\n",
      " |          <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |\n",
      " |          If a BaseIndexer subclass, the window boundaries\n",
      " |          based on the defined ``get_window_bounds`` method. Additional rolling\n",
      " |          keyword arguments, namely ``min_periods``, ``center``, ``closed`` and\n",
      " |          ``step`` will be passed to ``get_window_bounds``.\n",
      " |\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |\n",
      " |          For a window that is specified by an offset, ``min_periods`` will default to 1.\n",
      " |\n",
      " |          For a window that is specified by an integer, ``min_periods`` will default\n",
      " |          to the size of the window.\n",
      " |\n",
      " |      center : bool, default False\n",
      " |          If False, set the window labels as the right edge of the window index.\n",
      " |\n",
      " |          If True, set the window labels as the center of the window index.\n",
      " |\n",
      " |      win_type : str, default None\n",
      " |          If ``None``, all points are evenly weighted.\n",
      " |\n",
      " |          If a string, it must be a valid `scipy.signal window function\n",
      " |          <https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows>`__.\n",
      " |\n",
      " |          Certain Scipy window types require additional parameters to be passed\n",
      " |          in the aggregation function. The additional parameters must match\n",
      " |          the keywords specified in the Scipy window type method signature.\n",
      " |\n",
      " |      on : str, optional\n",
      " |          For a DataFrame, a column label or Index level on which\n",
      " |          to calculate the rolling window, rather than the DataFrame's index.\n",
      " |\n",
      " |          Provided integer column is ignored and excluded from result since\n",
      " |          an integer index is not used to calculate the rolling window.\n",
      " |\n",
      " |      axis : int or str, default 0\n",
      " |          If ``0`` or ``'index'``, roll across the rows.\n",
      " |\n",
      " |          If ``1`` or ``'columns'``, roll across the columns.\n",
      " |\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |\n",
      " |              The axis keyword is deprecated. For ``axis=1``,\n",
      " |              transpose the DataFrame first instead.\n",
      " |\n",
      " |      closed : str, default None\n",
      " |          If ``'right'``, the first point in the window is excluded from calculations.\n",
      " |\n",
      " |          If ``'left'``, the last point in the window is excluded from calculations.\n",
      " |\n",
      " |          If ``'both'``, the no points in the window are excluded from calculations.\n",
      " |\n",
      " |          If ``'neither'``, the first and last points in the window are excluded\n",
      " |          from calculations.\n",
      " |\n",
      " |          Default ``None`` (``'right'``).\n",
      " |\n",
      " |      step : int, default None\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |          Evaluate the window at every ``step`` result, equivalent to slicing as\n",
      " |          ``[::step]``. ``window`` must be an integer. Using a step argument other\n",
      " |          than None or 1 will produce a result with a different shape than the input.\n",
      " |\n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |\n",
      " |          .. versionadded:: 1.3.0\n",
      " |\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |\n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.Window or pandas.api.typing.Rolling\n",
      " |          An instance of Window is returned if ``win_type`` is passed. Otherwise,\n",
      " |          an instance of Rolling is returned.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.generic>` for further usage details\n",
      " |      and examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |\n",
      " |      **window**\n",
      " |\n",
      " |      Rolling sum with a window length of 2 observations.\n",
      " |\n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |\n",
      " |      Rolling sum with a window span of 2 seconds.\n",
      " |\n",
      " |      >>> df_time = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                        index=[pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                               pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                               pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                               pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                               pd.Timestamp('20130101 09:00:06')])\n",
      " |\n",
      " |      >>> df_time\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |\n",
      " |      >>> df_time.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |\n",
      " |      Rolling sum with forward looking windows with 2 observations.\n",
      " |\n",
      " |      >>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)\n",
      " |      >>> df.rolling(window=indexer, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  1.0\n",
      " |      1  3.0\n",
      " |      2  2.0\n",
      " |      3  4.0\n",
      " |      4  4.0\n",
      " |\n",
      " |      **min_periods**\n",
      " |\n",
      " |      Rolling sum with a window length of 2 observations, but only needs a minimum of 1\n",
      " |      observation to calculate a value.\n",
      " |\n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |\n",
      " |      **center**\n",
      " |\n",
      " |      Rolling sum with the result assigned to the center of the window index.\n",
      " |\n",
      " |      >>> df.rolling(3, min_periods=1, center=True).sum()\n",
      " |           B\n",
      " |      0  1.0\n",
      " |      1  3.0\n",
      " |      2  3.0\n",
      " |      3  6.0\n",
      " |      4  4.0\n",
      " |\n",
      " |      >>> df.rolling(3, min_periods=1, center=False).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  6.0\n",
      " |\n",
      " |      **step**\n",
      " |\n",
      " |      Rolling sum with a window length of 2 observations, minimum of 1 observation to\n",
      " |      calculate a value, and a step of 2.\n",
      " |\n",
      " |      >>> df.rolling(2, min_periods=1, step=2).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      2  3.0\n",
      " |      4  4.0\n",
      " |\n",
      " |      **win_type**\n",
      " |\n",
      " |      Rolling sum with a window length of 2, using the Scipy ``'gaussian'``\n",
      " |      window type. ``std`` is required in the aggregation function.\n",
      " |\n",
      " |      >>> df.rolling(2, win_type='gaussian').sum(std=3)\n",
      " |                B\n",
      " |      0       NaN\n",
      " |      1  0.986207\n",
      " |      2  2.958621\n",
      " |      3       NaN\n",
      " |      4       NaN\n",
      " |\n",
      " |      **on**\n",
      " |\n",
      " |      Rolling sum with a window length of 2 days.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'A': [pd.to_datetime('2020-01-01'),\n",
      " |      ...           pd.to_datetime('2020-01-01'),\n",
      " |      ...           pd.to_datetime('2020-01-02'),],\n",
      " |      ...     'B': [1, 2, 3], },\n",
      " |      ...     index=pd.date_range('2020', periods=3))\n",
      " |\n",
      " |      >>> df\n",
      " |                          A  B\n",
      " |      2020-01-01 2020-01-01  1\n",
      " |      2020-01-02 2020-01-01  2\n",
      " |      2020-01-03 2020-01-02  3\n",
      " |\n",
      " |      >>> df.rolling('2D', on='A').sum()\n",
      " |                          A    B\n",
      " |      2020-01-01 2020-01-01  1.0\n",
      " |      2020-01-02 2020-01-01  3.0\n",
      " |      2020-01-03 2020-01-02  6.0\n",
      " |\n",
      " |  sample(self, n: 'int | None' = None, frac: 'float | None' = None, replace: 'bool_t' = False, weights=None, random_state: 'RandomState | None' = None, axis: 'Axis | None' = None, ignore_index: 'bool_t' = False) -> 'Self'\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |\n",
      " |      You can use `random_state` for reproducibility.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : bool, default False\n",
      " |          Allow or disallow sampling of the same row more than once.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          Infinite values not allowed.\n",
      " |      random_state : int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional\n",
      " |          If int, array-like, or BitGenerator, seed for random number generator.\n",
      " |          If np.random.RandomState or np.random.Generator, use as given.\n",
      " |\n",
      " |          .. versionchanged:: 1.4.0\n",
      " |\n",
      " |              np.random.Generator objects now accepted\n",
      " |\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type. For `Series` this parameter is unused and defaults to `None`.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, , n - 1.\n",
      " |\n",
      " |          .. versionadded:: 1.3.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A new object of same type as caller containing `n` items randomly\n",
      " |          sampled from the caller object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrameGroupBy.sample: Generates random samples from each group of a\n",
      " |          DataFrame object.\n",
      " |      SeriesGroupBy.sample: Generates random samples from each group of a\n",
      " |          Series object.\n",
      " |      numpy.random.choice: Generates a random sample from a given 1-D numpy\n",
      " |          array.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `frac` > 1, `replacement` should be set to `True`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0],\n",
      " |      ...                    'num_specimen_seen': [10, 2, 1, 8]},\n",
      " |      ...                   index=['falcon', 'dog', 'spider', 'fish'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      dog            4          0                  2\n",
      " |      spider         8          0                  1\n",
      " |      fish           0          0                  8\n",
      " |\n",
      " |      Extract 3 random elements from the ``Series`` ``df['num_legs']``:\n",
      " |      Note that we use `random_state` to ensure the reproducibility of\n",
      " |      the examples.\n",
      " |\n",
      " |      >>> df['num_legs'].sample(n=3, random_state=1)\n",
      " |      fish      0\n",
      " |      spider    8\n",
      " |      falcon    2\n",
      " |      Name: num_legs, dtype: int64\n",
      " |\n",
      " |      A random 50% sample of the ``DataFrame`` with replacement:\n",
      " |\n",
      " |      >>> df.sample(frac=0.5, replace=True, random_state=1)\n",
      " |            num_legs  num_wings  num_specimen_seen\n",
      " |      dog          4          0                  2\n",
      " |      fish         0          0                  8\n",
      " |\n",
      " |      An upsample sample of the ``DataFrame`` with replacement:\n",
      " |      Note that `replace` parameter has to be `True` for `frac` parameter > 1.\n",
      " |\n",
      " |      >>> df.sample(frac=2, replace=True, random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      falcon         2          2                 10\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |\n",
      " |      Using a DataFrame column as weights. Rows with larger value in the\n",
      " |      `num_specimen_seen` column are more likely to be sampled.\n",
      " |\n",
      " |      >>> df.sample(n=2, weights='num_specimen_seen', random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |\n",
      " |  set_flags(self, *, copy: 'bool_t' = False, allows_duplicate_labels: 'bool_t | None' = None) -> 'Self'\n",
      " |      Return a new object with updated flags.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, default False\n",
      " |          Specify if a copy of the object should be made.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      allows_duplicate_labels : bool, optional\n",
      " |          Whether the returned object allows duplicate labels.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          The same type as the caller.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method returns a new object that's a view on the same data\n",
      " |      as the input. Mutating the input or the output values will be reflected\n",
      " |      in the other.\n",
      " |\n",
      " |      This method is intended to be used in method chains.\n",
      " |\n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df2 = df.set_flags(allows_duplicate_labels=False)\n",
      " |      >>> df2.flags.allows_duplicate_labels\n",
      " |      False\n",
      " |\n",
      " |  squeeze(self, axis: 'Axis | None' = None)\n",
      " |      Squeeze 1 dimensional axis objects into scalars.\n",
      " |\n",
      " |      Series or DataFrames with a single element are squeezed to a scalar.\n",
      " |      DataFrames with a single column or a single row are squeezed to a\n",
      " |      Series. Otherwise the object is unchanged.\n",
      " |\n",
      " |      This method is most useful when you don't know if your\n",
      " |      object is a Series or DataFrame, but you do know it has just a single\n",
      " |      column. In that case you can safely call `squeeze` to ensure you have a\n",
      " |      Series.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          A specific axis to squeeze. By default, all length-1 axes are\n",
      " |          squeezed. For `Series` this parameter is unused and defaults to `None`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame, Series, or scalar\n",
      " |          The projection after squeezing `axis` or all the axes.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.iloc : Integer-location based indexing for selecting scalars.\n",
      " |      DataFrame.iloc : Integer-location based indexing for selecting Series.\n",
      " |      Series.to_frame : Inverse of DataFrame.squeeze for a\n",
      " |          single-column DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> primes = pd.Series([2, 3, 5, 7])\n",
      " |\n",
      " |      Slicing might produce a Series with a single value:\n",
      " |\n",
      " |      >>> even_primes = primes[primes % 2 == 0]\n",
      " |      >>> even_primes\n",
      " |      0    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> even_primes.squeeze()\n",
      " |      2\n",
      " |\n",
      " |      Squeezing objects with more than one value in every axis does nothing:\n",
      " |\n",
      " |      >>> odd_primes = primes[primes % 2 == 1]\n",
      " |      >>> odd_primes\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> odd_primes.squeeze()\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Squeezing is even more effective when used with DataFrames.\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])\n",
      " |      >>> df\n",
      " |         a  b\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |\n",
      " |      Slicing a single column will produce a DataFrame with the columns\n",
      " |      having only one value:\n",
      " |\n",
      " |      >>> df_a = df[['a']]\n",
      " |      >>> df_a\n",
      " |         a\n",
      " |      0  1\n",
      " |      1  3\n",
      " |\n",
      " |      So the columns can be squeezed down, resulting in a Series:\n",
      " |\n",
      " |      >>> df_a.squeeze('columns')\n",
      " |      0    1\n",
      " |      1    3\n",
      " |      Name: a, dtype: int64\n",
      " |\n",
      " |      Slicing a single row from a single column will produce a single\n",
      " |      scalar DataFrame:\n",
      " |\n",
      " |      >>> df_0a = df.loc[df.index < 1, ['a']]\n",
      " |      >>> df_0a\n",
      " |         a\n",
      " |      0  1\n",
      " |\n",
      " |      Squeezing the rows produces a single scalar Series:\n",
      " |\n",
      " |      >>> df_0a.squeeze('rows')\n",
      " |      a    1\n",
      " |      Name: 0, dtype: int64\n",
      " |\n",
      " |      Squeezing all axes will project directly into a scalar:\n",
      " |\n",
      " |      >>> df_0a.squeeze()\n",
      " |      1\n",
      " |\n",
      " |  swapaxes(self, axis1: 'Axis', axis2: 'Axis', copy: 'bool_t | None' = None) -> 'Self'\n",
      " |      Interchange axes and swap values axes appropriately.\n",
      " |\n",
      " |      .. deprecated:: 2.1.0\n",
      " |          ``swapaxes`` is deprecated and will be removed.\n",
      " |          Please use ``transpose`` instead.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same as input\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Please see examples for :meth:`DataFrame.transpose`.\n",
      " |\n",
      " |  tail(self, n: 'int' = 5) -> 'Self'\n",
      " |      Return the last `n` rows.\n",
      " |\n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |\n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the first `|n|` rows, equivalent to ``df[|n|:]``.\n",
      " |\n",
      " |      If n is larger than the number of rows, this function returns all rows.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.head : The first `n` rows of the caller object.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |\n",
      " |      Viewing the last 5 lines\n",
      " |\n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |\n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |\n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |\n",
      " |      For negative values of `n`\n",
      " |\n",
      " |      >>> df.tail(-3)\n",
      " |         animal\n",
      " |      3    lion\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |\n",
      " |  take(self, indices, axis: 'Axis' = 0, **kwargs) -> 'Self'\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |\n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed'],\n",
      " |      ...                   index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |\n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |\n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |\n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |\n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |\n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |\n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |\n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |\n",
      " |  to_clipboard(self, *, excel: 'bool_t' = True, sep: 'str | None' = None, **kwargs) -> 'None'\n",
      " |      Copy object to the system clipboard.\n",
      " |\n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          Produce output in a csv format for easy pasting into excel.\n",
      " |\n",
      " |          - True, use the provided separator for csv pasting.\n",
      " |          - False, write a string representation of the object to the clipboard.\n",
      " |\n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_csv.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |\n",
      " |        - Linux : `xclip`, or `xsel` (with `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - macOS : none\n",
      " |\n",
      " |      This method uses the processes developed for the package `pyperclip`. A\n",
      " |      solution to render any output string format is given in the examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |\n",
      " |      >>> df.to_clipboard(sep=',')  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |\n",
      " |      We can omit the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |\n",
      " |      >>> df.to_clipboard(sep=',', index=False)  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |\n",
      " |      Using the original `pyperclip` package for any string output format.\n",
      " |\n",
      " |      .. code-block:: python\n",
      " |\n",
      " |         import pyperclip\n",
      " |         html = df.style.to_html()\n",
      " |         pyperclip.copy(html)\n",
      " |\n",
      " |  to_csv(self, path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, *, sep: 'str' = ',', na_rep: 'str' = '', float_format: 'str | Callable | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | list[str]' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, mode: 'str' = 'w', encoding: 'str | None' = None, compression: 'CompressionOptions' = 'infer', quoting: 'int | None' = None, quotechar: 'str' = '\"', lineterminator: 'str | None' = None, chunksize: 'int | None' = None, date_format: 'str | None' = None, doublequote: 'bool_t' = True, escapechar: 'str | None' = None, decimal: 'str' = '.', errors: 'OpenFileErrors' = 'strict', storage_options: 'StorageOptions | None' = None) -> 'str | None'\n",
      " |      Write object to a comma-separated values (csv) file.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing os.PathLike[str]), or file-like\n",
      " |          object implementing a write() function. If None, the result is\n",
      " |          returned as a string. If a non-binary file object is passed, it should\n",
      " |          be opened with `newline=''`, disabling universal newlines. If a binary\n",
      " |          file object is passed, `mode` might need to contain a `'b'`.\n",
      " |      sep : str, default ','\n",
      " |          String of length 1. Field delimiter for the output file.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, Callable, default None\n",
      " |          Format string for floating point numbers. If a Callable is given, it takes\n",
      " |          precedence over other numeric formatting parameters, like decimal.\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, or False, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the object uses MultiIndex. If\n",
      " |          False do not print fields for index names. Use index_label=False\n",
      " |          for easier importing in R.\n",
      " |      mode : {'w', 'x', 'a'}, default 'w'\n",
      " |          Forwarded to either `open(mode=)` or `fsspec.open(mode=)` to control\n",
      " |          the file opening. Typical values include:\n",
      " |\n",
      " |          - 'w', truncate the file first.\n",
      " |          - 'x', exclusive creation, failing if the file already exists.\n",
      " |          - 'a', append to the end of file if it exists.\n",
      " |\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      " |          is a non-binary file object.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      " |          other key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |\n",
      " |             May be a dict with key 'method' as compression mode\n",
      " |             and other entries as additional compression options if\n",
      " |             compression mode is 'zip'.\n",
      " |\n",
      " |             Passing compression options as keys in dict is\n",
      " |             supported for compression modes 'gzip', 'bz2', 'zstd', and 'zip'.\n",
      " |      quoting : optional constant from csv module\n",
      " |          Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      " |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      " |          will treat them as non-numeric.\n",
      " |      quotechar : str, default '\\\"'\n",
      " |          String of length 1. Character used to quote fields.\n",
      " |      lineterminator : str, optional\n",
      " |          The newline character or character sequence to use in the output\n",
      " |          file. Defaults to `os.linesep`, which depends on the OS in which\n",
      " |          this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      " |\n",
      " |          .. versionchanged:: 1.5.0\n",
      " |\n",
      " |              Previously was line_terminator, changed for consistency with\n",
      " |              read_csv and the standard library 'csv' module.\n",
      " |\n",
      " |      chunksize : int or None\n",
      " |          Rows to write at a time.\n",
      " |      date_format : str, default None\n",
      " |          Format string for datetime objects.\n",
      " |      doublequote : bool, default True\n",
      " |          Control quoting of `quotechar` inside a field.\n",
      " |      escapechar : str, default None\n",
      " |          String of length 1. Character used to escape `sep` and `quotechar`\n",
      " |          when appropriate.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting csv format as a\n",
      " |          string. Otherwise returns None.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_csv : Load a CSV file into a DataFrame.\n",
      " |      to_excel : Write DataFrame to an Excel file.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create 'out.csv' containing 'df' without indices\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      " |      ...                    'mask': ['red', 'purple'],\n",
      " |      ...                    'weapon': ['sai', 'bo staff']})\n",
      " |      >>> df.to_csv('out.csv', index=False)  # doctest: +SKIP\n",
      " |\n",
      " |      Create 'out.zip' containing 'out.csv'\n",
      " |\n",
      " |      >>> df.to_csv(index=False)\n",
      " |      'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      " |      >>> compression_opts = dict(method='zip',\n",
      " |      ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      " |      >>> df.to_csv('out.zip', index=False,\n",
      " |      ...           compression=compression_opts)  # doctest: +SKIP\n",
      " |\n",
      " |      To write a csv file to a new folder or nested folder you will first\n",
      " |      need to create it using either Pathlib or os:\n",
      " |\n",
      " |      >>> from pathlib import Path  # doctest: +SKIP\n",
      " |      >>> filepath = Path('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      " |      >>> filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP\n",
      " |      >>> df.to_csv(filepath)  # doctest: +SKIP\n",
      " |\n",
      " |      >>> import os  # doctest: +SKIP\n",
      " |      >>> os.makedirs('folder/subfolder', exist_ok=True)  # doctest: +SKIP\n",
      " |      >>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      " |\n",
      " |  to_excel(self, excel_writer: 'FilePath | WriteExcelBuffer | ExcelWriter', *, sheet_name: 'str' = 'Sheet1', na_rep: 'str' = '', float_format: 'str | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'Sequence[Hashable] | bool_t' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, startrow: 'int' = 0, startcol: 'int' = 0, engine: \"Literal['openpyxl', 'xlsxwriter'] | None\" = None, merge_cells: 'bool_t' = True, inf_rep: 'str' = 'inf', freeze_panes: 'tuple[int, int] | None' = None, storage_options: 'StorageOptions | None' = None, engine_kwargs: 'dict[str, Any] | None' = None) -> 'None'\n",
      " |      Write object to an Excel sheet.\n",
      " |\n",
      " |      To write a single object to an Excel .xlsx file it is only necessary to\n",
      " |      specify a target file name. To write to multiple sheets it is necessary to\n",
      " |      create an `ExcelWriter` object with a target file name, and specify a sheet\n",
      " |      in the file to write to.\n",
      " |\n",
      " |      Multiple sheets may be written to by specifying unique `sheet_name`.\n",
      " |      With all data written to the file it is necessary to save the changes.\n",
      " |      Note that creating an `ExcelWriter` object with a file name that already\n",
      " |      exists will result in the contents of the existing file being erased.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : path-like, file-like, or ExcelWriter object\n",
      " |          File path or existing ExcelWriter.\n",
      " |      sheet_name : str, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, optional\n",
      " |          Format string for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` will format 0.1234 to 0.12.\n",
      " |      columns : sequence or list of str, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of string is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, optional\n",
      " |          Column label for index column(s) if desired. If not specified, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow : int, default 0\n",
      " |          Upper left cell row to dump data frame.\n",
      " |      startcol : int, default 0\n",
      " |          Upper left cell column to dump data frame.\n",
      " |      engine : str, optional\n",
      " |          Write engine to use, 'openpyxl' or 'xlsxwriter'. You can also set this\n",
      " |          via the options ``io.excel.xlsx.writer`` or\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |\n",
      " |      merge_cells : bool, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      inf_rep : str, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel).\n",
      " |      freeze_panes : tuple of int (length 2), optional\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |          .. versionadded:: 1.2.0\n",
      " |      engine_kwargs : dict, optional\n",
      " |          Arbitrary keyword arguments passed to excel engine.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      " |      ExcelWriter : Class for writing DataFrame objects into excel sheets.\n",
      " |      read_excel : Read an Excel file into a pandas DataFrame.\n",
      " |      read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |      io.formats.style.Styler.to_excel : Add styles to Excel sheet.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      For compatibility with :meth:`~DataFrame.to_csv`,\n",
      " |      to_excel serializes lists and dicts to strings before writing.\n",
      " |\n",
      " |      Once a workbook has been saved it is not possible to write further\n",
      " |      data without rewriting the whole workbook.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      Create, write to and save a workbook:\n",
      " |\n",
      " |      >>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                    index=['row 1', 'row 2'],\n",
      " |      ...                    columns=['col 1', 'col 2'])\n",
      " |      >>> df1.to_excel(\"output.xlsx\")  # doctest: +SKIP\n",
      " |\n",
      " |      To specify the sheet name:\n",
      " |\n",
      " |      >>> df1.to_excel(\"output.xlsx\",\n",
      " |      ...              sheet_name='Sheet_name_1')  # doctest: +SKIP\n",
      " |\n",
      " |      If you wish to write to more than one sheet in the workbook, it is\n",
      " |      necessary to specify an ExcelWriter object:\n",
      " |\n",
      " |      >>> df2 = df1.copy()\n",
      " |      >>> with pd.ExcelWriter('output.xlsx') as writer:  # doctest: +SKIP\n",
      " |      ...     df1.to_excel(writer, sheet_name='Sheet_name_1')\n",
      " |      ...     df2.to_excel(writer, sheet_name='Sheet_name_2')\n",
      " |\n",
      " |      ExcelWriter can also be used to append to an existing Excel file:\n",
      " |\n",
      " |      >>> with pd.ExcelWriter('output.xlsx',\n",
      " |      ...                     mode='a') as writer:  # doctest: +SKIP\n",
      " |      ...     df1.to_excel(writer, sheet_name='Sheet_name_3')\n",
      " |\n",
      " |      To set the library that is used to write the Excel file,\n",
      " |      you can pass the `engine` keyword (the default engine is\n",
      " |      automatically chosen depending on the file extension):\n",
      " |\n",
      " |      >>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  # doctest: +SKIP\n",
      " |\n",
      " |  to_hdf(self, path_or_buf: 'FilePath | HDFStore', *, key: 'str', mode: \"Literal['a', 'w', 'r+']\" = 'a', complevel: 'int | None' = None, complib: \"Literal['zlib', 'lzo', 'bzip2', 'blosc'] | None\" = None, append: 'bool_t' = False, format: \"Literal['fixed', 'table'] | None\" = None, index: 'bool_t' = True, min_itemsize: 'int | dict[str, int] | None' = None, nan_rep=None, dropna: 'bool_t | None' = None, data_columns: 'Literal[True] | list[str] | None' = None, errors: 'OpenFileErrors' = 'strict', encoding: 'str' = 'UTF-8') -> 'None'\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |\n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |\n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |\n",
      " |      .. warning::\n",
      " |\n",
      " |         One can store a subclass of ``DataFrame`` or ``Series`` to HDF5,\n",
      " |         but the type of the subclass is lost upon storing.\n",
      " |\n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |\n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      complevel : {0-9}, default None\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 or None disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          These additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      format : {'fixed', 'table', None}, default 'fixed'\n",
      " |          Possible values:\n",
      " |\n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |          - If None, pd.get_option('io.hdf.default_format') is checked,\n",
      " |            followed by fallback to \"fixed\".\n",
      " |      index : bool, default True\n",
      " |          Write DataFrame index as a column.\n",
      " |      min_itemsize : dict or int, optional\n",
      " |          Map column names to minimum string sizes for columns.\n",
      " |      nan_rep : Any, optional\n",
      " |          How to represent null values as str.\n",
      " |          Not allowed with append=True.\n",
      " |      dropna : bool, default False, optional\n",
      " |          Remove missing values.\n",
      " |      data_columns : list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See\n",
      " |          :ref:`Query via data columns<io.hdf5-query-data-columns>`. for\n",
      " |          more information.\n",
      " |          Applicable only to format='table'.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      encoding : str, default \"UTF-8\"\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_orc : Write a DataFrame to the binary orc format.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a SQL table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])  # doctest: +SKIP\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')  # doctest: +SKIP\n",
      " |\n",
      " |      We can add another object to the same file:\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])  # doctest: +SKIP\n",
      " |      >>> s.to_hdf('data.h5', key='s')  # doctest: +SKIP\n",
      " |\n",
      " |      Reading from HDF file:\n",
      " |\n",
      " |      >>> pd.read_hdf('data.h5', 'df')  # doctest: +SKIP\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')  # doctest: +SKIP\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |\n",
      " |  to_json(self, path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, *, orient: \"Literal['split', 'records', 'index', 'table', 'columns', 'values'] | None\" = None, date_format: 'str | None' = None, double_precision: 'int' = 10, force_ascii: 'bool_t' = True, date_unit: 'TimeUnit' = 'ms', default_handler: 'Callable[[Any], JSONSerializable] | None' = None, lines: 'bool_t' = False, compression: 'CompressionOptions' = 'infer', index: 'bool_t | None' = None, indent: 'int | None' = None, storage_options: 'StorageOptions | None' = None, mode: \"Literal['a', 'w']\" = 'w') -> 'str | None'\n",
      " |      Convert the object to a JSON string.\n",
      " |\n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing os.PathLike[str]), or file-like\n",
      " |          object implementing a write() function. If None, the result is\n",
      " |          returned as a string.\n",
      " |      orient : str\n",
      " |          Indication of expected JSON string format.\n",
      " |\n",
      " |          * Series:\n",
      " |\n",
      " |              - default is 'index'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'table'}.\n",
      " |\n",
      " |          * DataFrame:\n",
      " |\n",
      " |              - default is 'columns'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'columns',\n",
      " |                'values', 'table'}.\n",
      " |\n",
      " |          * The format of the JSON string:\n",
      " |\n",
      " |              - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
      " |                'data' -> [values]}\n",
      " |              - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
      " |              - 'index' : dict like {index -> {column -> value}}\n",
      " |              - 'columns' : dict like {column -> {index -> value}}\n",
      " |              - 'values' : just the values array\n",
      " |              - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |\n",
      " |              Describing the data, where data component is like ``orient='records'``.\n",
      " |\n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values. The possible maximal value is 15.\n",
      " |          Passing double_precision greater than 15 will raise a ValueError.\n",
      " |      force_ascii : bool, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : str, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : bool, default False\n",
      " |          If 'orient' is 'records' write out line-delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not\n",
      " |          list-like.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      " |          other key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |\n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |\n",
      " |      index : bool or None, default None\n",
      " |          The index is only used when 'orient' is 'split', 'index', 'column',\n",
      " |          or 'table'. Of these, 'index' and 'column' do not support\n",
      " |          `index=False`.\n",
      " |\n",
      " |      indent : int, optional\n",
      " |         Length of whitespace used to indent each record.\n",
      " |\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      mode : str, default 'w' (writing)\n",
      " |          Specify the IO mode for output when supplying a path_or_buf.\n",
      " |          Accepted args are 'w' (writing) and 'a' (append) only.\n",
      " |          mode='a' is only supported when lines is True and orient is 'records'.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting json format as a\n",
      " |          string. Otherwise returns None.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_json : Convert a JSON string to pandas object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The behavior of ``indent=0`` varies from the stdlib, which does not\n",
      " |      indent the output but does insert newlines. Currently, ``indent=0``\n",
      " |      and the default ``indent=None`` are equivalent in pandas, though this\n",
      " |      may change in a future release.\n",
      " |\n",
      " |      ``orient='table'`` contains a 'pandas_version' field under 'schema'.\n",
      " |      This stores the version of `pandas` used in the latest revision of the\n",
      " |      schema.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from json import loads, dumps\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [[\"a\", \"b\"], [\"c\", \"d\"]],\n",
      " |      ...     index=[\"row 1\", \"row 2\"],\n",
      " |      ...     columns=[\"col 1\", \"col 2\"],\n",
      " |      ... )\n",
      " |\n",
      " |      >>> result = df.to_json(orient=\"split\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"columns\": [\n",
      " |              \"col 1\",\n",
      " |              \"col 2\"\n",
      " |          ],\n",
      " |          \"index\": [\n",
      " |              \"row 1\",\n",
      " |              \"row 2\"\n",
      " |          ],\n",
      " |          \"data\": [\n",
      " |              [\n",
      " |                  \"a\",\n",
      " |                  \"b\"\n",
      " |              ],\n",
      " |              [\n",
      " |                  \"c\",\n",
      " |                  \"d\"\n",
      " |              ]\n",
      " |          ]\n",
      " |      }\n",
      " |\n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |\n",
      " |      >>> result = df.to_json(orient=\"records\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      ]\n",
      " |\n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |\n",
      " |      >>> result = df.to_json(orient=\"index\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"row 1\": {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          \"row 2\": {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |\n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |\n",
      " |      >>> result = df.to_json(orient=\"columns\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"col 1\": {\n",
      " |              \"row 1\": \"a\",\n",
      " |              \"row 2\": \"c\"\n",
      " |          },\n",
      " |          \"col 2\": {\n",
      " |              \"row 1\": \"b\",\n",
      " |              \"row 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |\n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |\n",
      " |      >>> result = df.to_json(orient=\"values\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          [\n",
      " |              \"a\",\n",
      " |              \"b\"\n",
      " |          ],\n",
      " |          [\n",
      " |              \"c\",\n",
      " |              \"d\"\n",
      " |          ]\n",
      " |      ]\n",
      " |\n",
      " |      Encoding with Table Schema:\n",
      " |\n",
      " |      >>> result = df.to_json(orient=\"table\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"schema\": {\n",
      " |              \"fields\": [\n",
      " |                  {\n",
      " |                      \"name\": \"index\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 1\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 2\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  }\n",
      " |              ],\n",
      " |              \"primaryKey\": [\n",
      " |                  \"index\"\n",
      " |              ],\n",
      " |              \"pandas_version\": \"1.4.0\"\n",
      " |          },\n",
      " |          \"data\": [\n",
      " |              {\n",
      " |                  \"index\": \"row 1\",\n",
      " |                  \"col 1\": \"a\",\n",
      " |                  \"col 2\": \"b\"\n",
      " |              },\n",
      " |              {\n",
      " |                  \"index\": \"row 2\",\n",
      " |                  \"col 1\": \"c\",\n",
      " |                  \"col 2\": \"d\"\n",
      " |              }\n",
      " |          ]\n",
      " |      }\n",
      " |\n",
      " |  to_latex(self, buf: 'FilePath | WriteBuffer[str] | None' = None, *, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | SequenceNotStr[str]' = True, index: 'bool_t' = True, na_rep: 'str' = 'NaN', formatters: 'FormattersType | None' = None, float_format: 'FloatFormatType | None' = None, sparsify: 'bool_t | None' = None, index_names: 'bool_t' = True, bold_rows: 'bool_t' = False, column_format: 'str | None' = None, longtable: 'bool_t | None' = None, escape: 'bool_t | None' = None, encoding: 'str | None' = None, decimal: 'str' = '.', multicolumn: 'bool_t | None' = None, multicolumn_format: 'str | None' = None, multirow: 'bool_t | None' = None, caption: 'str | tuple[str, str] | None' = None, label: 'str | None' = None, position: 'str | None' = None) -> 'str | None'\n",
      " |      Render object to a LaTeX tabular, longtable, or nested table.\n",
      " |\n",
      " |      Requires ``\\usepackage{{booktabs}}``.  The output can be copy/pasted\n",
      " |      into a main LaTeX document or read from an external file\n",
      " |      with ``\\input{{table.tex}}``.\n",
      " |\n",
      " |      .. versionchanged:: 2.0.0\n",
      " |         Refactored to use the Styler implementation via jinja2 templating.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : list of label, optional\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given,\n",
      " |          it is assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      na_rep : str, default 'NaN'\n",
      " |          Missing data representation.\n",
      " |      formatters : list of functions or dict of {{str: function}}, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function or str, optional, default None\n",
      " |          Formatter for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` and ``float_format=\"{{:0.2f}}\".format`` will\n",
      " |          both result in 0.1234 being formatted as 0.12.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row. By default, the value will be\n",
      " |          read from the config module.\n",
      " |      index_names : bool, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      bold_rows : bool, default False\n",
      " |          Make the row labels bold in the output.\n",
      " |      column_format : str, optional\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g. 'rcl' for 3\n",
      " |          columns. By default, 'l' will be used for all columns except\n",
      " |          columns of numbers, which default to 'r'.\n",
      " |      longtable : bool, optional\n",
      " |          Use a longtable environment instead of tabular. Requires\n",
      " |          adding a \\usepackage{{longtable}} to your LaTeX preamble.\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module, and set to `True` if the option ``styler.latex.environment`` is\n",
      " |          `\"longtable\"`.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed.\n",
      " |      escape : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module and set to `True` if the option ``styler.format.escape`` is\n",
      " |          `\"latex\"`. When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed, as has the\n",
      " |             default value to `False`.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      multicolumn : bool, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module, and is set\n",
      " |          as the option ``styler.sparse.columns``.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed.\n",
      " |      multicolumn_format : str, default 'r'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module, and is set as the option\n",
      " |          ``styler.latex.multicol_align``.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed, as has the\n",
      " |             default value to \"r\".\n",
      " |      multirow : bool, default True\n",
      " |          Use \\multirow to enhance MultiIndex rows. Requires adding a\n",
      " |          \\usepackage{{multirow}} to your LaTeX preamble. Will print\n",
      " |          centered labels (instead of top-aligned) across the contained\n",
      " |          rows, separating groups via clines. The default will be read\n",
      " |          from the pandas config module, and is set as the option\n",
      " |          ``styler.sparse.index``.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed, as has the\n",
      " |             default value to `True`.\n",
      " |      caption : str or tuple, optional\n",
      " |          Tuple (full_caption, short_caption),\n",
      " |          which results in ``\\caption[short_caption]{{full_caption}}``;\n",
      " |          if a single string is passed, no short caption will be set.\n",
      " |      label : str, optional\n",
      " |          The LaTeX label to be placed inside ``\\label{{}}`` in the output.\n",
      " |          This is used with ``\\ref{{}}`` in the main ``.tex`` file.\n",
      " |\n",
      " |      position : str, optional\n",
      " |          The LaTeX positional argument for tables, to be placed after\n",
      " |          ``\\begin{{}}`` in the output.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns None.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      io.formats.style.Styler.to_latex : Render a DataFrame to LaTeX\n",
      " |          with conditional formatting.\n",
      " |      DataFrame.to_string : Render a DataFrame to a console-friendly\n",
      " |          tabular output.\n",
      " |      DataFrame.to_html : Render a DataFrame as an HTML table.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      As of v2.0.0 this method has changed to use the Styler implementation as\n",
      " |      part of :meth:`.Styler.to_latex` via ``jinja2`` templating. This means\n",
      " |      that ``jinja2`` is a requirement, and needs to be installed, for this method\n",
      " |      to function. It is advised that users switch to using Styler, since that\n",
      " |      implementation is more frequently updated and contains much more\n",
      " |      flexibility with the output.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Convert a general DataFrame to LaTeX with formatting:\n",
      " |\n",
      " |      >>> df = pd.DataFrame(dict(name=['Raphael', 'Donatello'],\n",
      " |      ...                        age=[26, 45],\n",
      " |      ...                        height=[181.23, 177.65]))\n",
      " |      >>> print(df.to_latex(index=False,\n",
      " |      ...                   formatters={\"name\": str.upper},\n",
      " |      ...                   float_format=\"{:.1f}\".format,\n",
      " |      ... ))  # doctest: +SKIP\n",
      " |      \\begin{tabular}{lrr}\n",
      " |      \\toprule\n",
      " |      name & age & height \\\\\n",
      " |      \\midrule\n",
      " |      RAPHAEL & 26 & 181.2 \\\\\n",
      " |      DONATELLO & 45 & 177.7 \\\\\n",
      " |      \\bottomrule\n",
      " |      \\end{tabular}\n",
      " |\n",
      " |  to_pickle(self, path: 'FilePath | WriteBuffer[bytes]', *, compression: 'CompressionOptions' = 'infer', protocol: 'int' = 5, storage_options: 'StorageOptions | None' = None) -> 'None'\n",
      " |      Pickle (serialize) object to file.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, or file-like object\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function. File path where\n",
      " |          the pickled object will be stored.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      " |          other key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values are 0, 1, 2, 3, 4, 5. A negative value for the protocol\n",
      " |          parameter is equivalent to setting its value to HIGHEST_PROTOCOL.\n",
      " |\n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html.\n",
      " |\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})  # doctest: +SKIP\n",
      " |      >>> original_df  # doctest: +SKIP\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")  # doctest: +SKIP\n",
      " |\n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")  # doctest: +SKIP\n",
      " |      >>> unpickled_df  # doctest: +SKIP\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |\n",
      " |  to_sql(self, name: 'str', con, *, schema: 'str | None' = None, if_exists: \"Literal['fail', 'replace', 'append']\" = 'fail', index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, chunksize: 'int | None' = None, dtype: 'DtypeArg | None' = None, method: \"Literal['multi'] | Callable | None\" = None) -> 'int | None'\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |\n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.(Engine or Connection) or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects. The user\n",
      " |          is responsible for engine disposal and connection closure for the SQLAlchemy\n",
      " |          connectable. See `here                 <https://docs.sqlalchemy.org/en/20/core/connections.html>`_.\n",
      " |          If passing a sqlalchemy.engine.Connection which is already in a transaction,\n",
      " |          the transaction will not be committed.  If passing a sqlite3.Connection,\n",
      " |          it will not be possible to roll back the record insertion.\n",
      " |\n",
      " |      schema : str, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |\n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |\n",
      " |      index : bool, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table. Creates a table index for this column.\n",
      " |      index_label : str or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Specify the number of rows in each batch to be written at a time.\n",
      " |          By default, all rows will be written at once.\n",
      " |      dtype : dict or scalar, optional\n",
      " |          Specifying the datatype for columns. If a dictionary is used, the\n",
      " |          keys should be the column names and the values should be the\n",
      " |          SQLAlchemy types or strings for the sqlite3 legacy mode. If a\n",
      " |          scalar is provided, it will be applied to all columns.\n",
      " |      method : {None, 'multi', callable}, optional\n",
      " |          Controls the SQL insertion clause used:\n",
      " |\n",
      " |          * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      " |          * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
      " |          * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
      " |\n",
      " |          Details and a sample callable implementation can be found in the\n",
      " |          section :ref:`insert method <io.sql.method>`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or int\n",
      " |          Number of rows affected by to_sql. None is returned if the callable\n",
      " |          passed into ``method`` does not return an integer number of rows.\n",
      " |\n",
      " |          The number of returned rows affected is the sum of the ``rowcount``\n",
      " |          attribute of ``sqlite3.Cursor`` or SQLAlchemy connectable which may not\n",
      " |          reflect the exact number of written rows as stipulated in the\n",
      " |          `sqlite3 <https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.rowcount>`__ or\n",
      " |          `SQLAlchemy <https://docs.sqlalchemy.org/en/20/core/connections.html#sqlalchemy.engine.CursorResult.rowcount>`__.\n",
      " |\n",
      " |          .. versionadded:: 1.4.0\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_sql : Read a DataFrame from a table.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Timezone aware datetime columns will be written as\n",
      " |      ``Timestamp with timezone`` type with SQLAlchemy if supported by the\n",
      " |      database. Otherwise, the datetimes will be stored as timezone unaware\n",
      " |      timestamps local to the original timezone.\n",
      " |\n",
      " |      Not all datastores support ``method=\"multi\"``. Oracle, for example,\n",
      " |      does not support multi-value insert.\n",
      " |\n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create an in-memory SQLite database.\n",
      " |\n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |\n",
      " |      Create a table from scratch with 3 rows.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |\n",
      " |      >>> df.to_sql(name='users', con=engine)\n",
      " |      3\n",
      " |      >>> from sqlalchemy import text\n",
      " |      >>> with engine.connect() as conn:\n",
      " |      ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |\n",
      " |      An `sqlalchemy.engine.Connection` can also be passed to `con`:\n",
      " |\n",
      " |      >>> with engine.begin() as connection:\n",
      " |      ...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      ...     df1.to_sql(name='users', con=connection, if_exists='append')\n",
      " |      2\n",
      " |\n",
      " |      This is allowed to support operations that require that the same\n",
      " |      DBAPI connection is used for the entire operation.\n",
      " |\n",
      " |      >>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})\n",
      " |      >>> df2.to_sql(name='users', con=engine, if_exists='append')\n",
      " |      2\n",
      " |      >>> with engine.connect() as conn:\n",
      " |      ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),\n",
      " |       (1, 'User 7')]\n",
      " |\n",
      " |      Overwrite the table with just ``df2``.\n",
      " |\n",
      " |      >>> df2.to_sql(name='users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      2\n",
      " |      >>> with engine.connect() as conn:\n",
      " |      ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
      " |      [(0, 'User 6'), (1, 'User 7')]\n",
      " |\n",
      " |      Use ``method`` to define a callable insertion method to do nothing\n",
      " |      if there's a primary key conflict on a table in a PostgreSQL database.\n",
      " |\n",
      " |      >>> from sqlalchemy.dialects.postgresql import insert\n",
      " |      >>> def insert_on_conflict_nothing(table, conn, keys, data_iter):\n",
      " |      ...     # \"a\" is the primary key in \"conflict_table\"\n",
      " |      ...     data = [dict(zip(keys, row)) for row in data_iter]\n",
      " |      ...     stmt = insert(table.table).values(data).on_conflict_do_nothing(index_elements=[\"a\"])\n",
      " |      ...     result = conn.execute(stmt)\n",
      " |      ...     return result.rowcount\n",
      " |      >>> df_conflict.to_sql(name=\"conflict_table\", con=conn, if_exists=\"append\", method=insert_on_conflict_nothing)  # doctest: +SKIP\n",
      " |      0\n",
      " |\n",
      " |      For MySQL, a callable to update columns ``b`` and ``c`` if there's a conflict\n",
      " |      on a primary key.\n",
      " |\n",
      " |      >>> from sqlalchemy.dialects.mysql import insert\n",
      " |      >>> def insert_on_conflict_update(table, conn, keys, data_iter):\n",
      " |      ...     # update columns \"b\" and \"c\" on primary key conflict\n",
      " |      ...     data = [dict(zip(keys, row)) for row in data_iter]\n",
      " |      ...     stmt = (\n",
      " |      ...         insert(table.table)\n",
      " |      ...         .values(data)\n",
      " |      ...     )\n",
      " |      ...     stmt = stmt.on_duplicate_key_update(b=stmt.inserted.b, c=stmt.inserted.c)\n",
      " |      ...     result = conn.execute(stmt)\n",
      " |      ...     return result.rowcount\n",
      " |      >>> df_conflict.to_sql(name=\"conflict_table\", con=conn, if_exists=\"append\", method=insert_on_conflict_update)  # doctest: +SKIP\n",
      " |      2\n",
      " |\n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |\n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql(name='integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      3\n",
      " |\n",
      " |      >>> with engine.connect() as conn:\n",
      " |      ...   conn.execute(text(\"SELECT * FROM integers\")).fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |\n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      xarray.DataArray or xarray.Dataset\n",
      " |          Data in the pandas structure converted to Dataset if the object is\n",
      " |          a DataFrame, or a DataArray if the object is a Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <https://xarray.pydata.org/en/stable/>`__\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0, 2),\n",
      " |      ...                    ('parrot', 'bird', 24.0, 2),\n",
      " |      ...                    ('lion', 'mammal', 80.5, 4),\n",
      " |      ...                    ('monkey', 'mammal', np.nan, 4)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed',\n",
      " |      ...                            'num_legs'])\n",
      " |      >>> df\n",
      " |           name   class  max_speed  num_legs\n",
      " |      0  falcon    bird      389.0         2\n",
      " |      1  parrot    bird       24.0         2\n",
      " |      2    lion  mammal       80.5         4\n",
      " |      3  monkey  mammal        NaN         4\n",
      " |\n",
      " |      >>> df.to_xarray()  # doctest: +SKIP\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:    (index: 4)\n",
      " |      Coordinates:\n",
      " |        * index      (index) int64 32B 0 1 2 3\n",
      " |      Data variables:\n",
      " |          name       (index) object 32B 'falcon' 'parrot' 'lion' 'monkey'\n",
      " |          class      (index) object 32B 'bird' 'bird' 'mammal' 'mammal'\n",
      " |          max_speed  (index) float64 32B 389.0 24.0 80.5 nan\n",
      " |          num_legs   (index) int64 32B 2 2 4 4\n",
      " |\n",
      " |      >>> df['max_speed'].to_xarray()  # doctest: +SKIP\n",
      " |      <xarray.DataArray 'max_speed' (index: 4)>\n",
      " |      array([389. ,  24. ,  80.5,   nan])\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2 3\n",
      " |\n",
      " |      >>> dates = pd.to_datetime(['2018-01-01', '2018-01-01',\n",
      " |      ...                         '2018-01-02', '2018-01-02'])\n",
      " |      >>> df_multiindex = pd.DataFrame({'date': dates,\n",
      " |      ...                               'animal': ['falcon', 'parrot',\n",
      " |      ...                                          'falcon', 'parrot'],\n",
      " |      ...                               'speed': [350, 18, 361, 15]})\n",
      " |      >>> df_multiindex = df_multiindex.set_index(['date', 'animal'])\n",
      " |\n",
      " |      >>> df_multiindex\n",
      " |                         speed\n",
      " |      date       animal\n",
      " |      2018-01-01 falcon    350\n",
      " |                 parrot     18\n",
      " |      2018-01-02 falcon    361\n",
      " |                 parrot     15\n",
      " |\n",
      " |      >>> df_multiindex.to_xarray()  # doctest: +SKIP\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (date: 2, animal: 2)\n",
      " |      Coordinates:\n",
      " |        * date     (date) datetime64[ns] 2018-01-01 2018-01-02\n",
      " |        * animal   (animal) object 'falcon' 'parrot'\n",
      " |      Data variables:\n",
      " |          speed    (date, animal) int64 350 18 361 15\n",
      " |\n",
      " |  truncate(self, before=None, after=None, axis: 'Axis | None' = None, copy: 'bool_t | None' = None) -> 'Self'\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |\n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, str, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, str, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      copy : bool, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                   index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |\n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |\n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |\n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |\n",
      " |      For Series, only rows can be truncated.\n",
      " |\n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |\n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |\n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |\n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |\n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |\n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |\n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |\n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |\n",
      " |  tz_convert(self, tz, axis: 'Axis' = 0, level=None, copy: 'bool_t | None' = None) -> 'Self'\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo object or None\n",
      " |          Target time zone. Passing ``None`` will convert to\n",
      " |          UTC and remove the timezone information.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis is a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Object with time zone converted axis.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Change to another time zone:\n",
      " |\n",
      " |      >>> s = pd.Series(\n",
      " |      ...     [1],\n",
      " |      ...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']),\n",
      " |      ... )\n",
      " |      >>> s.tz_convert('Asia/Shanghai')\n",
      " |      2018-09-15 07:30:00+08:00    1\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Pass None to convert to UTC and get a tz-naive index:\n",
      " |\n",
      " |      >>> s = pd.Series([1],\n",
      " |      ...               index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))\n",
      " |      >>> s.tz_convert(None)\n",
      " |      2018-09-14 23:30:00    1\n",
      " |      dtype: int64\n",
      " |\n",
      " |  tz_localize(self, tz, axis: 'Axis' = 0, level=None, copy: 'bool_t | None' = None, ambiguous: 'TimeAmbiguous' = 'raise', nonexistent: 'TimeNonexistent' = 'raise') -> 'Self'\n",
      " |      Localize tz-naive index of a Series or DataFrame to target time zone.\n",
      " |\n",
      " |      This operation localizes the Index. To localize the values in a\n",
      " |      timezone-naive Series, use :meth:`Series.dt.tz_localize`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo or None\n",
      " |          Time zone to localize. Passing ``None`` will remove the\n",
      " |          time zone information and preserve local time.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          When clocks moved backward due to DST, ambiguous times may arise.\n",
      " |          For example in Central European Time (UTC+01), when going from\n",
      " |          03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n",
      " |          00:30:00 UTC and at 01:30:00 UTC. In such a situation, the\n",
      " |          `ambiguous` parameter dictates how ambiguous times should be\n",
      " |          handled.\n",
      " |\n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      nonexistent : str, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST. Valid values are:\n",
      " |\n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Same type as the input.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Localize local times:\n",
      " |\n",
      " |      >>> s = pd.Series(\n",
      " |      ...     [1],\n",
      " |      ...     index=pd.DatetimeIndex(['2018-09-15 01:30:00']),\n",
      " |      ... )\n",
      " |      >>> s.tz_localize('CET')\n",
      " |      2018-09-15 01:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Pass None to convert to tz-naive index and preserve local time:\n",
      " |\n",
      " |      >>> s = pd.Series([1],\n",
      " |      ...               index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))\n",
      " |      >>> s.tz_localize(None)\n",
      " |      2018-09-15 01:30:00    1\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Be careful with DST changes. When there is sequential data, pandas\n",
      " |      can infer the DST time:\n",
      " |\n",
      " |      >>> s = pd.Series(range(7),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 03:00:00',\n",
      " |      ...                                       '2018-10-28 03:30:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous='infer')\n",
      " |      2018-10-28 01:30:00+02:00    0\n",
      " |      2018-10-28 02:00:00+02:00    1\n",
      " |      2018-10-28 02:30:00+02:00    2\n",
      " |      2018-10-28 02:00:00+01:00    3\n",
      " |      2018-10-28 02:30:00+01:00    4\n",
      " |      2018-10-28 03:00:00+01:00    5\n",
      " |      2018-10-28 03:30:00+01:00    6\n",
      " |      dtype: int64\n",
      " |\n",
      " |      In some cases, inferring the DST is impossible. In such cases, you can\n",
      " |      pass an ndarray to the ambiguous parameter to set the DST explicitly\n",
      " |\n",
      " |      >>> s = pd.Series(range(3),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',\n",
      " |      ...                                       '2018-10-28 02:36:00',\n",
      " |      ...                                       '2018-10-28 03:46:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))\n",
      " |      2018-10-28 01:20:00+02:00    0\n",
      " |      2018-10-28 02:36:00+02:00    1\n",
      " |      2018-10-28 03:46:00+01:00    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      If the DST transition causes nonexistent times, you can shift these\n",
      " |      dates forward or backward with a timedelta object or `'shift_forward'`\n",
      " |      or `'shift_backward'`.\n",
      " |\n",
      " |      >>> s = pd.Series(range(2),\n",
      " |      ...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',\n",
      " |      ...                                       '2015-03-29 03:30:00']))\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')\n",
      " |      2015-03-29 03:00:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')\n",
      " |      2015-03-29 01:59:59.999999999+01:00    0\n",
      " |      2015-03-29 03:30:00+02:00              1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1h'))\n",
      " |      2015-03-29 03:30:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |\n",
      " |  where(self, cond, other=nan, *, inplace: 'bool_t' = False, axis: 'Axis | None' = None, level: 'Level | None' = None) -> 'Self | None'\n",
      " |      Replace values where the condition is False.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |          If not specified, entries will be filled with the corresponding\n",
      " |          NULL value (``np.nan`` for numpy dtypes, ``pd.NA`` for extension\n",
      " |          dtypes).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed. For `Series` this parameter is\n",
      " |          unused and defaults to 0.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask` : Return an object of same shape as\n",
      " |          self.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used. If the axis of ``other`` does not align with axis of\n",
      " |      ``cond`` Series/DataFrame, the misaligned index positions will be filled with\n",
      " |      False.\n",
      " |\n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |\n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |\n",
      " |      The dtype of the object takes precedence. The fill value is casted to\n",
      " |      the object's dtype, if this can be done losslessly.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> t = pd.Series([True, False])\n",
      " |      >>> s.where(t, 99)\n",
      " |      0     0\n",
      " |      1    99\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(t, 99)\n",
      " |      0    99\n",
      " |      1     1\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |\n",
      " |  xs(self, key: 'IndexLabel', axis: 'Axis' = 0, level: 'IndexLabel | None' = None, drop_level: 'bool_t' = True) -> 'Self'\n",
      " |      Return cross-section from the Series/DataFrame.\n",
      " |\n",
      " |      This method takes a `key` argument to select data at a particular\n",
      " |      level of a MultiIndex.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : label or tuple of label\n",
      " |          Label contained in the index, or partially in a MultiIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to retrieve cross-section on.\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : bool, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Cross-section from the original Series or DataFrame\n",
      " |          corresponding to the selected index levels.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      DataFrame.iloc : Purely integer-location based indexing\n",
      " |          for selection by position.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      `xs` can not be used to set values.\n",
      " |\n",
      " |      MultiIndex Slicers is a generic way to get/set values on\n",
      " |      any level or levels.\n",
      " |      It is a superset of `xs` functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'num_legs': [4, 4, 2, 2],\n",
      " |      ...      'num_wings': [0, 0, 2, 2],\n",
      " |      ...      'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
      " |      ...      'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
      " |      ...      'locomotion': ['walks', 'walks', 'flies', 'walks']}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df = df.set_index(['class', 'animal', 'locomotion'])\n",
      " |      >>> df\n",
      " |                                 num_legs  num_wings\n",
      " |      class  animal  locomotion\n",
      " |      mammal cat     walks              4          0\n",
      " |             dog     walks              4          0\n",
      " |             bat     flies              2          2\n",
      " |      bird   penguin walks              2          2\n",
      " |\n",
      " |      Get values at specified index\n",
      " |\n",
      " |      >>> df.xs('mammal')\n",
      " |                         num_legs  num_wings\n",
      " |      animal locomotion\n",
      " |      cat    walks              4          0\n",
      " |      dog    walks              4          0\n",
      " |      bat    flies              2          2\n",
      " |\n",
      " |      Get values at several indexes\n",
      " |\n",
      " |      >>> df.xs(('mammal', 'dog', 'walks'))\n",
      " |      num_legs     4\n",
      " |      num_wings    0\n",
      " |      Name: (mammal, dog, walks), dtype: int64\n",
      " |\n",
      " |      Get values at specified index and level\n",
      " |\n",
      " |      >>> df.xs('cat', level=1)\n",
      " |                         num_legs  num_wings\n",
      " |      class  locomotion\n",
      " |      mammal walks              4          0\n",
      " |\n",
      " |      Get values at several indexes and levels\n",
      " |\n",
      " |      >>> df.xs(('bird', 'walks'),\n",
      " |      ...       level=[0, 'locomotion'])\n",
      " |               num_legs  num_wings\n",
      " |      animal\n",
      " |      penguin         2          2\n",
      " |\n",
      " |      Get values at specified column and axis\n",
      " |\n",
      " |      >>> df.xs('num_wings', axis=1)\n",
      " |      class   animal   locomotion\n",
      " |      mammal  cat      walks         0\n",
      " |              dog      walks         0\n",
      " |              bat      flies         2\n",
      " |      bird    penguin  walks         2\n",
      " |      Name: num_wings, dtype: int64\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.generic.NDFrame:\n",
      " |\n",
      " |  dtypes\n",
      " |      Return the dtypes in the DataFrame.\n",
      " |\n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype. See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type of each column.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'float': [1.0],\n",
      " |      ...                    'int': [1],\n",
      " |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      " |      ...                    'string': ['foo']})\n",
      " |      >>> df.dtypes\n",
      " |      float              float64\n",
      " |      int                  int64\n",
      " |      datetime    datetime64[ns]\n",
      " |      string              object\n",
      " |      dtype: object\n",
      " |\n",
      " |  empty\n",
      " |      Indicator whether Series/DataFrame is empty.\n",
      " |\n",
      " |      True if Series/DataFrame is entirely empty (no items), meaning any of the\n",
      " |      axes are of length 0.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          If Series/DataFrame is empty, return True, if not return False.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dropna : Return series without null values.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      If Series/DataFrame contains only NaNs, it is still not considered empty. See\n",
      " |      the example below.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      An example of an actual empty DataFrame. Notice the index is empty:\n",
      " |\n",
      " |      >>> df_empty = pd.DataFrame({'A' : []})\n",
      " |      >>> df_empty\n",
      " |      Empty DataFrame\n",
      " |      Columns: [A]\n",
      " |      Index: []\n",
      " |      >>> df_empty.empty\n",
      " |      True\n",
      " |\n",
      " |      If we only have NaNs in our DataFrame, it is not considered empty! We\n",
      " |      will need to drop the NaNs to make the DataFrame empty:\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A' : [np.nan]})\n",
      " |      >>> df\n",
      " |          A\n",
      " |      0 NaN\n",
      " |      >>> df.empty\n",
      " |      False\n",
      " |      >>> df.dropna().empty\n",
      " |      True\n",
      " |\n",
      " |      >>> ser_empty = pd.Series({'A' : []})\n",
      " |      >>> ser_empty\n",
      " |      A    []\n",
      " |      dtype: object\n",
      " |      >>> ser_empty.empty\n",
      " |      False\n",
      " |      >>> ser_empty = pd.Series()\n",
      " |      >>> ser_empty.empty\n",
      " |      True\n",
      " |\n",
      " |  flags\n",
      " |      Get the properties associated with this pandas object.\n",
      " |\n",
      " |      The available flags are\n",
      " |\n",
      " |      * :attr:`Flags.allows_duplicate_labels`\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Flags : Flags that apply to pandas objects.\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags\n",
      " |      <Flags(allows_duplicate_labels=True)>\n",
      " |\n",
      " |      Flags can be get or set using ``.``\n",
      " |\n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df.flags.allows_duplicate_labels = False\n",
      " |\n",
      " |      Or by slicing with a key\n",
      " |\n",
      " |      >>> df.flags[\"allows_duplicate_labels\"]\n",
      " |      False\n",
      " |      >>> df.flags[\"allows_duplicate_labels\"] = True\n",
      " |\n",
      " |  ndim\n",
      " |      Return an int representing the number of axes / array dimensions.\n",
      " |\n",
      " |      Return 1 if Series. Otherwise return 2 if DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.ndim : Number of array dimensions.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.ndim\n",
      " |      1\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.ndim\n",
      " |      2\n",
      " |\n",
      " |  size\n",
      " |      Return an int representing the number of elements in this object.\n",
      " |\n",
      " |      Return the number of rows if Series. Otherwise return the number of\n",
      " |      rows times number of columns if DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.size : Number of elements in the array.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.size\n",
      " |      3\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.size\n",
      " |      4\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |\n",
      " |  attrs\n",
      " |      Dictionary of global attributes of this dataset.\n",
      " |\n",
      " |      .. warning::\n",
      " |\n",
      " |         attrs is experimental and may change without warning.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Many operations that create new datasets will copy ``attrs``. Copies\n",
      " |      are always deep so that changing ``attrs`` will only affect the\n",
      " |      present dataset. ``pandas.concat`` copies ``attrs`` only if all input\n",
      " |      datasets have the same ``attrs``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      >>> ser = pd.Series([1, 2, 3])\n",
      " |      >>> ser.attrs = {\"A\": [10, 20, 30]}\n",
      " |      >>> ser.attrs\n",
      " |      {'A': [10, 20, 30]}\n",
      " |\n",
      " |      For DataFrame:\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
      " |      >>> df.attrs = {\"A\": [10, 20, 30]}\n",
      " |      >>> df.attrs\n",
      " |      {'A': [10, 20, 30]}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      " |\n",
      " |  __array_priority__ = 1000\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |\n",
      " |  __sizeof__(self) -> 'int'\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |\n",
      " |  __dir__(self) -> 'list[str]'\n",
      " |      Provide method name lookup and completion.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.indexing.IndexingMixin:\n",
      " |\n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |\n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If getting a value and 'label' does not exist in a DataFrame or Series.\n",
      " |\n",
      " |      ValueError\n",
      " |          If row/column label pair is not a tuple or if any label\n",
      " |          from the pair is not a scalar for DataFrame.\n",
      " |          If label is list-like (*excluding* NamedTuple) for Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column pair by label.\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer\n",
      " |          position(s).\n",
      " |      Series.at : Access a single value by label.\n",
      " |      Series.iat : Access a single value by integer position.\n",
      " |      Series.loc : Access a group of rows by label(s).\n",
      " |      Series.iloc : Access a group of rows by integer position(s).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Fast scalar value getting and setting <indexing.basics.get_value>`\n",
      " |      for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |\n",
      " |      Get value at specified row/column pair\n",
      " |\n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |\n",
      " |      Set value at specified row/column pair\n",
      " |\n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |\n",
      " |      Get value within a Series\n",
      " |\n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |\n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |\n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |\n",
      " |      Get value at specified row/column pair\n",
      " |\n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |\n",
      " |      Set value at specified row/column pair\n",
      " |\n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |\n",
      " |      Get value within a series\n",
      " |\n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |\n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |\n",
      " |      .. deprecated:: 2.2.0\n",
      " |\n",
      " |         Returning a tuple from a callable is deprecated.\n",
      " |\n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |\n",
      " |      Allowed inputs are:\n",
      " |\n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above).\n",
      " |        This is useful in method chains, when you don't have a reference to the\n",
      " |        calling object, but would like to base your selection on\n",
      " |        some value.\n",
      " |      - A tuple of row and column indexes. The tuple elements consist of one of the\n",
      " |        above inputs, e.g. ``(0, 1)``.\n",
      " |\n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |\n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Fast integer location scalar accessor.\n",
      " |      DataFrame.loc : Purely label-location based indexer for selection by label.\n",
      " |      Series.iloc : Purely integer-location based indexing for\n",
      " |                     selection by position.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
      " |      ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
      " |      ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000}]\n",
      " |      >>> df = pd.DataFrame(mydict)\n",
      " |      >>> df\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |\n",
      " |      **Indexing just the rows**\n",
      " |\n",
      " |      With a scalar integer.\n",
      " |\n",
      " |      >>> type(df.iloc[0])\n",
      " |      <class 'pandas.core.series.Series'>\n",
      " |      >>> df.iloc[0]\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      d    4\n",
      " |      Name: 0, dtype: int64\n",
      " |\n",
      " |      With a list of integers.\n",
      " |\n",
      " |      >>> df.iloc[[0]]\n",
      " |         a  b  c  d\n",
      " |      0  1  2  3  4\n",
      " |      >>> type(df.iloc[[0]])\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |\n",
      " |      >>> df.iloc[[0, 1]]\n",
      " |           a    b    c    d\n",
      " |      0    1    2    3    4\n",
      " |      1  100  200  300  400\n",
      " |\n",
      " |      With a `slice` object.\n",
      " |\n",
      " |      >>> df.iloc[:3]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |\n",
      " |      With a boolean mask the same length as the index.\n",
      " |\n",
      " |      >>> df.iloc[[True, False, True]]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |\n",
      " |      With a callable, useful in method chains. The `x` passed\n",
      " |      to the ``lambda`` is the DataFrame being sliced. This selects\n",
      " |      the rows whose index label even.\n",
      " |\n",
      " |      >>> df.iloc[lambda x: x.index % 2 == 0]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |\n",
      " |      **Indexing both axes**\n",
      " |\n",
      " |      You can mix the indexer types for the index and columns. Use ``:`` to\n",
      " |      select the entire axis.\n",
      " |\n",
      " |      With scalar integers.\n",
      " |\n",
      " |      >>> df.iloc[0, 1]\n",
      " |      2\n",
      " |\n",
      " |      With lists of integers.\n",
      " |\n",
      " |      >>> df.iloc[[0, 2], [1, 3]]\n",
      " |            b     d\n",
      " |      0     2     4\n",
      " |      2  2000  4000\n",
      " |\n",
      " |      With `slice` objects.\n",
      " |\n",
      " |      >>> df.iloc[1:3, 0:3]\n",
      " |            a     b     c\n",
      " |      1   100   200   300\n",
      " |      2  1000  2000  3000\n",
      " |\n",
      " |      With a boolean array whose length matches the columns.\n",
      " |\n",
      " |      >>> df.iloc[:, [True, False, True, False]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |\n",
      " |      With a callable function that expects the Series or DataFrame.\n",
      " |\n",
      " |      >>> df.iloc[:, lambda df: [0, 2]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |\n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |\n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |\n",
      " |      Allowed inputs are:\n",
      " |\n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |\n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |\n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - An alignable boolean Series. The index of the key will be aligned before\n",
      " |        masking.\n",
      " |      - An alignable Index. The Index of the returned selection will be the input.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above)\n",
      " |\n",
      " |      See more at :ref:`Selection by Label <indexing.label>`.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any items are not found.\n",
      " |      IndexingError\n",
      " |          If an indexed key is passed and its index is unalignable to the frame index.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s).\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |                     Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...                   index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...                   columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |\n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |\n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |\n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      Single label for row and column\n",
      " |\n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |\n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |\n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |\n",
      " |      Boolean list with the same length as the row axis\n",
      " |\n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      Alignable boolean Series:\n",
      " |\n",
      " |      >>> df.loc[pd.Series([False, True, False],\n",
      " |      ...                  index=['viper', 'sidewinder', 'cobra'])]\n",
      " |                           max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      Index (same behavior as ``df.reindex``)\n",
      " |\n",
      " |      >>> df.loc[pd.Index([\"cobra\", \"viper\"], name=\"foo\")]\n",
      " |             max_speed  shield\n",
      " |      foo\n",
      " |      cobra          1       2\n",
      " |      viper          4       5\n",
      " |\n",
      " |      Conditional that returns a boolean Series\n",
      " |\n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |\n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |\n",
      " |      Multiple conditional using ``&`` that returns a boolean Series\n",
      " |\n",
      " |      >>> df.loc[(df['max_speed'] > 1) & (df['shield'] < 8)]\n",
      " |                  max_speed  shield\n",
      " |      viper          4       5\n",
      " |\n",
      " |      Multiple conditional using ``|`` that returns a boolean Series\n",
      " |\n",
      " |      >>> df.loc[(df['max_speed'] > 4) | (df['shield'] < 5)]\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      Please ensure that each condition is wrapped in parentheses ``()``.\n",
      " |      See the :ref:`user guide<indexing.boolean>`\n",
      " |      for more details and explanations of Boolean indexing.\n",
      " |\n",
      " |      .. note::\n",
      " |          If you find yourself using 3 or more conditionals in ``.loc[]``,\n",
      " |          consider using :ref:`advanced indexing<advanced.advanced_hierarchical>`.\n",
      " |\n",
      " |          See below for using ``.loc[]`` on MultiIndex DataFrames.\n",
      " |\n",
      " |      Callable that returns a boolean Series\n",
      " |\n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      **Setting values**\n",
      " |\n",
      " |      Set value for all items matching the list of labels\n",
      " |\n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |\n",
      " |      Set value for an entire row\n",
      " |\n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |\n",
      " |      Set value for an entire column\n",
      " |\n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |\n",
      " |      Set value for rows matching callable condition\n",
      " |\n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |\n",
      " |      Add value matching location\n",
      " |\n",
      " |      >>> df.loc[\"viper\", \"shield\"] += 5\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       5\n",
      " |      sidewinder          0       0\n",
      " |\n",
      " |      Setting using a ``Series`` or a ``DataFrame`` sets the values matching the\n",
      " |      index labels, not the index positions.\n",
      " |\n",
      " |      >>> shuffled_df = df.loc[[\"viper\", \"cobra\", \"sidewinder\"]]\n",
      " |      >>> df.loc[:] += shuffled_df\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              60      20\n",
      " |      viper               0      10\n",
      " |      sidewinder          0       0\n",
      " |\n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |\n",
      " |      Another example using integers for the index\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...                   index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |\n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |\n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |\n",
      " |      **Getting values with a MultiIndex**\n",
      " |\n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |\n",
      " |      >>> tuples = [\n",
      " |      ...     ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...     ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...     ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...           [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |\n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |\n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |\n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |\n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |\n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |\n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |\n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |\n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |\n",
      " |      Single tuple for the index with a single label for the column\n",
      " |\n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |\n",
      " |      Slice from index tuple to single label\n",
      " |\n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |\n",
      " |      Slice from index tuple to index tuple\n",
      " |\n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      " |\n",
      " |      Please see the :ref:`user guide<advanced.advanced_hierarchical>`\n",
      " |      for more details and explanations of advanced indexing.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.arraylike.OpsMixin:\n",
      " |\n",
      " |  __add__(self, other)\n",
      " |      Get Addition of DataFrame and other, column-wise.\n",
      " |\n",
      " |      Equivalent to ``DataFrame.add(other)``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Object to be added to the DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The result of adding ``other`` to DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add a DataFrame and another object, with option for index-\n",
      " |          or column-oriented addition.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'height': [1.5, 2.6], 'weight': [500, 800]},\n",
      " |      ...                   index=['elk', 'moose'])\n",
      " |      >>> df\n",
      " |             height  weight\n",
      " |      elk       1.5     500\n",
      " |      moose     2.6     800\n",
      " |\n",
      " |      Adding a scalar affects all rows and columns.\n",
      " |\n",
      " |      >>> df[['height', 'weight']] + 1.5\n",
      " |             height  weight\n",
      " |      elk       3.0   501.5\n",
      " |      moose     4.1   801.5\n",
      " |\n",
      " |      Each element of a list is added to a column of the DataFrame, in order.\n",
      " |\n",
      " |      >>> df[['height', 'weight']] + [0.5, 1.5]\n",
      " |             height  weight\n",
      " |      elk       2.0   501.5\n",
      " |      moose     3.1   801.5\n",
      " |\n",
      " |      Keys of a dictionary are aligned to the DataFrame, based on column names;\n",
      " |      each value in the dictionary is added to the corresponding column.\n",
      " |\n",
      " |      >>> df[['height', 'weight']] + {'height': 0.5, 'weight': 1.5}\n",
      " |             height  weight\n",
      " |      elk       2.0   501.5\n",
      " |      moose     3.1   801.5\n",
      " |\n",
      " |      When `other` is a :class:`Series`, the index of `other` is aligned with the\n",
      " |      columns of the DataFrame.\n",
      " |\n",
      " |      >>> s1 = pd.Series([0.5, 1.5], index=['weight', 'height'])\n",
      " |      >>> df[['height', 'weight']] + s1\n",
      " |             height  weight\n",
      " |      elk       3.0   500.5\n",
      " |      moose     4.1   800.5\n",
      " |\n",
      " |      Even when the index of `other` is the same as the index of the DataFrame,\n",
      " |      the :class:`Series` will not be reoriented. If index-wise alignment is desired,\n",
      " |      :meth:`DataFrame.add` should be used with `axis='index'`.\n",
      " |\n",
      " |      >>> s2 = pd.Series([0.5, 1.5], index=['elk', 'moose'])\n",
      " |      >>> df[['height', 'weight']] + s2\n",
      " |             elk  height  moose  weight\n",
      " |      elk    NaN     NaN    NaN     NaN\n",
      " |      moose  NaN     NaN    NaN     NaN\n",
      " |\n",
      " |      >>> df[['height', 'weight']].add(s2, axis='index')\n",
      " |             height  weight\n",
      " |      elk       2.0   500.5\n",
      " |      moose     4.1   801.5\n",
      " |\n",
      " |      When `other` is a :class:`DataFrame`, both columns names and the\n",
      " |      index are aligned.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'height': [0.2, 0.4, 0.6]},\n",
      " |      ...                      index=['elk', 'moose', 'deer'])\n",
      " |      >>> df[['height', 'weight']] + other\n",
      " |             height  weight\n",
      " |      deer      NaN     NaN\n",
      " |      elk       1.7     NaN\n",
      " |      moose     3.0     NaN\n",
      " |\n",
      " |  __and__(self, other)\n",
      " |\n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |\n",
      " |  __floordiv__(self, other)\n",
      " |\n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |\n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |\n",
      " |  __mod__(self, other)\n",
      " |\n",
      " |  __mul__(self, other)\n",
      " |\n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |\n",
      " |  __or__(self, other)\n",
      " |      Return self|value.\n",
      " |\n",
      " |  __pow__(self, other)\n",
      " |\n",
      " |  __radd__(self, other)\n",
      " |\n",
      " |  __rand__(self, other)\n",
      " |\n",
      " |  __rfloordiv__(self, other)\n",
      " |\n",
      " |  __rmod__(self, other)\n",
      " |\n",
      " |  __rmul__(self, other)\n",
      " |\n",
      " |  __ror__(self, other)\n",
      " |      Return value|self.\n",
      " |\n",
      " |  __rpow__(self, other)\n",
      " |\n",
      " |  __rsub__(self, other)\n",
      " |\n",
      " |  __rtruediv__(self, other)\n",
      " |\n",
      " |  __rxor__(self, other)\n",
      " |\n",
      " |  __sub__(self, other)\n",
      " |\n",
      " |  __truediv__(self, other)\n",
      " |\n",
      " |  __xor__(self, other)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.arraylike.OpsMixin:\n",
      " |\n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4e8f826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "      <td>john.smith@company.com</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>95000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>sarah.johnson@company.com</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mike</td>\n",
       "      <td>Brown</td>\n",
       "      <td>mike.brown@company.com</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>72000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Lee</td>\n",
       "      <td>jessica.lee@company.com</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>71000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>David</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>david.wilson@company.com</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>78000</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Davis</td>\n",
       "      <td>emily.davis@company.com</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>68000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>lisa.anderson@company.com</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>85000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>tom.taylor@company.com</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>65000</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Anna</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>anna.martinez@company.com</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>chris.garcia@company.com</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>89000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                      email   hire_date  \\\n",
       "0            1       John     Smith     john.smith@company.com  2020-01-15   \n",
       "1            2      Sarah   Johnson  sarah.johnson@company.com  2019-03-22   \n",
       "2            3       Mike     Brown     mike.brown@company.com  2021-06-10   \n",
       "9           10    Jessica       Lee    jessica.lee@company.com  2021-12-03   \n",
       "4            5      David    Wilson   david.wilson@company.com  2018-11-30   \n",
       "3            4      Emily     Davis    emily.davis@company.com  2020-09-05   \n",
       "5            6       Lisa  Anderson  lisa.anderson@company.com  2022-02-14   \n",
       "6            7        Tom    Taylor     tom.taylor@company.com  2021-08-20   \n",
       "7            8       Anna  Martinez  anna.martinez@company.com  2020-04-12   \n",
       "8            9      Chris    Garcia   chris.garcia@company.com  2019-07-08   \n",
       "\n",
       "   salary  department_id  manager_id  \n",
       "0   95000              1         NaN  \n",
       "1   87000              1         1.0  \n",
       "2   72000              1         1.0  \n",
       "9   71000              1         1.0  \n",
       "4   78000              2         4.0  \n",
       "3   68000              2         NaN  \n",
       "5   85000              3         NaN  \n",
       "6   65000              3         6.0  \n",
       "7   62000              4         NaN  \n",
       "8   89000              5         NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['department_id','salary'],ascending=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "786d2930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(387000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['department_id'].isin([1,4])]['salary'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ec687db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "      <td>john.smith@company.com</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>95000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>sarah.johnson@company.com</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mike</td>\n",
       "      <td>Brown</td>\n",
       "      <td>mike.brown@company.com</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>72000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Anna</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>anna.martinez@company.com</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Lee</td>\n",
       "      <td>jessica.lee@company.com</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>71000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                      email   hire_date  \\\n",
       "0            1       John     Smith     john.smith@company.com  2020-01-15   \n",
       "1            2      Sarah   Johnson  sarah.johnson@company.com  2019-03-22   \n",
       "2            3       Mike     Brown     mike.brown@company.com  2021-06-10   \n",
       "7            8       Anna  Martinez  anna.martinez@company.com  2020-04-12   \n",
       "9           10    Jessica       Lee    jessica.lee@company.com  2021-12-03   \n",
       "\n",
       "   salary  department_id  manager_id  \n",
       "0   95000              1         NaN  \n",
       "1   87000              1         1.0  \n",
       "2   72000              1         1.0  \n",
       "7   62000              4         NaN  \n",
       "9   71000              1         1.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['department_id'].isin([1,4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c6312bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "      <td>john.smith@company.com</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>95000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>sarah.johnson@company.com</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                      email   hire_date  \\\n",
       "0            1       John     Smith     john.smith@company.com  2020-01-15   \n",
       "1            2      Sarah   Johnson  sarah.johnson@company.com  2019-03-22   \n",
       "\n",
       "   salary  department_id  manager_id  \n",
       "0   95000              1         NaN  \n",
       "1   87000              1         1.0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "473ff1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [2, 3, 4], [4, 5, 6]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3]\n",
    "l[0]\n",
    "l[1:]\n",
    "l[:-2]\n",
    "\n",
    "l = [[1,2,3],[2,3,4],[4,5,6]]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18b0e494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['employee_id', 'first_name', 'last_name', 'email', 'hire_date',\n",
       "       'salary', 'department_id', 'manager_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a79ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Smith\n",
       "1     Johnson\n",
       "2       Brown\n",
       "3       Davis\n",
       "4      Wilson\n",
       "5    Anderson\n",
       "6      Taylor\n",
       "7    Martinez\n",
       "8      Garcia\n",
       "9         Lee\n",
       "Name: last_name, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,2]  # [row,col,skip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "94935a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>sarah.johnson@company.com</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mike</td>\n",
       "      <td>Brown</td>\n",
       "      <td>mike.brown@company.com</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>72000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Davis</td>\n",
       "      <td>emily.davis@company.com</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>68000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>David</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>david.wilson@company.com</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>78000</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>lisa.anderson@company.com</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>85000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>tom.taylor@company.com</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>65000</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Anna</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>anna.martinez@company.com</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>chris.garcia@company.com</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>89000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Lee</td>\n",
       "      <td>jessica.lee@company.com</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>71000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                      email   hire_date  \\\n",
       "1            2      Sarah   Johnson  sarah.johnson@company.com  2019-03-22   \n",
       "2            3       Mike     Brown     mike.brown@company.com  2021-06-10   \n",
       "3            4      Emily     Davis    emily.davis@company.com  2020-09-05   \n",
       "4            5      David    Wilson   david.wilson@company.com  2018-11-30   \n",
       "5            6       Lisa  Anderson  lisa.anderson@company.com  2022-02-14   \n",
       "6            7        Tom    Taylor     tom.taylor@company.com  2021-08-20   \n",
       "7            8       Anna  Martinez  anna.martinez@company.com  2020-04-12   \n",
       "8            9      Chris    Garcia   chris.garcia@company.com  2019-07-08   \n",
       "9           10    Jessica       Lee    jessica.lee@company.com  2021-12-03   \n",
       "\n",
       "   salary  department_id  manager_id  \n",
       "1   87000              1         1.0  \n",
       "2   72000              1         1.0  \n",
       "3   68000              2         NaN  \n",
       "4   78000              2         4.0  \n",
       "5   85000              3         NaN  \n",
       "6   65000              3         6.0  \n",
       "7   62000              4         NaN  \n",
       "8   89000              5         NaN  \n",
       "9   71000              1         1.0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ccb1838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mike</td>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emily</td>\n",
       "      <td>Davis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David</td>\n",
       "      <td>Wilson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>Anderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tom</td>\n",
       "      <td>Taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Anna</td>\n",
       "      <td>Martinez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chris</td>\n",
       "      <td>Garcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jessica</td>\n",
       "      <td>Lee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name last_name\n",
       "1      Sarah   Johnson\n",
       "2       Mike     Brown\n",
       "3      Emily     Davis\n",
       "4      David    Wilson\n",
       "5       Lisa  Anderson\n",
       "6        Tom    Taylor\n",
       "7       Anna  Martinez\n",
       "8      Chris    Garcia\n",
       "9    Jessica       Lee"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1:,[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c45c7d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john.smith@company.com</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sarah.johnson@company.com</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>87000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mike.brown@company.com</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emily.davis@company.com</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>68000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>david.wilson@company.com</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>78000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lisa.anderson@company.com</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tom.taylor@company.com</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>65000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>anna.martinez@company.com</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>62000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chris.garcia@company.com</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>89000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jessica.lee@company.com</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>71000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       email   hire_date  salary\n",
       "0     john.smith@company.com  2020-01-15   95000\n",
       "1  sarah.johnson@company.com  2019-03-22   87000\n",
       "2     mike.brown@company.com  2021-06-10   72000\n",
       "3    emily.davis@company.com  2020-09-05   68000\n",
       "4   david.wilson@company.com  2018-11-30   78000\n",
       "5  lisa.anderson@company.com  2022-02-14   85000\n",
       "6     tom.taylor@company.com  2021-08-20   65000\n",
       "7  anna.martinez@company.com  2020-04-12   62000\n",
       "8   chris.garcia@company.com  2019-07-08   89000\n",
       "9    jessica.lee@company.com  2021-12-03   71000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,3:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "88e520fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  1.,  4.,  6.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['manager_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4ba86453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   department_id  manager_id\n",
       "0              1         NaN\n",
       "1              1         1.0\n",
       "2              1         1.0\n",
       "3              2         NaN\n",
       "4              2         4.0\n",
       "5              3         NaN\n",
       "6              3         6.0\n",
       "7              4         NaN\n",
       "8              5         NaN\n",
       "9              1         1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['department_id','manager_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "853862fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['department_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "108a854b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABC BCD'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ABC\"+ ' '+ \"BCD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "23362bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_name'] = df['first_name']+' '+df['last_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dc02143b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "      <td>john.smith@company.com</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>95000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>sarah.johnson@company.com</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sarah Johnson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                      email   hire_date  \\\n",
       "0            1       John     Smith     john.smith@company.com  2020-01-15   \n",
       "1            2      Sarah   Johnson  sarah.johnson@company.com  2019-03-22   \n",
       "\n",
       "   salary  department_id  manager_id      full_name  \n",
       "0   95000              1         NaN     John Smith  \n",
       "1   87000              1         1.0  Sarah Johnson  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5bbac4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    5\n",
       "2    4\n",
       "3    5\n",
       "4    5\n",
       "5    4\n",
       "6    3\n",
       "7    4\n",
       "8    5\n",
       "9    7\n",
       "Name: first_name, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['first_name'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8c70873b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       JOHN\n",
       "1      SARAH\n",
       "2       MIKE\n",
       "3      EMILY\n",
       "4      DAVID\n",
       "5       LISA\n",
       "6        TOM\n",
       "7       ANNA\n",
       "8      CHRIS\n",
       "9    JESSICA\n",
       "Name: first_name, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['first_name'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a74150de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       smith\n",
       "1     johnson\n",
       "2       brown\n",
       "3       davis\n",
       "4      wilson\n",
       "5    anderson\n",
       "6      taylor\n",
       "7    martinez\n",
       "8      garcia\n",
       "9         lee\n",
       "Name: last_name, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['last_name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c9efe2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Smith\n",
       "1     Johnson\n",
       "2       Brown\n",
       "3       Davis\n",
       "4      Wilson\n",
       "5    Anderson\n",
       "6      Taylor\n",
       "7    Martinez\n",
       "8      Garcia\n",
       "9         Lee\n",
       "Name: last_name, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['last_name'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d82a38dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Aohn\n",
       "1      Sarah\n",
       "2       Mike\n",
       "3      Emily\n",
       "4      David\n",
       "5       Lisa\n",
       "6        Tom\n",
       "7       Anna\n",
       "8      Chris\n",
       "9    Aessica\n",
       "Name: first_name, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['first_name'].str.replace(\"J\",\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa0f153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_data(x):\n",
    "    return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7f6e1ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       john.smith\n",
       "1    sarah.johnson\n",
       "2       mike.brown\n",
       "3      emily.davis\n",
       "4     david.wilson\n",
       "5    lisa.anderson\n",
       "6       tom.taylor\n",
       "7    anna.martinez\n",
       "8     chris.garcia\n",
       "9      jessica.lee\n",
       "Name: email, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['email'].str.split(\"@\").apply(lambda x : x[0])\n",
    "df['email'].str.split(\"@\").apply(return_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "223bd2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dhanush'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = \"dhanush prasad\"\n",
    "d.split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "db406aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99750.0\n",
       "1    91350.0\n",
       "2    75600.0\n",
       "3    71400.0\n",
       "4    81900.0\n",
       "5    89250.0\n",
       "6    68250.0\n",
       "7    65100.0\n",
       "8    93450.0\n",
       "9    74550.0\n",
       "Name: salary, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df['salary']*1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d6c78984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ec3247cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_category(x):\n",
    "    if x>=90000:\n",
    "        return \"High\"\n",
    "    if x >= 70000:\n",
    "        return \"Medium\"\n",
    "    else: return \"Low\"\n",
    "\n",
    "df['salary_category']= df['salary'].apply(salary_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3a0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<Axes: ylabel='count'>], dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['salary_category'].value_counts().plot(kind='pie',subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f364c4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Africa/Abidjan',\n",
       " 'Africa/Accra',\n",
       " 'Africa/Addis_Ababa',\n",
       " 'Africa/Algiers',\n",
       " 'Africa/Asmara',\n",
       " 'Africa/Asmera',\n",
       " 'Africa/Bamako',\n",
       " 'Africa/Bangui',\n",
       " 'Africa/Banjul',\n",
       " 'Africa/Bissau',\n",
       " 'Africa/Blantyre',\n",
       " 'Africa/Brazzaville',\n",
       " 'Africa/Bujumbura',\n",
       " 'Africa/Cairo',\n",
       " 'Africa/Casablanca',\n",
       " 'Africa/Ceuta',\n",
       " 'Africa/Conakry',\n",
       " 'Africa/Dakar',\n",
       " 'Africa/Dar_es_Salaam',\n",
       " 'Africa/Djibouti',\n",
       " 'Africa/Douala',\n",
       " 'Africa/El_Aaiun',\n",
       " 'Africa/Freetown',\n",
       " 'Africa/Gaborone',\n",
       " 'Africa/Harare',\n",
       " 'Africa/Johannesburg',\n",
       " 'Africa/Juba',\n",
       " 'Africa/Kampala',\n",
       " 'Africa/Khartoum',\n",
       " 'Africa/Kigali',\n",
       " 'Africa/Kinshasa',\n",
       " 'Africa/Lagos',\n",
       " 'Africa/Libreville',\n",
       " 'Africa/Lome',\n",
       " 'Africa/Luanda',\n",
       " 'Africa/Lubumbashi',\n",
       " 'Africa/Lusaka',\n",
       " 'Africa/Malabo',\n",
       " 'Africa/Maputo',\n",
       " 'Africa/Maseru',\n",
       " 'Africa/Mbabane',\n",
       " 'Africa/Mogadishu',\n",
       " 'Africa/Monrovia',\n",
       " 'Africa/Nairobi',\n",
       " 'Africa/Ndjamena',\n",
       " 'Africa/Niamey',\n",
       " 'Africa/Nouakchott',\n",
       " 'Africa/Ouagadougou',\n",
       " 'Africa/Porto-Novo',\n",
       " 'Africa/Sao_Tome',\n",
       " 'Africa/Timbuktu',\n",
       " 'Africa/Tripoli',\n",
       " 'Africa/Tunis',\n",
       " 'Africa/Windhoek',\n",
       " 'America/Adak',\n",
       " 'America/Anchorage',\n",
       " 'America/Anguilla',\n",
       " 'America/Antigua',\n",
       " 'America/Araguaina',\n",
       " 'America/Argentina/Buenos_Aires',\n",
       " 'America/Argentina/Catamarca',\n",
       " 'America/Argentina/ComodRivadavia',\n",
       " 'America/Argentina/Cordoba',\n",
       " 'America/Argentina/Jujuy',\n",
       " 'America/Argentina/La_Rioja',\n",
       " 'America/Argentina/Mendoza',\n",
       " 'America/Argentina/Rio_Gallegos',\n",
       " 'America/Argentina/Salta',\n",
       " 'America/Argentina/San_Juan',\n",
       " 'America/Argentina/San_Luis',\n",
       " 'America/Argentina/Tucuman',\n",
       " 'America/Argentina/Ushuaia',\n",
       " 'America/Aruba',\n",
       " 'America/Asuncion',\n",
       " 'America/Atikokan',\n",
       " 'America/Atka',\n",
       " 'America/Bahia',\n",
       " 'America/Bahia_Banderas',\n",
       " 'America/Barbados',\n",
       " 'America/Belem',\n",
       " 'America/Belize',\n",
       " 'America/Blanc-Sablon',\n",
       " 'America/Boa_Vista',\n",
       " 'America/Bogota',\n",
       " 'America/Boise',\n",
       " 'America/Buenos_Aires',\n",
       " 'America/Cambridge_Bay',\n",
       " 'America/Campo_Grande',\n",
       " 'America/Cancun',\n",
       " 'America/Caracas',\n",
       " 'America/Catamarca',\n",
       " 'America/Cayenne',\n",
       " 'America/Cayman',\n",
       " 'America/Chicago',\n",
       " 'America/Chihuahua',\n",
       " 'America/Ciudad_Juarez',\n",
       " 'America/Coral_Harbour',\n",
       " 'America/Cordoba',\n",
       " 'America/Costa_Rica',\n",
       " 'America/Coyhaique',\n",
       " 'America/Creston',\n",
       " 'America/Cuiaba',\n",
       " 'America/Curacao',\n",
       " 'America/Danmarkshavn',\n",
       " 'America/Dawson',\n",
       " 'America/Dawson_Creek',\n",
       " 'America/Denver',\n",
       " 'America/Detroit',\n",
       " 'America/Dominica',\n",
       " 'America/Edmonton',\n",
       " 'America/Eirunepe',\n",
       " 'America/El_Salvador',\n",
       " 'America/Ensenada',\n",
       " 'America/Fort_Nelson',\n",
       " 'America/Fort_Wayne',\n",
       " 'America/Fortaleza',\n",
       " 'America/Glace_Bay',\n",
       " 'America/Godthab',\n",
       " 'America/Goose_Bay',\n",
       " 'America/Grand_Turk',\n",
       " 'America/Grenada',\n",
       " 'America/Guadeloupe',\n",
       " 'America/Guatemala',\n",
       " 'America/Guayaquil',\n",
       " 'America/Guyana',\n",
       " 'America/Halifax',\n",
       " 'America/Havana',\n",
       " 'America/Hermosillo',\n",
       " 'America/Indiana/Indianapolis',\n",
       " 'America/Indiana/Knox',\n",
       " 'America/Indiana/Marengo',\n",
       " 'America/Indiana/Petersburg',\n",
       " 'America/Indiana/Tell_City',\n",
       " 'America/Indiana/Vevay',\n",
       " 'America/Indiana/Vincennes',\n",
       " 'America/Indiana/Winamac',\n",
       " 'America/Indianapolis',\n",
       " 'America/Inuvik',\n",
       " 'America/Iqaluit',\n",
       " 'America/Jamaica',\n",
       " 'America/Jujuy',\n",
       " 'America/Juneau',\n",
       " 'America/Kentucky/Louisville',\n",
       " 'America/Kentucky/Monticello',\n",
       " 'America/Knox_IN',\n",
       " 'America/Kralendijk',\n",
       " 'America/La_Paz',\n",
       " 'America/Lima',\n",
       " 'America/Los_Angeles',\n",
       " 'America/Louisville',\n",
       " 'America/Lower_Princes',\n",
       " 'America/Maceio',\n",
       " 'America/Managua',\n",
       " 'America/Manaus',\n",
       " 'America/Marigot',\n",
       " 'America/Martinique',\n",
       " 'America/Matamoros',\n",
       " 'America/Mazatlan',\n",
       " 'America/Mendoza',\n",
       " 'America/Menominee',\n",
       " 'America/Merida',\n",
       " 'America/Metlakatla',\n",
       " 'America/Mexico_City',\n",
       " 'America/Miquelon',\n",
       " 'America/Moncton',\n",
       " 'America/Monterrey',\n",
       " 'America/Montevideo',\n",
       " 'America/Montreal',\n",
       " 'America/Montserrat',\n",
       " 'America/Nassau',\n",
       " 'America/New_York',\n",
       " 'America/Nipigon',\n",
       " 'America/Nome',\n",
       " 'America/Noronha',\n",
       " 'America/North_Dakota/Beulah',\n",
       " 'America/North_Dakota/Center',\n",
       " 'America/North_Dakota/New_Salem',\n",
       " 'America/Nuuk',\n",
       " 'America/Ojinaga',\n",
       " 'America/Panama',\n",
       " 'America/Pangnirtung',\n",
       " 'America/Paramaribo',\n",
       " 'America/Phoenix',\n",
       " 'America/Port-au-Prince',\n",
       " 'America/Port_of_Spain',\n",
       " 'America/Porto_Acre',\n",
       " 'America/Porto_Velho',\n",
       " 'America/Puerto_Rico',\n",
       " 'America/Punta_Arenas',\n",
       " 'America/Rainy_River',\n",
       " 'America/Rankin_Inlet',\n",
       " 'America/Recife',\n",
       " 'America/Regina',\n",
       " 'America/Resolute',\n",
       " 'America/Rio_Branco',\n",
       " 'America/Rosario',\n",
       " 'America/Santa_Isabel',\n",
       " 'America/Santarem',\n",
       " 'America/Santiago',\n",
       " 'America/Santo_Domingo',\n",
       " 'America/Sao_Paulo',\n",
       " 'America/Scoresbysund',\n",
       " 'America/Shiprock',\n",
       " 'America/Sitka',\n",
       " 'America/St_Barthelemy',\n",
       " 'America/St_Johns',\n",
       " 'America/St_Kitts',\n",
       " 'America/St_Lucia',\n",
       " 'America/St_Thomas',\n",
       " 'America/St_Vincent',\n",
       " 'America/Swift_Current',\n",
       " 'America/Tegucigalpa',\n",
       " 'America/Thule',\n",
       " 'America/Thunder_Bay',\n",
       " 'America/Tijuana',\n",
       " 'America/Toronto',\n",
       " 'America/Tortola',\n",
       " 'America/Vancouver',\n",
       " 'America/Virgin',\n",
       " 'America/Whitehorse',\n",
       " 'America/Winnipeg',\n",
       " 'America/Yakutat',\n",
       " 'America/Yellowknife',\n",
       " 'Antarctica/Casey',\n",
       " 'Antarctica/Davis',\n",
       " 'Antarctica/DumontDUrville',\n",
       " 'Antarctica/Macquarie',\n",
       " 'Antarctica/Mawson',\n",
       " 'Antarctica/McMurdo',\n",
       " 'Antarctica/Palmer',\n",
       " 'Antarctica/Rothera',\n",
       " 'Antarctica/South_Pole',\n",
       " 'Antarctica/Syowa',\n",
       " 'Antarctica/Troll',\n",
       " 'Antarctica/Vostok',\n",
       " 'Arctic/Longyearbyen',\n",
       " 'Asia/Aden',\n",
       " 'Asia/Almaty',\n",
       " 'Asia/Amman',\n",
       " 'Asia/Anadyr',\n",
       " 'Asia/Aqtau',\n",
       " 'Asia/Aqtobe',\n",
       " 'Asia/Ashgabat',\n",
       " 'Asia/Ashkhabad',\n",
       " 'Asia/Atyrau',\n",
       " 'Asia/Baghdad',\n",
       " 'Asia/Bahrain',\n",
       " 'Asia/Baku',\n",
       " 'Asia/Bangkok',\n",
       " 'Asia/Barnaul',\n",
       " 'Asia/Beirut',\n",
       " 'Asia/Bishkek',\n",
       " 'Asia/Brunei',\n",
       " 'Asia/Calcutta',\n",
       " 'Asia/Chita',\n",
       " 'Asia/Choibalsan',\n",
       " 'Asia/Chongqing',\n",
       " 'Asia/Chungking',\n",
       " 'Asia/Colombo',\n",
       " 'Asia/Dacca',\n",
       " 'Asia/Damascus',\n",
       " 'Asia/Dhaka',\n",
       " 'Asia/Dili',\n",
       " 'Asia/Dubai',\n",
       " 'Asia/Dushanbe',\n",
       " 'Asia/Famagusta',\n",
       " 'Asia/Gaza',\n",
       " 'Asia/Harbin',\n",
       " 'Asia/Hebron',\n",
       " 'Asia/Ho_Chi_Minh',\n",
       " 'Asia/Hong_Kong',\n",
       " 'Asia/Hovd',\n",
       " 'Asia/Irkutsk',\n",
       " 'Asia/Istanbul',\n",
       " 'Asia/Jakarta',\n",
       " 'Asia/Jayapura',\n",
       " 'Asia/Jerusalem',\n",
       " 'Asia/Kabul',\n",
       " 'Asia/Kamchatka',\n",
       " 'Asia/Karachi',\n",
       " 'Asia/Kashgar',\n",
       " 'Asia/Kathmandu',\n",
       " 'Asia/Katmandu',\n",
       " 'Asia/Khandyga',\n",
       " 'Asia/Kolkata',\n",
       " 'Asia/Krasnoyarsk',\n",
       " 'Asia/Kuala_Lumpur',\n",
       " 'Asia/Kuching',\n",
       " 'Asia/Kuwait',\n",
       " 'Asia/Macao',\n",
       " 'Asia/Macau',\n",
       " 'Asia/Magadan',\n",
       " 'Asia/Makassar',\n",
       " 'Asia/Manila',\n",
       " 'Asia/Muscat',\n",
       " 'Asia/Nicosia',\n",
       " 'Asia/Novokuznetsk',\n",
       " 'Asia/Novosibirsk',\n",
       " 'Asia/Omsk',\n",
       " 'Asia/Oral',\n",
       " 'Asia/Phnom_Penh',\n",
       " 'Asia/Pontianak',\n",
       " 'Asia/Pyongyang',\n",
       " 'Asia/Qatar',\n",
       " 'Asia/Qostanay',\n",
       " 'Asia/Qyzylorda',\n",
       " 'Asia/Rangoon',\n",
       " 'Asia/Riyadh',\n",
       " 'Asia/Saigon',\n",
       " 'Asia/Sakhalin',\n",
       " 'Asia/Samarkand',\n",
       " 'Asia/Seoul',\n",
       " 'Asia/Shanghai',\n",
       " 'Asia/Singapore',\n",
       " 'Asia/Srednekolymsk',\n",
       " 'Asia/Taipei',\n",
       " 'Asia/Tashkent',\n",
       " 'Asia/Tbilisi',\n",
       " 'Asia/Tehran',\n",
       " 'Asia/Tel_Aviv',\n",
       " 'Asia/Thimbu',\n",
       " 'Asia/Thimphu',\n",
       " 'Asia/Tokyo',\n",
       " 'Asia/Tomsk',\n",
       " 'Asia/Ujung_Pandang',\n",
       " 'Asia/Ulaanbaatar',\n",
       " 'Asia/Ulan_Bator',\n",
       " 'Asia/Urumqi',\n",
       " 'Asia/Ust-Nera',\n",
       " 'Asia/Vientiane',\n",
       " 'Asia/Vladivostok',\n",
       " 'Asia/Yakutsk',\n",
       " 'Asia/Yangon',\n",
       " 'Asia/Yekaterinburg',\n",
       " 'Asia/Yerevan',\n",
       " 'Atlantic/Azores',\n",
       " 'Atlantic/Bermuda',\n",
       " 'Atlantic/Canary',\n",
       " 'Atlantic/Cape_Verde',\n",
       " 'Atlantic/Faeroe',\n",
       " 'Atlantic/Faroe',\n",
       " 'Atlantic/Jan_Mayen',\n",
       " 'Atlantic/Madeira',\n",
       " 'Atlantic/Reykjavik',\n",
       " 'Atlantic/South_Georgia',\n",
       " 'Atlantic/St_Helena',\n",
       " 'Atlantic/Stanley',\n",
       " 'Australia/ACT',\n",
       " 'Australia/Adelaide',\n",
       " 'Australia/Brisbane',\n",
       " 'Australia/Broken_Hill',\n",
       " 'Australia/Canberra',\n",
       " 'Australia/Currie',\n",
       " 'Australia/Darwin',\n",
       " 'Australia/Eucla',\n",
       " 'Australia/Hobart',\n",
       " 'Australia/LHI',\n",
       " 'Australia/Lindeman',\n",
       " 'Australia/Lord_Howe',\n",
       " 'Australia/Melbourne',\n",
       " 'Australia/NSW',\n",
       " 'Australia/North',\n",
       " 'Australia/Perth',\n",
       " 'Australia/Queensland',\n",
       " 'Australia/South',\n",
       " 'Australia/Sydney',\n",
       " 'Australia/Tasmania',\n",
       " 'Australia/Victoria',\n",
       " 'Australia/West',\n",
       " 'Australia/Yancowinna',\n",
       " 'Brazil/Acre',\n",
       " 'Brazil/DeNoronha',\n",
       " 'Brazil/East',\n",
       " 'Brazil/West',\n",
       " 'CET',\n",
       " 'CST6CDT',\n",
       " 'Canada/Atlantic',\n",
       " 'Canada/Central',\n",
       " 'Canada/Eastern',\n",
       " 'Canada/Mountain',\n",
       " 'Canada/Newfoundland',\n",
       " 'Canada/Pacific',\n",
       " 'Canada/Saskatchewan',\n",
       " 'Canada/Yukon',\n",
       " 'Chile/Continental',\n",
       " 'Chile/EasterIsland',\n",
       " 'Cuba',\n",
       " 'EET',\n",
       " 'EST',\n",
       " 'EST5EDT',\n",
       " 'Egypt',\n",
       " 'Eire',\n",
       " 'Etc/GMT',\n",
       " 'Etc/GMT+0',\n",
       " 'Etc/GMT+1',\n",
       " 'Etc/GMT+10',\n",
       " 'Etc/GMT+11',\n",
       " 'Etc/GMT+12',\n",
       " 'Etc/GMT+2',\n",
       " 'Etc/GMT+3',\n",
       " 'Etc/GMT+4',\n",
       " 'Etc/GMT+5',\n",
       " 'Etc/GMT+6',\n",
       " 'Etc/GMT+7',\n",
       " 'Etc/GMT+8',\n",
       " 'Etc/GMT+9',\n",
       " 'Etc/GMT-0',\n",
       " 'Etc/GMT-1',\n",
       " 'Etc/GMT-10',\n",
       " 'Etc/GMT-11',\n",
       " 'Etc/GMT-12',\n",
       " 'Etc/GMT-13',\n",
       " 'Etc/GMT-14',\n",
       " 'Etc/GMT-2',\n",
       " 'Etc/GMT-3',\n",
       " 'Etc/GMT-4',\n",
       " 'Etc/GMT-5',\n",
       " 'Etc/GMT-6',\n",
       " 'Etc/GMT-7',\n",
       " 'Etc/GMT-8',\n",
       " 'Etc/GMT-9',\n",
       " 'Etc/GMT0',\n",
       " 'Etc/Greenwich',\n",
       " 'Etc/UCT',\n",
       " 'Etc/UTC',\n",
       " 'Etc/Universal',\n",
       " 'Etc/Zulu',\n",
       " 'Europe/Amsterdam',\n",
       " 'Europe/Andorra',\n",
       " 'Europe/Astrakhan',\n",
       " 'Europe/Athens',\n",
       " 'Europe/Belfast',\n",
       " 'Europe/Belgrade',\n",
       " 'Europe/Berlin',\n",
       " 'Europe/Bratislava',\n",
       " 'Europe/Brussels',\n",
       " 'Europe/Bucharest',\n",
       " 'Europe/Budapest',\n",
       " 'Europe/Busingen',\n",
       " 'Europe/Chisinau',\n",
       " 'Europe/Copenhagen',\n",
       " 'Europe/Dublin',\n",
       " 'Europe/Gibraltar',\n",
       " 'Europe/Guernsey',\n",
       " 'Europe/Helsinki',\n",
       " 'Europe/Isle_of_Man',\n",
       " 'Europe/Istanbul',\n",
       " 'Europe/Jersey',\n",
       " 'Europe/Kaliningrad',\n",
       " 'Europe/Kiev',\n",
       " 'Europe/Kirov',\n",
       " 'Europe/Kyiv',\n",
       " 'Europe/Lisbon',\n",
       " 'Europe/Ljubljana',\n",
       " 'Europe/London',\n",
       " 'Europe/Luxembourg',\n",
       " 'Europe/Madrid',\n",
       " 'Europe/Malta',\n",
       " 'Europe/Mariehamn',\n",
       " 'Europe/Minsk',\n",
       " 'Europe/Monaco',\n",
       " 'Europe/Moscow',\n",
       " 'Europe/Nicosia',\n",
       " 'Europe/Oslo',\n",
       " 'Europe/Paris',\n",
       " 'Europe/Podgorica',\n",
       " 'Europe/Prague',\n",
       " 'Europe/Riga',\n",
       " 'Europe/Rome',\n",
       " 'Europe/Samara',\n",
       " 'Europe/San_Marino',\n",
       " 'Europe/Sarajevo',\n",
       " 'Europe/Saratov',\n",
       " 'Europe/Simferopol',\n",
       " 'Europe/Skopje',\n",
       " 'Europe/Sofia',\n",
       " 'Europe/Stockholm',\n",
       " 'Europe/Tallinn',\n",
       " 'Europe/Tirane',\n",
       " 'Europe/Tiraspol',\n",
       " 'Europe/Ulyanovsk',\n",
       " 'Europe/Uzhgorod',\n",
       " 'Europe/Vaduz',\n",
       " 'Europe/Vatican',\n",
       " 'Europe/Vienna',\n",
       " 'Europe/Vilnius',\n",
       " 'Europe/Volgograd',\n",
       " 'Europe/Warsaw',\n",
       " 'Europe/Zagreb',\n",
       " 'Europe/Zaporozhye',\n",
       " 'Europe/Zurich',\n",
       " 'GB',\n",
       " 'GB-Eire',\n",
       " 'GMT',\n",
       " 'GMT+0',\n",
       " 'GMT-0',\n",
       " 'GMT0',\n",
       " 'Greenwich',\n",
       " 'HST',\n",
       " 'Hongkong',\n",
       " 'Iceland',\n",
       " 'Indian/Antananarivo',\n",
       " 'Indian/Chagos',\n",
       " 'Indian/Christmas',\n",
       " 'Indian/Cocos',\n",
       " 'Indian/Comoro',\n",
       " 'Indian/Kerguelen',\n",
       " 'Indian/Mahe',\n",
       " 'Indian/Maldives',\n",
       " 'Indian/Mauritius',\n",
       " 'Indian/Mayotte',\n",
       " 'Indian/Reunion',\n",
       " 'Iran',\n",
       " 'Israel',\n",
       " 'Jamaica',\n",
       " 'Japan',\n",
       " 'Kwajalein',\n",
       " 'Libya',\n",
       " 'MET',\n",
       " 'MST',\n",
       " 'MST7MDT',\n",
       " 'Mexico/BajaNorte',\n",
       " 'Mexico/BajaSur',\n",
       " 'Mexico/General',\n",
       " 'NZ',\n",
       " 'NZ-CHAT',\n",
       " 'Navajo',\n",
       " 'PRC',\n",
       " 'PST8PDT',\n",
       " 'Pacific/Apia',\n",
       " 'Pacific/Auckland',\n",
       " 'Pacific/Bougainville',\n",
       " 'Pacific/Chatham',\n",
       " 'Pacific/Chuuk',\n",
       " 'Pacific/Easter',\n",
       " 'Pacific/Efate',\n",
       " 'Pacific/Enderbury',\n",
       " 'Pacific/Fakaofo',\n",
       " 'Pacific/Fiji',\n",
       " 'Pacific/Funafuti',\n",
       " 'Pacific/Galapagos',\n",
       " 'Pacific/Gambier',\n",
       " 'Pacific/Guadalcanal',\n",
       " 'Pacific/Guam',\n",
       " 'Pacific/Honolulu',\n",
       " 'Pacific/Johnston',\n",
       " 'Pacific/Kanton',\n",
       " 'Pacific/Kiritimati',\n",
       " 'Pacific/Kosrae',\n",
       " 'Pacific/Kwajalein',\n",
       " 'Pacific/Majuro',\n",
       " 'Pacific/Marquesas',\n",
       " 'Pacific/Midway',\n",
       " 'Pacific/Nauru',\n",
       " 'Pacific/Niue',\n",
       " 'Pacific/Norfolk',\n",
       " 'Pacific/Noumea',\n",
       " 'Pacific/Pago_Pago',\n",
       " 'Pacific/Palau',\n",
       " 'Pacific/Pitcairn',\n",
       " 'Pacific/Pohnpei',\n",
       " 'Pacific/Ponape',\n",
       " 'Pacific/Port_Moresby',\n",
       " 'Pacific/Rarotonga',\n",
       " 'Pacific/Saipan',\n",
       " 'Pacific/Samoa',\n",
       " 'Pacific/Tahiti',\n",
       " 'Pacific/Tarawa',\n",
       " 'Pacific/Tongatapu',\n",
       " 'Pacific/Truk',\n",
       " 'Pacific/Wake',\n",
       " 'Pacific/Wallis',\n",
       " 'Pacific/Yap',\n",
       " 'Poland',\n",
       " 'Portugal',\n",
       " 'ROC',\n",
       " 'ROK',\n",
       " 'Singapore',\n",
       " 'Turkey',\n",
       " 'UCT',\n",
       " 'US/Alaska',\n",
       " 'US/Aleutian',\n",
       " 'US/Arizona',\n",
       " 'US/Central',\n",
       " 'US/East-Indiana',\n",
       " 'US/Eastern',\n",
       " 'US/Hawaii',\n",
       " 'US/Indiana-Starke',\n",
       " 'US/Michigan',\n",
       " 'US/Mountain',\n",
       " 'US/Pacific',\n",
       " 'US/Samoa',\n",
       " 'UTC',\n",
       " 'Universal',\n",
       " 'W-SU',\n",
       " 'WET',\n",
       " 'Zulu']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytz\n",
    "pytz.all_timezones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "11205a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_tz = pytz.timezone(\"America/New_York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d2ec1248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-09-08 22:46:27.481900-0400', tz='America/New_York')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp.now(tz=ny_tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "082a361c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-09-14 08:20:02.610105')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp.now() + pd.Timedelta(days=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "71e4e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '26-01-2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "45924331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhanu\\AppData\\Local\\Temp\\ipykernel_42292\\1702495809.py:1: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  pd.to_datetime(date)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-01-26 00:00:00')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "12852ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pd.Timestamp.today() - pd.to_datetime(df['hire_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7b28602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number_days_active'] = k.dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b569d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "91a3eec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='first_name'>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['first_name','number_days_active','salary']].plot(kind='barh',x='first_name',y=['salary','number_days_active'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c455b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.plotting.backend =  \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "41857ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=salary<br>first_name=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "salary",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "salary",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "John",
          "Sarah",
          "Mike",
          "Emily",
          "David",
          "Lisa",
          "Tom",
          "Anna",
          "Chris",
          "Jessica"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "GHMBANhTAQBAGQEAoAkBALAwAQAITAEA6P0AADDyAACoWwEAWBUBAA==",
          "dtype": "i4"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=number_days_active<br>first_name=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "number_days_active",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "number_days_active",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "John",
          "Sarah",
          "Mike",
          "Emily",
          "David",
          "Lisa",
          "Tom",
          "Anna",
          "Chris",
          "Jessica"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "EAg7CRAGJgerCRcFyQW4B88IYAU=",
          "dtype": "i2"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "first_name"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['first_name','number_days_active','salary']].plot(kind='bar',x='first_name',y=['salary','number_days_active'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8532b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"save.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f235520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"save.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5e81f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"save.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d3d49560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Unnamed: 0\":\"Dummy_INDEX\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071bb7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2afc3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387cce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #(n_rows, n_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6c0bd87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "642964f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id           10\n",
       "first_name            10\n",
       "last_name             10\n",
       "email                 10\n",
       "hire_date             10\n",
       "salary                10\n",
       "department_id         10\n",
       "manager_id             5\n",
       "full_name             10\n",
       "salary_category       10\n",
       "number_days_active    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c1414fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(df['manager_id'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "11d24e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(5)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()['manager_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "fa317525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(772000)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3adf1600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       10.000000\n",
       "mean     77200.000000\n",
       "std      11272.385137\n",
       "min      62000.000000\n",
       "25%      68750.000000\n",
       "50%      75000.000000\n",
       "75%      86500.000000\n",
       "max      95000.000000\n",
       "Name: salary, dtype: float64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2b978982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>number_days_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.50000</td>\n",
       "      <td>77200.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>1867.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.02765</td>\n",
       "      <td>11272.385137</td>\n",
       "      <td>1.418136</td>\n",
       "      <td>2.302173</td>\n",
       "      <td>425.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>62000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.25000</td>\n",
       "      <td>68750.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1498.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.50000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1903.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.75000</td>\n",
       "      <td>86500.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2207.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.00000</td>\n",
       "      <td>95000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2475.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       employee_id        salary  department_id  manager_id  \\\n",
       "count     10.00000     10.000000      10.000000    5.000000   \n",
       "mean       5.50000  77200.000000       2.300000    2.600000   \n",
       "std        3.02765  11272.385137       1.418136    2.302173   \n",
       "min        1.00000  62000.000000       1.000000    1.000000   \n",
       "25%        3.25000  68750.000000       1.000000    1.000000   \n",
       "50%        5.50000  75000.000000       2.000000    1.000000   \n",
       "75%        7.75000  86500.000000       3.000000    4.000000   \n",
       "max       10.00000  95000.000000       5.000000    6.000000   \n",
       "\n",
       "       number_days_active  \n",
       "count           10.000000  \n",
       "mean          1867.500000  \n",
       "std            425.006993  \n",
       "min           1303.000000  \n",
       "25%           1498.750000  \n",
       "50%           1903.000000  \n",
       "75%           2207.250000  \n",
       "max           2475.000000  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b15335d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   employee_id         10 non-null     int64  \n",
      " 1   first_name          10 non-null     object \n",
      " 2   last_name           10 non-null     object \n",
      " 3   email               10 non-null     object \n",
      " 4   hire_date           10 non-null     object \n",
      " 5   salary              10 non-null     int64  \n",
      " 6   department_id       10 non-null     int64  \n",
      " 7   manager_id          5 non-null      float64\n",
      " 8   full_name           10 non-null     object \n",
      " 9   salary_category     10 non-null     object \n",
      " 10  number_days_active  10 non-null     int64  \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 1012.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "bdd790eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = df.groupby(['department_id'])[['department_id','salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "72656a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.count_nonzero([1,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0134c2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhanu\\AppData\\Local\\Temp\\ipykernel_42292\\71933563.py:1: FutureWarning:\n",
      "\n",
      "The provided callable <function mean at 0x000002A05755ACA0> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_df  = group_data.agg({\"department_id\":np.count_nonzero,'salary':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ff54069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = 'matplotlib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "90750dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<Axes: ylabel='salary'>], dtype=object)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_df['salary'].plot(kind='pie',subplots=True,autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "982f3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_datetime(df['hire_date']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614644a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<Axes: ylabel='salary'>], dtype=object)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(['department_id','year'])['salary'].mean().plot(kind='pie',subplots=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c151175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=df.groupby(['department_id','year'])['salary'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8b286f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department_id</th>\n",
       "      <th>year</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>87000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>95000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>71500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>78000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>68000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>85000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>62000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>89000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   department_id  year   salary\n",
       "0              1  2019  87000.0\n",
       "1              1  2020  95000.0\n",
       "2              1  2021  71500.0\n",
       "3              2  2018  78000.0\n",
       "4              2  2020  68000.0\n",
       "5              3  2021  65000.0\n",
       "6              3  2022  85000.0\n",
       "7              4  2020  62000.0\n",
       "8              5  2019  89000.0"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423a3361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<Axes: ylabel='salary'>], dtype=object)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df.groupby(['department_id','year'])['salary'].mean().plot(kind='pie',subplots=True,autopct=lambda x: round(x*df['salary'].mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcade69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcf869d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate mean salaries per group\n",
    "means = df.groupby(['department_id','year'])['salary'].mean()\n",
    "\n",
    "# Function to return actual slice values\n",
    "def actual_values(pct, allvals):\n",
    "    total = sum(allvals)\n",
    "    value = int(round(pct * total / 100.0))\n",
    "    return f\"{value:.2f}\"\n",
    "\n",
    "# Plot pie chart with actual values displayed\n",
    "means.plot(\n",
    "    kind='pie',\n",
    "    autopct=lambda pct: actual_values(pct, means.values)\n",
    ")\n",
    "\n",
    "plt.ylabel(\"\")  # remove automatic y-label\n",
    "plt.title(\"Average Salary by Department & Year\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b86b2348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(87562.5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12.5*sum(means.values)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1163289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['employee_id'] = df['employee_id'].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2aa27f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>department_id</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "      <td>john.smith@company.com</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>95000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>sarah.johnson@company.com</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Mike</td>\n",
       "      <td>Brown</td>\n",
       "      <td>mike.brown@company.com</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>72000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Davis</td>\n",
       "      <td>emily.davis@company.com</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>68000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>David</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>david.wilson@company.com</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>78000</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>lisa.anderson@company.com</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>85000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>tom.taylor@company.com</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>65000</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Anna</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>anna.martinez@company.com</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>chris.garcia@company.com</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>89000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Lee</td>\n",
       "      <td>jessica.lee@company.com</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>71000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id first_name last_name                      email   hire_date  \\\n",
       "0          1.0       John     Smith     john.smith@company.com  2020-01-15   \n",
       "1          2.0      Sarah   Johnson  sarah.johnson@company.com  2019-03-22   \n",
       "2          3.0       Mike     Brown     mike.brown@company.com  2021-06-10   \n",
       "3          4.0      Emily     Davis    emily.davis@company.com  2020-09-05   \n",
       "4          5.0      David    Wilson   david.wilson@company.com  2018-11-30   \n",
       "5          6.0       Lisa  Anderson  lisa.anderson@company.com  2022-02-14   \n",
       "6          7.0        Tom    Taylor     tom.taylor@company.com  2021-08-20   \n",
       "7          8.0       Anna  Martinez  anna.martinez@company.com  2020-04-12   \n",
       "8          9.0      Chris    Garcia   chris.garcia@company.com  2019-07-08   \n",
       "9         10.0    Jessica       Lee    jessica.lee@company.com  2021-12-03   \n",
       "\n",
       "   salary  department_id  manager_id  year  \n",
       "0   95000              1         NaN  2020  \n",
       "1   87000              1         1.0  2019  \n",
       "2   72000              1         1.0  2021  \n",
       "3   68000              2         NaN  2020  \n",
       "4   78000              2         4.0  2018  \n",
       "5   85000              3         NaN  2022  \n",
       "6   65000              3         6.0  2021  \n",
       "7   62000              4         NaN  2020  \n",
       "8   89000              5         NaN  2019  \n",
       "9   71000              1         1.0  2021  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7fd69a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhanu\\AppData\\Local\\Temp\\ipykernel_23468\\48949584.py:2: FutureWarning: The provided callable <function mean at 0x000001F8FB6CCEA0> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  df.groupby(['department_id'])[['employee_id','salary']].agg(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>81250.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               employee_id   salary\n",
       "department_id                      \n",
       "1                        4  81250.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df.groupby(['department_id'])[['employee_id','salary']].agg(\n",
    "    {\n",
    "        \"employee_id\":np.count_nonzero,\n",
    "        \"salary\":np.mean\n",
    "    }\n",
    ").query(\"employee_id > 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc67e24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhanu\\AppData\\Local\\Temp\\ipykernel_23468\\2097603498.py:2: FutureWarning: The provided callable <function mean at 0x000001F8FB6CCEA0> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  tmp_df.groupby(['department_id'])[['employee_id','salary']].agg(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='department_id'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGxCAYAAACA4KdFAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAATbZJREFUeJzt3Qd4VGX69/E7CUkIJXQSepFeBARB7AoSEV1RVxH9Iyp2VFAXlHdX0HVdsFdEXXfB3VUprpUq0lQIIL1H0FAEQgRJaCGE5Hmv+xnOZAYSmAmESc58P9d1HM6cJ2fOHAfml6dGGGOMAAAAuExkqC8AAACgOBByAACAKxFyAACAKxFyAACAKxFyAACAKxFyAACAKxFyAACAKxFyAACAK5WRMJaXlyc7duyQihUrSkRERKgvBwAABEDnMd6/f7/Url1bIiMLr68J65CjAadevXqhvgwAAFAE27Ztk7p16xZ6PKxDjtbgODcpPj4+1JcDAAACsG/fPltJ4XyPFyasQ47TRKUBh5ADAEDpcqquJnQ8BgAArkTIAQAArkTIAQAArkTIAQAArkTIAQAArkTIAQAArhRUyMnNzZWnn35aGjVqJHFxcXLOOefIc889Z2cedOifhw8fLrVq1bJlunfvLhs3bvQ7z++//y633367HbZduXJlGTBggBw4cMCvzKpVq+SSSy6RsmXL2rHwL7744gnXM2nSJGnRooUt07ZtW5k6dWrwdwAAALhSUCHnhRdekDFjxsjbb78t69evt/saPt566y1vGd1/88035d1335VFixZJ+fLlJSkpSQ4fPuwtowFn7dq1MnPmTJk8ebJ89913ct999/lN8tOjRw9p0KCBLF26VF566SV55pln5P333/eWWbBggfTt29cGpOXLl0vv3r3ttmbNmtO/KwAAoPQzQejVq5e5++67/Z678cYbze23327/nJeXZxITE81LL73kPZ6RkWFiY2PNJ598YvfXrVun1T7mxx9/9JaZNm2aiYiIMNu3b7f777zzjqlSpYrJzs72lnnyySdN8+bNvfu33HKLvR5fXbp0Mffff3/A7yczM9Neiz4CAIDSIdDv76Bqci688EKZNWuW/PTTT3Z/5cqV8sMPP0jPnj3tfmpqqqSlpdkmKkelSpWkS5cukpycbPf1UZuoOnXq5C2j5XWBLa35ccpceumlEhMT4y2jtUEpKSmyd+9ebxnf13HKOK8DAADCW1DLOjz11FO2KUn7wURFRdk+Os8//7xtflIacFRCQoLfz+m+c0wfa9as6X8RZcpI1apV/cpov5/jz+Ecq1Klin082esUJDs7224OfS8AAMCdgqrJmThxonz00Ufy8ccfy7Jly+TDDz+Ul19+2T6WBiNHjrQ1S87GCuQAALhXUCFnyJAhtjbn1ltvtaOZ+vXrJ4899pgNDyoxMdE+7tq1y+/ndN85po/p6el+x48ePWpHXPmWKegcvq9RWBnneEGGDRsmmZmZ3k1XHy8WG78V2bFcOzwVz/kBAMCZDTmHDh2yfWd8abNVXl6e/bM2MWnI0H47vk1C2tema9eudl8fMzIy7Kgpx+zZs+05tO+OU0ZHXOXk5HjL6Eis5s2b26Yqp4zv6zhlnNcpSGxsrHfF8WJbeVyDzdQnRN6/XOT1tiLTnhLZPF8kL/fMvxYAAChcML2Z+/fvb+rUqWMmT55sUlNTzWeffWaqV69uhg4d6i0zatQoU7lyZfPll1+aVatWmeuvv940atTIZGVlectcffXVpkOHDmbRokXmhx9+ME2bNjV9+/b1G5GVkJBg+vXrZ9asWWPGjx9vypUrZ9577z1vmfnz55syZcqYl19+2axfv96MGDHCREdHm9WrV4d2dNXhfcZM6GfM3xKNGRGfv73Q2JgvHzHmp2+MyTl85l4PAIAwkxng93dQIWffvn1m0KBBpn79+qZs2bKmcePG5s9//rPfUG8dRv7000/bkKJDx7t162ZSUlL8zrNnzx4baipUqGDi4+PNXXfdZfbv3+9XZuXKlebiiy+259BgpeHpeBMnTjTNmjUzMTExpnXr1mbKlCnBvJ3iHUJ+5JAx6ycb89n9xoys7x94/l7XmE8HGLP2C2OyD5z51wYAwMUC/f6O0P9ImNKmNO2ArP1ziqXpypGbI7L5B5H1X4tsmCxywKcvUZmyIud0E2l5nUizJJFyVYvvOgAACKPvb0LO2Qg5vrT/0vYlIuu/8oSevZvzj0WWEWl4sSfwtLhWpGLhnagBAAhX+wg5JTTk+NJbv2uNyPrJnsCTvtbnYIRIvc6esKOhp6r/vEEAAISrfYScUhByjrfn5/wmrV9/9D+W0NYTdlpeK1KzlUhERKiuEgCAkCLklMaQ42vfDpENUzzNWjoE3fgMQa/a+Fjg+YNI7fNEjhvWDwCAmxFySnvI8XXod5GUaZ5anp9ni+TmL00hFWvlN2k1uEgkKqiVOgAAKHUIOW4KOb6y94tsnOlp0vpphsiRA/nH4qqINL/GE3gaXyESXTaUVwoAQLEg5Lg15PjKOSySOs/TpLVhqkjW7/nHYiqINL3KU8vTtIdI2VL4/gAAKAAhJxxCjq/coyJbk/M7Lu/bnn8sKsZTs6M1PFrTU75aKK8UAIDTQsgJt5DjS/+X7ljmCTy67dmUfywi0tN3x87F00ukUt1QXikAAEEj5IRzyPGl/3t/SzkWeL4SSVvlf7xOx2Mdl/8gUr1JqK4SAICAEXICEBYh53g6w7JOPqhNWlsXagrKP1ajpWceHq3lSTyXuXgAACUSIScAYRlyfO3fJZKic/FM9nRgzjuaf6xyfU/tjgaeup2ZiwcAUGIQcgIQ9iHHV9ZekZ++8TRpbZolcjQr/1j5mp7+Oxp4Gl4iUiYmlFcKAAhz+wg5p0bIKcSRQyI/z/L040mZLpKdmX8stpJI86s9gUdXT48pF8orBQCEoX2EnFMj5ATg6BGRzd8d68czReRgev6xMnEiTbuLtLhOpFmSSFzlUF4pgEAdSBfZsUJk50qRnStE0teLVGsi0u5WzzQTTCSKEo6QEwBCTpDyckW2LfZ0WtZmrYyt+cciy4g0uix/aHqFmqG8UgBK/3nfv9MTZnxDjT5XGK2tbd1bpF1fkfoXMAABJRIhJwCEnNOgHxsdju7MxfPbBp+DEZ5/HG3guVakSoMQXigQRn8nM7cdF2hW+te+ekWIVG8mUqudSO32ItWbi2xdILJygsi+X/OLVW7gqd05t49ItXPO5rsBToqQEwBCzhm0e2N+4NGJCH3pcHRnpFaN5vxmCJwu/Wdbp4PQWhnfUOO7tIvvBKA1WojUap8fahLaiMRWOLFsXp7Ilh9EVo4XWfel/9p49bp4wk7rG0TKVS3e9wecAiEnAIScYpL5q6f/jgaeLfNFTF7+sWpN8+fiqX0egQc4FQ0ev/9yLND41NAc9hkQ4NtsXLOlJ8zYUKOBpnXRBgjoAAT9e7zyE5Ff5uT/PdZlYppd7WnOatKd0ZYICUJOAAg5Z8HB3SIpUz0dl/Ufytwj+cfi63oCjzZp1e8qElUmlFcKlIx+b7oMi2//mZ2rRI7sP7Gsho2arTw1M06o0f3i6DS8P01k9SSRFZ+IpK/Nf75cNZE2fxRp14dfWnBWEXICQMg5yw7vE9moc/F8LbJxpkjOQf9/LHVUhzZrNb5MpExsKK8UODuL6u5O8W9uSlvt//fCUaasp4nJaW7SR52hPBS1KHqN2pyloefArvzntY+P9t9pe4tI5Xpn/7oQVvYRck6NkBNCOVkiv8w9NhfPVM9khI6YiiLNeniatJpcVXDfAaC0TcWgnfN9+9DsWiNy9PCJZaPLiSS29e9DowEiKlpKXEjTv8PanKUjLr3vJUKk4cWe5qxWfxCJrRjiC4UbEXICQMgpQf9Yat8dDTz6j6Xv8NaoWJFzrvQEnuY96fCIku9otsiutT7NTSs9+75Ntb6Bvta5Pn1o2olUbyoSGSWlrpZWOyprDY92XPadS0v/7mpzVuMrSt/7QolFyAkAIaeEdrLcvlRkw9ci674S2ZuafywiyvMbojMXT3ztUF4p4KmR1ACzY7n/xHq+68D5zj+jgcY2Nx3bqjZ237pwe7eIrJ7oCTzav8hRIVHk3Js9NTzaGRo4DYScABBySjj9aKavOzY0fbLIrtX+x+uenz8XD3N4oLgdOejpj+Lbh0aboEzuiWXjqvg3N+ljlUbh1TFX//7qLywadtZ86t8krc1x52r/nZtFKiaE8ipRShFyAkDIKWV0GK2GHQ09vy72P1aztSfw6Ka/JYbTlwmKp/nFBhqfPjS7f9Jv7hPLlqvuUztzLNRUqsdn8Pg+STroQPvv/DRDJC8nv3ZWm6O1w7LWzkbHhfpKUUoQcgJAyCnF9u0USTk2F0/q9/6/TVdpeCzw/EGkTif3NQfgzMrKyJ97xgk1vs0svrTJxXfItj5qsymBJnCHfhdZ+5mnhufXH/Ofj433dFS2y0lcyN9bnBQhJwCEHBf9o6m/HWrg0dXTfUes6JeS/oaooUf785S0ESo4+58VDTK+89DozMEF0XmcfJubdKuYeLav2N12bxJZNUFk1Xj/tfAq1fd0VtYmrepNQnmFKKEIOQEg5LhQ9gGRTd96Rmlp8Mnel3+sbOVjc/Fc66kip2rc3Q78lj9LsA01q0Qyfb5IfVWu79/clNhOpEKNs33F4T3gYGuypzlr7Rf+kx9qbaw2Z7W5idGV8CLkBICQEwZDeVO/86yYvmGqyKHd+ceiy4s07e5p0mp6lUjZSqG8UpyJ5kvf5iYNNft3FFxWRzT5NjfpxpdnyRqxpstJaA3Ppln5TdGR0SLNkjyBp2kPJgwNc/sIOadGyAmz6fK3LsxfRNR3pWX9x7Px5cfm4rmG3+BL/Erbv/oHGt18Z971ihCp1sS/D42O6omrHIILR5Hs3+UZmaU1PNoR3Hf0mtbsaP+dOh3pExWG9hFyTo2QE6b0I69fkOuPzcWzZ6P/is3a6dFZU4vp6UP7/yljy3HrOK0UObTnxLL6/6168+MCja60zWy7rqHzEWln5VUTRQ6k5T+vQVb77px7i0iVBqG8QpT2kNOwYUPZsmXLCc8/9NBDMnr0aDl8+LA88cQTMn78eMnOzpakpCR55513JCEhfx6ErVu3yoMPPihz5syRChUqSP/+/WXkyJFSpkz+4oxz586Vxx9/XNauXSv16tWTv/zlL3LnnXf6vaa+3ksvvSRpaWnSrl07eeutt6Rz584SDEIOrN9SPE1aOjxdv0h91e5wbC6e60RqNAvVFYZHnwyd+NGvU7CutJ1R8Erbum6Tb6dgXdepKCtto3TWyupyEtqcpb+o5BzKP9ZAl5O4VaTV9SJl+TfdzYol5Pz222+Sm5s/VHfNmjVy1VVX2cBy+eWX2/AyZcoUGTdunH3xhx9+WCIjI2X+/Pm2vP5s+/btJTEx0QaUnTt3yh133CH33nuv/P3vf7dlUlNTpU2bNvLAAw/IPffcI7NmzZLBgwfb82poUhMmTLA/9+6770qXLl3k9ddfl0mTJklKSorUrFnzjN8khBEd4aFhRzsub1ngPy+K1hQ4c/HoFytV5Kex0vbP/v1n0lb5dxL3bUpMaJVfO6OhRudEKo6VtlH6ZO/3BB1tztKpJJy/r7qgqY6q1OYsXU4iKv+XaLjDWWmu0vAxefJk2bhxo33BGjVqyMcffyx//OMf7fENGzZIy5YtJTk5WS644AKZNm2aXHvttbJjxw5v7Y4GlSeffNIGqJiYGPtnDTQaoBy33nqrZGRkyPTp0+2+Bpvzzz9f3n77bbufl5dna3weeeQReeqpp874TUKYOpDuWTxU/xH9ZV7+BGbOEFdt0tLAU68La/KcdKXtn47rQ7Oq4JW2dZ0yncjRt8mppq60TQdTBED7amlTljZp6erujvI1PTMraw2P9snilxNXCPT7u8jx9siRI/Lf//7XNitFRETI0qVLJScnR7p37+4t06JFC6lfv7435Ohj27Zt/ZqvtHZGa4C0aapDhw62jO85nDIaqJzX1dcaNmyY97jWFunP6M+ejDah6eZ7k4BCVagp0vFOz3Y4U+SnbzzNWjpEXYciL3zHs5WvcWxo+h9EGl0qUiZGwlJujmeZA98+NGm60nbWiWV14Ub9wvENNDWaM48Riq5SXZFLHhe5+DHPWmLOchIH00UWjvZsWguoYUdDT3ytUF8xzoIih5wvvvjC1q44fWW0b4zWxFSu7D9yQQONHnPK+AYc57hz7GRlNJBkZWXJ3r17bbNXQWW05uhktO/Ps88+W9S3jHCmQ8x1cUHdjhwS+WWOp4ZHa3oO/iay7EPPposw6jBXreVp0l0kpry4dni+rivmu46TXWk7/5cIr5gKIonHVtp2Qk21pjQhoHhoTU2d8zxb0vOeX0q0OStlmkj6WpGZT4t8O8IzolKbs7RZy61/T1H0kPPPf/5TevbsKbVrl56VoLX2R2ueHBqctJkLCIp2cNV/GHXT2ovN33sCj87toUOZdQVm3bRfgAYdHaXV/GrPsNdSu9K2Bprl+aHGrrTt03znOzW/M/eM04em6jlM0Y/Q0JrB5j09my4QuvZzkZUTRLYtFPl5tmfTEK4dlbWGRzsu81l1lSKFHB1h9e2338pnn33mfU47E2tTktbu+Nbm7Nq1yx5zyixe7L+woh53jjmPznO+ZbTNLS4uTqKiouxWUBnnHIWJjY21G3BG/xHV2ZN1u+YVz1o8dqTW157hz9qBWTcdEdTwkmMjtXqV3OUB7Erba/z70GigKWilbZ1B+vh1nHSlbb4kUBLpLxmd7vZs2vHd9t/5xPP3dMVHnk2X8tCh6Bp4tPkU4Rlyxo4da0cx9erVy/tcx44dJTo62o6Guummm+xzOtpJh4x37drV7uvj888/L+np6d5RUDNnzrQBplWrVt4yU6dO9Xs9LeOcQ5vE9LX0dXr37u3teKz7OpoLCBn9cq/fxbP1+JvIrjX5kw9q0442cek25QmRep2PBZ5rRao2Ct3IFJ1gzbcPjXYSNnknli1XLb9mxgk1uhQCnThRGlU7R+SKYSKXPyWybZEn7Kz53DNJ6A+verba5+UvJ1G+eqivGEUU9OgqDRSNGjWSvn37yqhRo/yOaQdiDSg6hFyDi452UgsWLPAbQq5NXC+++KLtf9OvXz87VPz4IeQDBw6Uu+++W2bPni2PPvroCUPIdX6d9957z86No0PIJ06caPvkHN9X52QYXYWzRn9zdALP9iX+x7QDrs7Do6FHRxMVR3DQlbZ1mLZvHxq70nYBf/0rJPiv42RX2q5DoIG75RwW+Wmapzlr00yRvKOe57UWVpeR0MDT7GpG+7l9CPk333xjw4bW0jRr5j85mjMZ4CeffOI3GaBvM5I2dWkY0gn/ypcvb8OKhqXjJwN87LHHZN26dVK3bl15+umnT5gMUIePO5MBanB688037dDyYBByEBKZ2z39dzZ8LbJ5vn9TkPZfcebi0d8ki9L0Y1faPm4dJ51oryAaXnybmzTUlNSmNOBsLu665n+eGh7fCUJ1AELrGz0dlrU2luAfMizrEABCDkLu4B7Pb49aw/PzHP/RSRVr58/Fo0tNFDQa6eDuYzUzzrbSM6FhQXRun9pOp+AOIrXO9QyTB1C49A0iq8Z7anh8F33V/mdau3Nun9A1OYexfYScUyPkoETRPjIbZ3oCz8ZvRI4cyD8WV9UzF4/Ow7N3c35Nzb7tBZ9L/wH2bW7SmhpW2gZOb6ZuHUmp8+/omne+E1rW73psOYneLAB7lhByAkDIQYnuH5A6zzNSa8NUkazfCy+rCxT6NjfpnDT8QwsU7yhEXf5Fm7N0HS2nb5vO2t3iGs+CoU26MbllMSLkBICQg1KzNMLWBZ5/VLcv9YwMcUKNdlpmIUIgdPbtyF9O4rf1+c+Xq56/nARr3Z1xhJwAEHIAAGeEfpXqCEYNO6sneWZCd9RocWw5iVtEKtUJ5VW6BiEnAIQcAMAZpzOh60ACbc7SkZTeAQURIo0v8zRn6YCC2AohvtDSi5ATAEIOAKBY6RxV67701PBos7MjupxnUV+t4dEBBZFRobzKUoeQEwBCDgDgrNGRkc5yEr//kv98xVrHlpPo65kQFKdEyAkAIQcAcNbp166uc2eXk/hM5HBG/jHtpKxhp80fRSrUCOVVlmiEnAAQcgAAIXU0W+SnGZ7mrI0z8peTiIgSadLd05ylc2RFlw31lZYohJwAEHIAACVqBvS1n3lqeHS6CEesLifR2xN4dOJBhqMLIScAhBwAQIn020+e5SS0D0/mtvznKzfIX05C58wKU/sIOadGyAEAlGh5eSJb5h9bTuIL/+Ve6nb2BJ7WN4Tdsi37CDmnRsgBAJQaRw6JpEz1NGf9PFvE5Hmej4oRaXa1p8Oy9uMpEyNut4+Qc2qEHABAqbQ/zTOzstbw7Frjv5hv2z96anhqn+fa/juEnAAQcgAApV7a6vzlJA7syn++erP85SQq1xM3IeQEgJADAHDVYr66KrqznMTRrGMHIkQaXuxpzmr1B5HYilLaEXICQMgBALjS4X0i67/y1PBs/j7/+TJxIi2v9dTwNL6i1C4nQcgJACEHAOB6GVuPLScxXmTPxvznKySKnHuzZ8HQxDZSmhByAkDIAQCEDWNEti87tpzE/0Syfs8/ltD2WP+dm0UqJkhJR8gJACEHABCWjh4R2TTTE3hSpovk5Xiej4gUOadb/nISMeWkJCLkBICQAwAIe4d+P7acxASRXxfnPx9TUaT19Z4Oy/UvFImMlJKCkBMAQg4AAD72/Ozpu6NLSmhfHkel+iLn3uKp4aneVEKNkBMAQg4AAIUsJ7E12RN21n4hkr0v/1idTp6w0+amkC0nQcgJACEHAIBTyMk6tpzEeJFNs0RMruf5yGiRZkmewNO0h0iZWDlbCDkBIOQAABCEA+kiqz/1dFhOW5X/fFwVT82ODkev26nYl5Mg5ASAkAMAQBHtWudpztI5ePbvzH++6jmezsrah6dKAykOhJwAEHIAADhNebkiqfM8zVnrvxbJOZR/rMFFIte+JlKjuYTi+7vMGX1VAAAQXiKjRM650rNl7xdZP9nTnJX6nci2xSLla4Ts0gg5AADgzNDFP9v39WyZv4r8uiRkI7AUIQcAAJx5lep6thAqOdMXAgAAhDLkbN++Xf7v//5PqlWrJnFxcdK2bVtZsmSJ97j2Yx4+fLjUqlXLHu/evbts3Oiz6qmI/P7773L77bfbzkKVK1eWAQMGyIEDB/zKrFq1Si655BIpW7as1KtXT1588cUTrmXSpEnSokULW0avY+rUqcG+HQAA4FJBhZy9e/fKRRddJNHR0TJt2jRZt26dvPLKK1KlShVvGQ0jb775prz77ruyaNEiKV++vCQlJcnhw4e9ZTTgrF27VmbOnCmTJ0+W7777Tu677z6/XtM9evSQBg0ayNKlS+Wll16SZ555Rt5//31vmQULFkjfvn1tQFq+fLn07t3bbmvWrDn9uwIAAEo/E4Qnn3zSXHzxxYUez8vLM4mJieall17yPpeRkWFiY2PNJ598YvfXrVunQ9bNjz/+6C0zbdo0ExERYbZv327333nnHVOlShWTnZ3t99rNmzf37t9yyy2mV69efq/fpUsXc//99wf8fjIzM+216CMAACgdAv3+Dqom56uvvpJOnTrJzTffLDVr1pQOHTrIP/7xD+/x1NRUSUtLs01UDh3H3qVLF0lOTrb7+qhNVHoeh5aPjIy0NT9OmUsvvVRiYmK8ZbQ2KCUlxdYmOWV8X8cp47wOAAAIb0GFnF9++UXGjBkjTZs2lRkzZsiDDz4ojz76qHz44Yf2uAYclZCQ4Pdzuu8c00cNSL7KlCkjVatW9StT0Dl8X6OwMs7xgmRnZ9umMN8NAAC4U1BDyPPy8mwNzN///ne7rzU52gdG+9/0799fSrqRI0fKs88+G+rLAAAAJa0mR0dMtWrVyu+5li1bytatW+2fExMT7eOuXbv8yui+c0wf09PT/Y4fPXrUjrjyLVPQOXxfo7AyzvGCDBs2zE4B7Wzbtm0L5u0DAAC3hhwdWaX9Ynz99NNPdhSUatSokQ0Zs2bN8h7XJiHta9O1a1e7r48ZGRl21JRj9uzZtpZI++44ZXTEVU5OjreMjsRq3ry5dySXlvF9HaeM8zoFiY2NtcPWfTcAAOBSwfRmXrx4sSlTpox5/vnnzcaNG81HH31kypUrZ/773/96y4waNcpUrlzZfPnll2bVqlXm+uuvN40aNTJZWVneMldffbXp0KGDWbRokfnhhx9M06ZNTd++ff1GZCUkJJh+/fqZNWvWmPHjx9vXee+997xl5s+fb6/l5ZdfNuvXrzcjRoww0dHRZvXq1QG/H0ZXAQBQ+gT6/R1UyFFff/21adOmjR0W3qJFC/P++++fMIz86aeftiFFy3Tr1s2kpKT4ldmzZ48NNRUqVDDx8fHmrrvuMvv37/crs3LlSjtcXc9Rp04dG56ON3HiRNOsWTMTExNjWrdubaZMmRLUeyHkAABQ+gT6/R2h/5EwFehS7QAAoPR9f7N2FQAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcCVCDgAAcKWgQs4zzzwjERERfluLFi28xw8fPiwDBw6UatWqSYUKFeSmm26SXbt2+Z1j69at0qtXLylXrpzUrFlThgwZIkePHvUrM3fuXDnvvPMkNjZWmjRpIuPGjTvhWkaPHi0NGzaUsmXLSpcuXWTx4sXBv3sAAOBaQdfktG7dWnbu3OndfvjhB++xxx57TL7++muZNGmSzJs3T3bs2CE33nij93hubq4NOEeOHJEFCxbIhx9+aAPM8OHDvWVSU1NtmSuuuEJWrFghgwcPlnvuuUdmzJjhLTNhwgR5/PHHZcSIEbJs2TJp166dJCUlSXp6+undDQAA4B4mCCNGjDDt2rUr8FhGRoaJjo42kyZN8j63fv16oy+RnJxs96dOnWoiIyNNWlqat8yYMWNMfHy8yc7OtvtDhw41rVu39jt3nz59TFJSkne/c+fOZuDAgd793NxcU7t2bTNy5Mhg3o7JzMy016ePAACgdAj0+zvompyNGzdK7dq1pXHjxnL77bfb5ie1dOlSycnJke7du3vLalNW/fr1JTk52e7rY9u2bSUhIcFbRmtg9u3bJ2vXrvWW8T2HU8Y5h9YC6Wv5lomMjLT7TpnCZGdn29fy3QAAgDsFFXK074s2L02fPl3GjBljm5YuueQS2b9/v6SlpUlMTIxUrlzZ72c00OgxpY++Acc57hw7WRkNJFlZWbJ7927b7FVQGecchRk5cqRUqlTJu9WrVy+Ytw8AAEqRMsEU7tmzp/fP5557rg09DRo0kIkTJ0pcXJyUdMOGDbN9eRwanAg6AAC402kNIddam2bNmsmmTZskMTHRNiVlZGT4ldHRVXpM6ePxo62c/VOViY+Pt0GqevXqEhUVVWAZ5xyF0dFaeh7fDQAAuNNphZwDBw7Izz//LLVq1ZKOHTtKdHS0zJo1y3s8JSXF9tnp2rWr3dfH1atX+42Cmjlzpg0brVq18pbxPYdTxjmHNonpa/mWycvLs/tOGQAAgKBGVz3xxBNm7ty5JjU11cyfP990797dVK9e3aSnp9vjDzzwgKlfv76ZPXu2WbJkienatavdHEePHjVt2rQxPXr0MCtWrDDTp083NWrUMMOGDfOW+eWXX0y5cuXMkCFD7Ois0aNHm6ioKFvWMX78eBMbG2vGjRtn1q1bZ+677z5TuXJlv1FbgWB0FQAApU+g399BhRwdyl2rVi0TExNj6tSpY/c3bdrkPZ6VlWUeeughU6VKFRtUbrjhBrNz506/c2zevNn07NnTxMXF2YCkwSknJ8evzJw5c0z79u3t6zRu3NiMHTv2hGt56623bKDSMjqkfOHChSZYhBwAAEqfQL+/I/Q/Eqa047GOssrMzKR/DgAALvv+Zu0qAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSmVCfQEAgPBjjJGjR49Kbm5uqC8FJVBUVJSUKVNGIiIiTus8hBwAwFl15MgR2blzpxw6dCjUl4ISrFy5clKrVi2JiYkp8jkIOQCAsyYvL09SU1Ptb+q1a9e2X2Cn+9s63FfLd+TIEfntt9/sZ6Vp06YSGVm03jWEHADAWaNfXhp06tWrZ39TBwoSFxcn0dHRsmXLFvuZKVu2rBQFHY8BAGddUX8zR/iIPAOfET5lAADAlQg5AACUcA0bNpTXX39dSou5c+favlYZGRmFlhk3bpxUrly5WK+DkAMAAM6oCy+80I6gq1SpkoQSHY8BAMAZpaPmEhMTJdSoyQEAIEA6MmzkyJHSqFEjOwKoXbt28umnn/o10cyYMUM6dOhgj1955ZWSnp4u06ZNk5YtW0p8fLzcdtttfnMEXX755fLwww/bTWs+qlevLk8//bQdSl2YrVu3yvXXXy8VKlSw57zllltk165d9tjmzZttp90lS5b4/Yw2dzVo0MC+B7VmzRrp2bOnPUdCQoL069dPdu/eHdB7LUpzlTZP1a9f346qu+GGG2TPnj1S3Ag5AICQ0i/zQ0eOhmQ7WZAoiH7p//vf/5Z3331X1q5dK4899pj83//9n8ybN89b5plnnpG3335bFixYINu2bbMBRAPGxx9/LFOmTJFvvvlG3nrrLb/zfvjhh3aG38WLF8sbb7whr776qnzwwQcFXoOGDw04v//+u33dmTNnyi+//CJ9+vTx9t/p3r27jB071u/ndP/OO++0AUjDhwYwDWMahqZPn25Dkl5rMO81UIsWLZIBAwbYILdixQq54oor5G9/+5sUtwgT7P9hF9m3b59NzZmZmTYJAwCK1+HDh+0Eb1o74Mx9omGj1fAZIbmedX9NknIxgfXcyM7OlqpVq8q3334rXbt29T5/zz332JqZ++67z3556/Fu3brZY6NGjZJhw4bJzz//LI0bN7bPPfDAA7a2RYOFU5OjtT0aJJyJEZ966in56quvZN26dd7gMnjwYLtpqNEaGL2POt+QfR/r1knr1q1tSDr//PNl4sSJ9nW0X0xsbKwsW7ZMOnXqZMOQnksDxvfff29rnRy//vqrPV9KSoqt8TnZe9XAdqqaHL0Xe/futZ2LtfZKv2s15DluvfVWew8K65xc0Gcl2O9vanIAAAjApk2b7Bf8VVddZZt4nE1rOzTEOM4991zvn7UZSJtnnIDjPKehxtcFF1zgN/OzBouNGzcWuLbX+vXrbRhxAo5q1aqVDRN6TPXu3dvOKv355597m4o0dGjAUStXrpQ5c+b4vY8WLVrYY/peAn2vgdLr6tKli99zvuGpuNDxGAAQUnHRUbZGJVSvHagDBw7YR62NqFOnjt8xrS1xvvx1pl6HBhfffec5p19McXb8veOOO2wT1Y033mhrXrQZzPe9XHfddfLCCy+c8LO6XpT21znZey0tCDkAgJDSL/1Am4xCSWtL9AteO/1edtllJxwvSg2Hb58VXwsXLrRrNmltzPG0A7P29dHNt7lKm330Gn2bltq0aSPvvPOOXfFdw47jvPPOk//973+2Zkf7AgX7XoOl11zQeyxuJf9TBQBACVCxYkX505/+ZDvgak3MxRdfbPuEzJ8/3/YL0X4sRaVh4vHHH5f777/f9p/RjsmvvPJKgWW1U3Hbtm3l9ttvtx2aNcA89NBDNoxovxvfYHHBBRfIk08+KXfffbcdIeUYOHCg/OMf/5C+ffvK0KFDbf8bbaIaP3687fB8qvfav3//oN7fo48+KhdddJG8/PLLttO09gVy+iQVJ/rkAAAQoOeee84O79aRRxoirr76atuko51jT4c2LWVlZUnnzp1tABk0aJDtyFxYzdeXX34pVapUkUsvvdSGHu3zM2HChBPKDhgwwC5wqSHHl64Ar4FF+/z06NHDhibt1Kz9epw1o87ke9WwpaFKm8x0KLqOMPvLX/4ixY3RVYyuAoCz5mQjZsKVjq5q3759sSzb8Nxzz8mkSZNk1apVUtqEfHSVDo3TRKnpz/eiNIVWq1bN9sS+6aabvBMU+VbL9erVy/Y4r1mzpgwZMsRWtx0//EzbDLVNsEmTJrZn+PFGjx5t2xP1zWuvbR06BwBAuNOOxWvWrLHz9TzyyCMSrooccn788Ud57733/IbKKW2/+/rrr21y1AmDduzY4dfZSavGNOBo9ZlOlKQTIGmAGT58uLeMJjcto8PddNIgDVHagcp3PL9Wy2n75YgRI2z7pVZ/JSUlnTAsDwCAcKOT7nXs2NHWEh3fVHUm6Bw8vkPLfTc9VmKYIti/f79p2rSpmTlzprnsssvMoEGD7PMZGRkmOjraTJo0yVt2/fr12hxmkpOT7f7UqVNNZGSkSUtL85YZM2aMiY+PN9nZ2XZ/6NChpnXr1n6v2adPH5OUlOTd79y5sxk4cKB3Pzc319SuXduMHDky4PeRmZlpr00fAQDFLysry6xbt84+ovTatWuX2bhxY4GbHivuz0qg399FqsnR5iitadHOTr6WLl0qOTk5fs/r5EK6VkVycrLd10ft4KSTITm0Bkbb13S2R6fM8efWMs45tBZIX8u3jHaU0n2nTGGzVerr+G4AACA42tVEu5IUtOmxkiLoIeQ6vEybh7S56nhpaWl2AiLtne1LA40ec8r4BhznuHPsZGU0lGjvc50mWpu9CiqzYcOGQq9de4g/++yzwb5lAABQCgVVk6MTD+mwto8++qhU9orX9UO0J7az6fsBAADuFFTI0SYi7diro550hkTdtHPxm2++af+sNSnalHT8Yls6uioxMdH+WR+PH23l7J+qjA4T08mMdBl6nQWyoDLOOQqiI7X0HL4bAABwp6BCjq6qunr1ajviydl0dkWdddH5s67RMWvWLO/P6GqmOmTcWYhLH/UcvqOgdEVVDRzOdNRaxvccThnnHNokpr3GfcvojIy6fzYW/AIAACVfUH1ydJpnXQfDV/ny5e2cOM7zOruiDu3WKaI1uOj4fA0eOtuh0pkVNcz069dPXnzxRdv/Rmc91M7MzqJfOvxMx/brVNM69G327Nl22XjfJdr1NXRaaQ1WOkOkTqJ08OBBueuuu87EfQEAAKXcGV+76rXXXrMjnXQSQB3NpKOidHEwhzYzTZ48WR588EEbfjQkaVj561//6i2jsxtqoNE5d3QK6Lp169q1NPRcjj59+shvv/1m59fRoKSzReo6GMd3RgYAoCTQyXM///xz6d27d6gvJWywrAPLOgDAWRPOyzoQckrZsg4AAODs0IE9CA4hBwCAAH366ad2Qlsd6av9UXUSWu0PqnPHXXXVVXb0r9YwXHbZZXZOuZN58sknpVmzZnYdR11FXFf81gl1Hc8884ztiqHdNZzajH//+9/2dbU7iC+tHdK+rijmPjkAAARFe03kHArNa0eX03akgIru3LlT+vbtawfN3HDDDbJ//375/vvvdXkk+2ftX/rWW2/Z/VdeeUWuueYa2bhxox20UxB9XtdurF27th11fO+999rndNCNY9OmTfK///1PPvvsM9untWnTpvLoo4/KV199JTfffLMto6OVtR/rN998c4ZuinsQcgAAoaUB5++1Q/Pa/2+HSEz5gEPO0aNH7aLTDRo0sM9prY668sor/cq+//77dvZ/nUvu2muvLfB8OrLY0bBhQ/nTn/5kVxXwDTnaRKW1NzVq1PA+d9ttt8nYsWO9Iee///2vXT5JF+OEP5qrAAAIQLt27ex8cRpsNGD84x//sMsMOZPRak2M1rRoc5V2hj1w4ICdJ64wEyZMkIsuushOYqurd2voOb68hinfgKP0dbTWZvv27XZfa4PuvPNO27EZ/qjJAQCEljYZaY1KqF47QNpcpBPTLliwwIYMbZr685//LIsWLbLTouzZs8dOe6LBROd902lSCussrItJ60S6up6iTo+iwUhrcbSZy5dOs3K8Dh062MClNTw695wubu07jxzyEXIAAKGlNRABNhmFmtaWaO2LbjpPmwYaHRY+f/58Oyec9sNRujbi7t27Cz2PBiX9WQ1Jji1btgR8Hffcc4+dBFdrc7Tzc7169U7znbkTIQcAgABojY0uH6S1JzVr1rT7Oilty5YtbTPVf/7zHzsLv87hMmTIEDsCqzBaXpumtPbm/PPPtzUxGpYCpf1ytA+PNplpjQ4KRp8cAAACoP1svvvuO1tbo0O/tQ+NNi/17NlT/vnPf9r+ObqAtQ7l1hFQGoQK84c//MHO6v/www/bYeJas6NDyAOlzVu6soD25WFywcIx4zEzHgPAWRPOMx6fadoJunXr1vLmm2+KGx0+AzMe01wFAEApojVGc+fOtZvv2pA4ESEHAIBSREdXadB54YUXpHnz5qG+nBKNkAMAQCmyefPmUF9CqUHHYwAA4EqEHAAA4EqEHADAWRfGA3txFj8jhBwAwFkTHR1tHw8dCtGq4yg1nM+I85kpCjoeAwDOGl3/SVfnTk9Pt/vlypVjYUmcUIOjAUc/I/pZ0c9MURFyAABnla66rZygAxREA47zWSkqQg4A4KzSmptatWrZZQ9ycnJCfTkogbSJ6nRqcByEHABASOiX2Jn4IgMKQ8djAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSoQcAADgSkGFnDFjxsi5554r8fHxduvatatMmzbNe/zw4cMycOBAqVatmlSoUEFuuukm2bVrl985tm7dKr169bIrz+q6JUOGDJGjR4/6lZk7d66cd955EhsbK02aNJFx48adcC2jR4+Whg0bStmyZaVLly6yePHi4N89AABwraBCTt26dWXUqFGydOlSWbJkiVx55ZVy/fXXy9q1a+3xxx57TL7++muZNGmSzJs3T3bs2CE33nij9+dzc3NtwDly5IgsWLBAPvzwQxtghg8f7i2Tmppqy1xxxRWyYsUKGTx4sNxzzz0yY8YMb5kJEybI448/LiNGjJBly5ZJu3btJCkpiRVtAQBAPnOaqlSpYj744AOTkZFhoqOjzaRJk7zH1q9fb/QlkpOT7f7UqVNNZGSkSUtL85YZM2aMiY+PN9nZ2XZ/6NChpnXr1n6v0adPH5OUlOTd79y5sxk4cKB3Pzc319SuXduMHDkyqGvPzMy016ePAACgdAj0+7vIfXK0Vmb8+PFy8OBB22yltTs5OTnSvXt3b5kWLVpI/fr1JTk52e7rY9u2bSUhIcFbRmtg9u3b560N0jK+53DKOOfQWiB9Ld8ykZGRdt8pAwAAUCbYH1i9erUNNdr/RvvdfP7559KqVSvbtBQTEyOVK1f2K6+BJi0tzf5ZH30DjnPcOXayMhqEsrKyZO/evTZgFVRmw4YNJ7327Oxsuzn0nAAAwJ2Crslp3ry5DTSLFi2SBx98UPr37y/r1q2T0mDkyJFSqVIl71avXr1QXxIAACgpIUdra3TEU8eOHW1o0E6/b7zxhiQmJtqmpIyMDL/yOrpKjyl9PH60lbN/qjI6misuLk6qV68uUVFRBZZxzlGYYcOGSWZmpnfbtm1bsG8fAACEyzw5eXl5tglIQ090dLTMmjXLeywlJcUOGdfmLaWP2tzlOwpq5syZNsBok5dTxvccThnnHBqy9LV8y+g16L5TpjA6JN0Z/u5sAADAnYLqk6M1IT179rSdiffv3y8ff/yxndNGh3dr88+AAQPs0O6qVavaAPHII4/Y4HHBBRfYn+/Ro4cNM/369ZMXX3zR9r/5y1/+YufW0QCiHnjgAXn77bdl6NChcvfdd8vs2bNl4sSJMmXKFO916GtoM1mnTp2kc+fO8vrrr9sO0HfdddeZvj8AAKC0CmbI1t13320aNGhgYmJiTI0aNUy3bt3MN9984z2elZVlHnroITusvFy5cuaGG24wO3fu9DvH5s2bTc+ePU1cXJypXr26eeKJJ0xOTo5fmTlz5pj27dvb12ncuLEZO3bsCdfy1ltvmfr169syOqR84cKFJlgMIQcAoPQJ9Ps7Qv8jYUpHV2kNlPbPoekKAAB3fX+zdhUAAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHCloELOyJEj5fzzz5eKFStKzZo1pXfv3pKSkuJX5vDhwzJw4ECpVq2aVKhQQW666SbZtWuXX5mtW7dKr169pFy5cvY8Q4YMkaNHj/qVmTt3rpx33nkSGxsrTZo0kXHjxp1wPaNHj5aGDRtK2bJlpUuXLrJ48eLg3j0AAHCtoELOvHnzbIBZuHChzJw5U3JycqRHjx5y8OBBb5nHHntMvv76a5k0aZItv2PHDrnxxhu9x3Nzc23AOXLkiCxYsEA+/PBDG2CGDx/uLZOammrLXHHFFbJixQoZPHiw3HPPPTJjxgxvmQkTJsjjjz8uI0aMkGXLlkm7du0kKSlJ0tPTT/+uAACA0s+chvT0dKOnmDdvnt3PyMgw0dHRZtKkSd4y69evt2WSk5Pt/tSpU01kZKRJS0vzlhkzZoyJj4832dnZdn/o0KGmdevWfq/Vp08fk5SU5N3v3LmzGThwoHc/NzfX1K5d24wcOTLg68/MzLTXpo8AAKB0CPT7+7T65GRmZtrHqlWr2selS5fa2p3u3bt7y7Ro0ULq168vycnJdl8f27ZtKwkJCd4yWgOzb98+Wbt2rbeM7zmcMs45tBZIX8u3TGRkpN13yhQkOzvbvo7vBgAA3KnIIScvL882I1100UXSpk0b+1xaWprExMRI5cqV/cpqoNFjThnfgOMcd46drIyGkqysLNm9e7dt9iqojHOOwvoUVapUybvVq1evqG8fAAC4NeRo35w1a9bI+PHjpbQYNmyYrX1ytm3btoX6kgAAQDEpU5Qfevjhh2Xy5Mny3XffSd26db3PJyYm2qakjIwMv9ocHV2lx5wyx4+CckZf+ZY5fkSW7sfHx0tcXJxERUXZraAyzjkKoiO1dAMAAO4XVE2OMcYGnM8//1xmz54tjRo18jvesWNHiY6OllmzZnmf0yHmOmS8a9eudl8fV69e7TcKSkdqaYBp1aqVt4zvOZwyzjm0SUxfy7eMNp/pvlMGAACEuWB6Mz/44IOmUqVKZu7cuWbnzp3e7dChQ94yDzzwgKlfv76ZPXu2WbJkienatavdHEePHjVt2rQxPXr0MCtWrDDTp083NWrUMMOGDfOW+eWXX0y5cuXMkCFD7Ois0aNHm6ioKFvWMX78eBMbG2vGjRtn1q1bZ+677z5TuXJlv1Fbp8LoKgAASp9Av7+DCjl6woK2sWPHestkZWWZhx56yFSpUsUGlRtuuMEGIV+bN282PXv2NHFxcaZ69ermiSeeMDk5OX5l5syZY9q3b29iYmJM48aN/V7D8dZbb9lApWV0SPnChQuDeTuEHAAASqFAv78j9D8SpnS0lo6y0k7I2lwGAADc8/3N2lUAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVCDkAAMCVgg453333nVx33XVSu3ZtiYiIkC+++MLvuDFGhg8fLrVq1ZK4uDjp3r27bNy40a/M77//LrfffrvEx8dL5cqVZcCAAXLgwAG/MqtWrZJLLrlEypYtK/Xq1ZMXX3zxhGuZNGmStGjRwpZp27atTJ06Ndi3AwAAXCrokHPw4EFp166djB49usDjGkbefPNNeffdd2XRokVSvnx5SUpKksOHD3vLaMBZu3atzJw5UyZPnmyD03333ec9vm/fPunRo4c0aNBAli5dKi+99JI888wz8v7773vLLFiwQPr27WsD0vLly6V37952W7NmTfB3AQAAuI85Dfrjn3/+uXc/Ly/PJCYmmpdeesn7XEZGhomNjTWffPKJ3V+3bp39uR9//NFbZtq0aSYiIsJs377d7r/zzjumSpUqJjs721vmySefNM2bN/fu33LLLaZXr15+19OlSxdz//33B3z9mZmZ9lr0EQAAlA6Bfn+f0T45qampkpaWZpuoHJUqVZIuXbpIcnKy3ddHbaLq1KmTt4yWj4yMtDU/TplLL71UYmJivGW0NiglJUX27t3rLeP7Ok4Z53UKkp2dbWuJfDcAAOBOZzTkaMBRCQkJfs/rvnNMH2vWrOl3vEyZMlK1alW/MgWdw/c1CivjHC/IyJEjbehyNu3rAwAA3CmsRlcNGzZMMjMzvdu2bdtCfUkAAKA0hJzExET7uGvXLr/ndd85po/p6el+x48ePWpHXPmWKegcvq9RWBnneEFiY2PtiC7fDQAAuNMZDTmNGjWyIWPWrFne57Tfi/a16dq1q93Xx4yMDDtqyjF79mzJy8uzfXecMjriKicnx1tGR2I1b95cqlSp4i3j+zpOGed1AABAeAs65Oh8NitWrLCb09lY/7x161Y7b87gwYPlb3/7m3z11VeyevVqueOOO+ycOjq8W7Vs2VKuvvpquffee2Xx4sUyf/58efjhh+XWW2+15dRtt91mOx3r8HAdaj5hwgR544035PHHH/dex6BBg2T69OnyyiuvyIYNG+wQ8yVLlthzAQAABD2EfM6cOXbY1vFb//79vcPIn376aZOQkGCHjnfr1s2kpKT4nWPPnj2mb9++pkKFCiY+Pt7cddddZv/+/X5lVq5caS6++GJ7jjp16phRo0adcC0TJ040zZo1MzExMaZ169ZmypQpQb0XhpADAFD6BPr9HaH/kTClTWk6yko7IdM/BwAAd31/h9XoKgAAED4IOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJUIOQAAwJVKfcgZPXq0NGzYUMqWLStdunSRxYsXh/qSAABACVCqQ86ECRPk8ccflxEjRsiyZcukXbt2kpSUJOnp6aG+NAAAEGKlOuS8+uqrcu+998pdd90lrVq1knfffVfKlSsn//rXv0J9aQAAIMTKSCl15MgRWbp0qQwbNsz7XGRkpHTv3l2Sk5NDem2LftkjR3LzQnoNpUmERIT6EgAAxeT8RlUktkyUhEKpDTm7d++W3NxcSUhI8Hte9zds2FDgz2RnZ9vNsW/fvmK5tkc+WS7p+/NfBwCAcLX4z92kZkVCTrEbOXKkPPvss8X+Ok0TKkjV8jHF/joIP8aIRFDxBaAUKRMZup4xpTbkVK9eXaKiomTXrl1+z+t+YmJigT+jTVvaUdm3JqdevXpn/No+uueCM35OAAAQJh2PY2JipGPHjjJr1izvc3l5eXa/a9euBf5MbGysxMfH+20AAMCdSm1NjtJamf79+0unTp2kc+fO8vrrr8vBgwftaCsAABDeSnXI6dOnj/z2228yfPhwSUtLk/bt28v06dNP6IwMAADCT4Qx2pUxPGmfnEqVKklmZiZNVwAAuOz7u9T2yQEAADgZQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHAlQg4AAHClUr121elyVrTQ6aEBAEDp4Hxvn2plqrAOOfv377eP9erVC/WlAACAInyP6xpWhQnrBTrz8vJkx44dUrFiRYmIiDijCVOD07Zt21j48xS4V4HjXgWH+xU47lXguFcl415pdNGAU7t2bYmMLLznTVjX5OiNqVu3brGdX/+n8pcgMNyrwHGvgsP9Chz3KnDcq9Dfq5PV4DjoeAwAAFyJkAMAAFyJkFMMYmNjZcSIEfYRJ8e9Chz3Kjjcr8BxrwLHvSpd9yqsOx4DAAD3oiYHAAC4EiEHAAC4EiEHAAC4EiGnCL777ju57rrr7CREOongF198ccqfmTt3rpx33nm2A1aTJk1k3LhxEg6CvVd6n7Tc8VtaWpq43ciRI+X888+3k1PWrFlTevfuLSkpKaf8uUmTJkmLFi2kbNmy0rZtW5k6daq4XVHulf6dO/5zpffM7caMGSPnnnuud66Srl27yrRp0076M+H4mSrKvQrXz1RBRo0aZd//4MGDpSR9tgg5RXDw4EFp166djB49OqDyqamp0qtXL7niiitkxYoV9kNwzz33yIwZM8Ttgr1XDv3C2rlzp3fTLzK3mzdvngwcOFAWLlwoM2fOlJycHOnRo4e9h4VZsGCB9O3bVwYMGCDLly+3X/a6rVmzRtysKPdK6ReX7+dqy5Yt4nY64al+AS1dulSWLFkiV155pVx//fWydu3aAsuH62eqKPcqXD9Tx/vxxx/lvffeswHxZELy2dLRVSg6vYWff/75ScsMHTrUtG7d2u+5Pn36mKSkJBNOArlXc+bMseX27t1rwl16erq9F/PmzSu0zC233GJ69erl91yXLl3M/fffb8JJIPdq7NixplKlSmf1ukqqKlWqmA8++KDAY3ymAr9XfKaM2b9/v2natKmZOXOmueyyy8ygQYMKLRuKzxY1OWdBcnKydO/e3e+5pKQk+zwK1r59e6lVq5ZcddVVMn/+fAlHmZmZ9rFq1aqFluGzFfi9UgcOHJAGDRrY9XRO9Ru6G+Xm5sr48eNtjZc2xRSEz1Tg90qF+2dq4MCBtqXi+M9MSflshfXaVWeL9idJSEjwe073dfGyrKwsiYuLC9m1lTQabN59913p1KmTZGdnywcffCCXX365LFq0yPZpCqfFY7VZ86KLLpI2bdoE/dkKhz5Mwd6r5s2by7/+9S9bpa6h6OWXX5YLL7zQfikV5xp2JcHq1avtF/Xhw4elQoUK8vnnn0urVq0KLBvun6lg7lU4f6aUhsBly5bZ5qpAhOKzRchBiaL/aOjm0H8wfv75Z3nttdfkP//5j4TTb0faTv3DDz+E+lJcc6/0i8v3N3L9bLVs2dL2JXjuuefEzfTvlPYH1C/iTz/9VPr372/7NRX25R3OgrlX4fyZ2rZtmwwaNMj2iSvJna0JOWdBYmKi7Nq1y+853dcOa9TinFrnzp3D6sv+4YcflsmTJ9uRaaf6bbCwz5Y+Hw6CuVfHi46Olg4dOsimTZvE7WJiYuyoTtWxY0f7m/cbb7xhv4yPF+6fqWDuVTh/ppYuXSrp6el+NezaxKd/F99++21bEx8VFRXyzxZ9cs4CTfqzZs3ye07T78naeZFPf6vSZiy3077Z+qWt1eOzZ8+WRo0anfJnwvWzVZR7dTz9B1mbJsLhs1VQE59+CRUkXD9TRblX4fyZ6tatm32v+u+zs2k3g9tvv93++fiAE7LPVrF1aXZ5b/Lly5fbTW/hq6++av+8ZcsWe/ypp54y/fr185b/5ZdfTLly5cyQIUPM+vXrzejRo01UVJSZPn26cbtg79Vrr71mvvjiC7Nx40azevVq21M/MjLSfPvtt8btHnzwQTtSY+7cuWbnzp3e7dChQ94yeq/0njnmz59vypQpY15++WX72RoxYoSJjo62987NinKvnn32WTNjxgzz888/m6VLl5pbb73VlC1b1qxdu9a4md4DHXWWmppqVq1aZfcjIiLMN998Y4/zmSr6vQrXz1Rhjh9dVRI+W4ScInCGOR+/9e/f3x7XR/2fffzPtG/f3sTExJjGjRvboYfhINh79cILL5hzzjnH/kNRtWpVc/nll5vZs2ebcFDQfdLN97Oi98q5d46JEyeaZs2a2c+WTlUwZcoU43ZFuVeDBw829evXt/cpISHBXHPNNWbZsmXG7e6++27ToEED+75r1KhhunXr5v3SVnymin6vwvUzFWjIKQmfLVYhBwAArkSfHAAA4EqEHAAA4EqEHAAA4EqEHAAA4EqEHAAA4EqEHAAA4EqEHAAA4EqEHAAA4EqEHAABufzyy2Xw4MGhvgxXGDdunFSuXPmkZZ555hlp3779WbsmwI0IOQBKlc2bN0tERIRdBLCkaNiwobz++usBl+/Tp4/89NNPxXpNAETKhPoCACBQR44cETeIi4uzG4DiRU0OgBMcPHhQ7rjjDqlQoYLUqlVLXnnlFb/j2dnZ8qc//Unq1Kkj5cuXly5dusjcuXNPaI754osvpGnTplK2bFlJSkqSbdu2ecv8/PPPcv3110tCQoJ9nfPPP1++/fbbE2pInnvuOXst8fHxct9990mjRo3ssQ4dOtgaHW1GU3feeaf07t1b/v73v9tz6uv/9a9/laNHj8qQIUOkatWqUrduXRk7dqzfa+g13XLLLba8ltFr0toih3Pel19+2d6LatWqycCBAyUnJ8ce19ffsmWLPPbYY/Z6dCtKc9WoUaPsdVesWFEGDBgghw8fDuj/FYDCEXIAnEBDwbx58+TLL7+Ub775xgaYZcuWeY8//PDDkpycLOPHj5dVq1bJzTffLFdffbVs3LjRW+bQoUPy/PPPy7///W+ZP3++ZGRkyK233uo9fuDAAbnmmmtk1qxZsnz5cvvz1113nWzdutXvWjRctGvXzpZ5+umnZfHixfZ5DUQ7d+6Uzz77zFt29uzZsmPHDvnuu+/k1VdflREjRsi1114rVapUkUWLFskDDzwg999/v/z666+2vAYVDV8aLL7//nt7nRq49Fp8a43mzJljQ5k+fvjhhzak6Kb09TU8aaDS69EtWBMnTrR9cDSgLVmyxIapd955J+jzADhOsa5xDqDU2b9/v4mJiTETJ070Prdnzx4TFxdnBg0aZLZs2WKioqLM9u3b/X6uW7duZtiwYfbPY8eONfrPy8KFC73H169fb59btGhRoa/dunVr89Zbb3n3GzRoYHr37u1XJjU11Z5n+fLlfs/379/fls/NzfU+17x5c3PJJZd4948ePWrKly9vPvnkE7v/n//8x5bJy8vzlsnOzrbvdcaMGX7n1Z913HzzzaZPnz5+1/naa6+ZQOn9qVSpkne/a9eu5qGHHvIr06VLF9OuXbuAzwngRNTkAPCjNRZai6FNUA5txmnevLn98+rVqyU3N1eaNWtmaz2cTWt+9GcdZcqUsU1QjhYtWtgmmvXr13trcrTJq2XLlvZ5PYceO74mp1OnTgFfe+vWrSUyMv+fNW3+adu2rXc/KirKNjelp6fb/ZUrV8qmTZtsTY7zPvS9alOR73vR8+rPOrSmxTnHmaDv2/d+q65du56x8wPhio7HAIKi4US/8JcuXer3xa80JARKA87MmTNtc1STJk1sR9w//vGPJ3Qu1j4/gYqOjvbb1/4xBT2Xl5fnfS8dO3aUjz766IRz1ahR46Tndc4BoOQi5ADwc84559gvde3DUr9+ffvc3r177ZDnyy67zHb41Zocrcm45JJLCj2PdvjV/iWdO3e2+ykpKbZfjtbcKO3/op16b7jhBm/g8O3wW5iYmBj7qNdwus477zyZMGGC1KxZ03ZsLiq9ptO5Hr0ner+1g7Vj4cKFRT4fAA+aqwCcUBujo3u087F25F2zZo0NI04zkDZT3X777fYLWTvdpqam2s7AI0eOlClTpnjPo0HpkUcesV/eWuuj57jgggu8oUdHXenP63w32mx02223BVQ7ooFEa32mT58uu3btkszMzCK/V30f1atXtyOqtOOxvhftZP3oo496OycHQkeBaWfn7du3y+7du4O+jkGDBsm//vUvO/JLw6R2mF67dm3Q5wHgj5AD4AQvvfSSraXR0U7du3eXiy++2DbrOPTLWEPOE088Yfvq6BDrH3/80Vvzo8qVKydPPvmkDS8XXXSRDU9aa+LQ0U866unCCy+0r6OjnLRm5VS0r8+bb74p7733ntSuXdsGlKLSa9Rwotd944032hoVZ/h2MDU7OrJKa6G0Fsy3mSuYyQF15NjQoUPtfdYh6Q8++GDQ5wHgL0J7Hx/3HACcFh1erUtAaPMUAIQKNTkAAMCVCDkAcIb17NnTb3i976YT/gE4O2iuAoAzTDsgZ2VlFXhM5+HRDUDxI+QAAABXorkKAAC4EiEHAAC4EiEHAAC4EiEHAAC4EiEHAAC4EiEHAAC4EiEHAAC4EiEHAACIG/1/i40DGeeTNaEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_df = df[df['hire_date']>'2020-01-01']\n",
    "tmp_df.groupby(['department_id'])[['employee_id','salary']].agg(\n",
    "    {\n",
    "        \"employee_id\":np.count_nonzero,\n",
    "        \"salary\":np.mean\n",
    "    }\n",
    ").query(\"salary > 60000\").plot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad0bf36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [3, 4, 5]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[1,2,3],[3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf4a4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf  =df['salary'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61290082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7       NaN\n",
       "6       NaN\n",
       "3    3000.0\n",
       "9    3000.0\n",
       "2    2000.0\n",
       "4    3500.0\n",
       "5    6500.0\n",
       "1    4500.0\n",
       "8    2000.0\n",
       "0    4000.0\n",
       "Name: salary, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(sdf-sdf.shift(1)).rolling(2).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
