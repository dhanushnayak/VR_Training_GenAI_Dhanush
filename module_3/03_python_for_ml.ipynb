{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Machine Learning (Revision)\n",
    "\n",
    "## Learning Objectives\n",
    "- Review NumPy and Pandas for data handling\n",
    "- Master Matplotlib and Seaborn for visualization\n",
    "- Understand Scikit-learn basics for ML workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy for Numerical Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Array creation and basic operations\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "print(\"1D Array:\", arr)\n",
    "print(\"2D Matrix:\\n\", matrix)\n",
    "print(\"Shape:\", matrix.shape)\n",
    "print(\"Data type:\", matrix.dtype)\n",
    "\n",
    "# Mathematical operations\n",
    "print(\"\\nMath Operations:\")\n",
    "print(\"Mean:\", np.mean(arr))\n",
    "print(\"Standard deviation:\", np.std(arr))\n",
    "print(\"Matrix multiplication:\\n\", np.dot(matrix, matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas for Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create sample dataset\n",
    "data = {\n",
    "    'age': [25, 30, 35, 40, 45],\n",
    "    'salary': [50000, 60000, 70000, 80000, 90000],\n",
    "    'department': ['IT', 'HR', 'IT', 'Finance', 'HR'],\n",
    "    'experience': [2, 5, 8, 12, 15]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Dataset:\")\n",
    "print(df)\n",
    "\n",
    "# Basic operations\n",
    "print(\"\\nDataset Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Data types:\\n{df.dtypes}\")\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation operations\n",
    "print(\"Data Manipulation Examples:\")\n",
    "\n",
    "# Filtering\n",
    "high_salary = df[df['salary'] > 65000]\n",
    "print(\"\\nHigh salary employees:\")\n",
    "print(high_salary)\n",
    "\n",
    "# Grouping\n",
    "dept_stats = df.groupby('department').agg({\n",
    "    'salary': ['mean', 'count'],\n",
    "    'age': 'mean'\n",
    "})\n",
    "print(\"\\nDepartment statistics:\")\n",
    "print(dept_stats)\n",
    "\n",
    "# Adding new columns\n",
    "df['salary_per_year_exp'] = df['salary'] / df['experience']\n",
    "print(\"\\nDataset with new column:\")\n",
    "print(df[['salary', 'experience', 'salary_per_year_exp']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib for Basic Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Basic plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Line plot\n",
    "axes[0, 0].plot(df['experience'], df['salary'], 'o-')\n",
    "axes[0, 0].set_title('Salary vs Experience')\n",
    "axes[0, 0].set_xlabel('Experience (years)')\n",
    "axes[0, 0].set_ylabel('Salary')\n",
    "\n",
    "# Bar plot\n",
    "dept_counts = df['department'].value_counts()\n",
    "axes[0, 1].bar(dept_counts.index, dept_counts.values)\n",
    "axes[0, 1].set_title('Employees by Department')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "\n",
    "# Histogram\n",
    "axes[1, 0].hist(df['age'], bins=5, alpha=0.7)\n",
    "axes[1, 0].set_title('Age Distribution')\n",
    "axes[1, 0].set_xlabel('Age')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Scatter plot\n",
    "colors = {'IT': 'blue', 'HR': 'red', 'Finance': 'green'}\n",
    "for dept in df['department'].unique():\n",
    "    dept_data = df[df['department'] == dept]\n",
    "    axes[1, 1].scatter(dept_data['age'], dept_data['salary'], \n",
    "                      c=colors[dept], label=dept, alpha=0.7)\n",
    "axes[1, 1].set_title('Age vs Salary by Department')\n",
    "axes[1, 1].set_xlabel('Age')\n",
    "axes[1, 1].set_ylabel('Salary')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn for Statistical Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create larger dataset for better visualization\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "large_data = {\n",
    "    'age': np.random.normal(35, 8, n_samples),\n",
    "    'salary': np.random.normal(65000, 15000, n_samples),\n",
    "    'experience': np.random.normal(8, 4, n_samples),\n",
    "    'department': np.random.choice(['IT', 'HR', 'Finance', 'Marketing'], n_samples)\n",
    "}\n",
    "large_df = pd.DataFrame(large_data)\n",
    "\n",
    "# Seaborn plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Distribution plot\n",
    "sns.histplot(data=large_df, x='salary', hue='department', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Salary Distribution by Department')\n",
    "\n",
    "# Box plot\n",
    "sns.boxplot(data=large_df, x='department', y='salary', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Salary Distribution by Department')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Correlation heatmap\n",
    "numeric_cols = ['age', 'salary', 'experience']\n",
    "correlation = large_df[numeric_cols].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Correlation Matrix')\n",
    "\n",
    "# Pair plot (using subplot)\n",
    "sns.scatterplot(data=large_df, x='experience', y='salary', hue='department', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Experience vs Salary')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Generate sample dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, \n",
    "                          n_informative=5, random_state=42)\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Target distribution: {np.bincount(y)}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Original data statistics:\")\n",
    "print(f\"Mean: {X_train.mean():.3f}, Std: {X_train.std():.3f}\")\n",
    "print(\"\\nScaled data statistics:\")\n",
    "print(f\"Mean: {X_train_scaled.mean():.3f}, Std: {X_train_scaled.std():.3f}\")\n",
    "\n",
    "# Model training and evaluation\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Use scaled data for logistic regression, original for random forest\n",
    "    if name == 'Logistic Regression':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    \n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Compare models\n",
    "print(\"\\nModel Comparison:\")\n",
    "for name, accuracy in results.items():\n",
    "    print(f\"{name}: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete ML Pipeline Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV score:\", grid_search.best_score_)\n",
    "\n",
    "# Final evaluation\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "final_accuracy = accuracy_score(y_test, y_pred_final)\n",
    "\n",
    "print(f\"\\nFinal test accuracy: {final_accuracy:.3f}\")\n",
    "\n",
    "# Confusion matrix visualization\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### NumPy\n",
    "- Efficient numerical operations\n",
    "- Foundation for other ML libraries\n",
    "- Array manipulation and mathematical functions\n",
    "\n",
    "### Pandas\n",
    "- Data loading, cleaning, and manipulation\n",
    "- Handling structured data (CSV, Excel, databases)\n",
    "- Grouping, filtering, and aggregation operations\n",
    "\n",
    "### Matplotlib\n",
    "- Basic plotting and visualization\n",
    "- Customizable plots for presentations\n",
    "- Foundation for other visualization libraries\n",
    "\n",
    "### Seaborn\n",
    "- Statistical visualization\n",
    "- Beautiful default styles\n",
    "- Easy exploration of relationships in data\n",
    "\n",
    "### Scikit-learn\n",
    "- Consistent API across algorithms\n",
    "- Built-in preprocessing and evaluation tools\n",
    "- Pipeline support for clean workflows\n",
    "\n",
    "## Next Steps\n",
    "- Learn mathematical foundations for ML\n",
    "- Explore deep learning frameworks (TensorFlow, Keras)\n",
    "- Practice with real-world datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}