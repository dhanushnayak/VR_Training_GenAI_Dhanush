{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Machine Learning\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand data components (features, labels, datasets)\n",
    "- Learn about bias vs variance tradeoff\n",
    "- Understand underfitting vs overfitting\n",
    "- Master train-validation-test splits and cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Data\n",
    "\n",
    "### Key Components\n",
    "- **Features (X)**: Input variables used to make predictions\n",
    "- **Labels (y)**: Target variable we want to predict\n",
    "- **Training Set**: Data used to train the model\n",
    "- **Test Set**: Data used to evaluate final model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "\n",
    "# Example dataset\n",
    "X, y = make_regression(n_samples=100, n_features=2, noise=10, random_state=42)\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "df = pd.DataFrame(X, columns=['Feature_1', 'Feature_2'])\n",
    "df['Target'] = y\n",
    "\n",
    "print(\"Dataset Structure:\")\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Labels (y): {y.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias vs. Variance\n",
    "\n",
    "### Bias\n",
    "- **Definition**: Error due to overly simplistic assumptions\n",
    "- **High Bias**: Model consistently misses relevant patterns (underfitting)\n",
    "- **Low Bias**: Model captures underlying patterns well\n",
    "\n",
    "### Variance\n",
    "- **Definition**: Error due to sensitivity to small fluctuations in training data\n",
    "- **High Variance**: Model varies significantly with different training sets (overfitting)\n",
    "- **Low Variance**: Model is consistent across different training sets\n",
    "\n",
    "### The Tradeoff\n",
    "Total Error = BiasÂ² + Variance + Irreducible Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Bias-Variance Tradeoff\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Generate simple dataset\n",
    "np.random.seed(42)\n",
    "X_simple = np.linspace(0, 1, 50).reshape(-1, 1)\n",
    "y_true = 1.5 * X_simple.ravel() + 0.5 * np.sin(2 * np.pi * X_simple.ravel())\n",
    "y_simple = y_true + np.random.normal(0, 0.1, X_simple.shape[0])\n",
    "\n",
    "# Different model complexities\n",
    "degrees = [1, 4, 15]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, degree in enumerate(degrees):\n",
    "    # Fit polynomial model\n",
    "    poly_model = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=degree)),\n",
    "        ('linear', LinearRegression())\n",
    "    ])\n",
    "    poly_model.fit(X_simple, y_simple)\n",
    "    \n",
    "    # Predictions\n",
    "    X_plot = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "    y_pred = poly_model.predict(X_plot)\n",
    "    \n",
    "    # Plot\n",
    "    axes[i].scatter(X_simple, y_simple, alpha=0.6, label='Data')\n",
    "    axes[i].plot(X_plot, y_pred, 'r-', label=f'Degree {degree}')\n",
    "    axes[i].set_title(f'Polynomial Degree {degree}\\n' + \n",
    "                     ('High Bias' if degree == 1 else \n",
    "                      'Good Fit' if degree == 4 else 'High Variance'))\n",
    "    axes[i].legend()\n",
    "    axes[i].set_xlabel('X')\n",
    "    axes[i].set_ylabel('y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underfitting vs. Overfitting\n",
    "\n",
    "### Underfitting (High Bias)\n",
    "- Model is too simple to capture underlying patterns\n",
    "- Poor performance on both training and test data\n",
    "- **Solutions**: Increase model complexity, add features, reduce regularization\n",
    "\n",
    "### Overfitting (High Variance)\n",
    "- Model memorizes training data including noise\n",
    "- Good performance on training data, poor on test data\n",
    "- **Solutions**: Reduce model complexity, add regularization, get more data\n",
    "\n",
    "### Good Fit\n",
    "- Model captures underlying patterns without memorizing noise\n",
    "- Good performance on both training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating overfitting with learning curves\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# Generate dataset\n",
    "X_curve, y_curve = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "\n",
    "# Validation curve for polynomial degrees\n",
    "degrees = range(1, 16)\n",
    "train_scores, val_scores = validation_curve(\n",
    "    Pipeline([('poly', PolynomialFeatures()), ('linear', LinearRegression())]),\n",
    "    X_curve, y_curve, param_name='poly__degree', param_range=degrees,\n",
    "    cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Convert to positive MSE\n",
    "train_mse = -train_scores.mean(axis=1)\n",
    "val_mse = -val_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(degrees, train_mse, 'o-', label='Training Error', color='blue')\n",
    "plt.fill_between(degrees, train_mse - train_std, train_mse + train_std, alpha=0.2, color='blue')\n",
    "plt.plot(degrees, val_mse, 'o-', label='Validation Error', color='red')\n",
    "plt.fill_between(degrees, val_mse - val_std, val_mse + val_std, alpha=0.2, color='red')\n",
    "\n",
    "plt.xlabel('Polynomial Degree (Model Complexity)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Learning Curve: Underfitting vs Overfitting')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotations\n",
    "plt.annotate('Underfitting\\n(High Bias)', xy=(2, train_mse[1]), xytext=(3, train_mse[1] + 500),\n",
    "            arrowprops=dict(arrowstyle='->', color='black'), fontsize=10)\n",
    "plt.annotate('Overfitting\\n(High Variance)', xy=(12, val_mse[11]), xytext=(10, val_mse[11] + 500),\n",
    "            arrowprops=dict(arrowstyle='->', color='black'), fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation-Test Splits\n",
    "\n",
    "### Purpose of Each Set\n",
    "- **Training Set (60-70%)**: Used to train the model\n",
    "- **Validation Set (15-20%)**: Used for hyperparameter tuning and model selection\n",
    "- **Test Set (15-20%)**: Used for final, unbiased evaluation\n",
    "\n",
    "### Why Three Sets?\n",
    "- Prevents data leakage\n",
    "- Provides unbiased performance estimates\n",
    "- Enables proper hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate sample dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "\n",
    "# First split: separate test set (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: separate train and validation (75% train, 25% validation of remaining)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Dataset Splits:\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Training set: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation set: {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Visualize the split\n",
    "fig, ax = plt.subplots(figsize=(10, 2))\n",
    "splits = ['Training', 'Validation', 'Test']\n",
    "sizes = [len(X_train), len(X_val), len(X_test)]\n",
    "colors = ['skyblue', 'lightgreen', 'lightcoral']\n",
    "\n",
    "left = 0\n",
    "for i, (split, size, color) in enumerate(zip(splits, sizes, colors)):\n",
    "    ax.barh(0, size, left=left, color=color, label=f'{split} ({size})')\n",
    "    ax.text(left + size/2, 0, f'{split}\\n{size}', ha='center', va='center')\n",
    "    left += size\n",
    "\n",
    "ax.set_xlim(0, len(X))\n",
    "ax.set_ylim(-0.5, 0.5)\n",
    "ax.set_xlabel('Number of Samples')\n",
    "ax.set_title('Train-Validation-Test Split')\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### K-Fold Cross-Validation\n",
    "- Divide data into k equal folds\n",
    "- Train on k-1 folds, validate on 1 fold\n",
    "- Repeat k times, average results\n",
    "- More robust than single train-validation split\n",
    "\n",
    "### Benefits\n",
    "- Better use of limited data\n",
    "- More reliable performance estimates\n",
    "- Reduces variance in evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation Example\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 5-Fold Cross-Validation\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"5-Fold Cross-Validation Results:\")\n",
    "print(f\"Fold scores: {cv_scores}\")\n",
    "print(f\"Mean accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "# Visualize CV folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    # Create array to show train/validation split\n",
    "    split_array = np.zeros(len(X_train))\n",
    "    split_array[val_idx] = 1  # 1 for validation, 0 for training\n",
    "    \n",
    "    ax.imshow(split_array.reshape(1, -1), cmap='RdYlBu', aspect='auto', \n",
    "              extent=[0, len(X_train), i, i+1])\n",
    "    ax.text(-20, i+0.5, f'Fold {i+1}', va='center', ha='right')\n",
    "\n",
    "ax.set_xlim(0, len(X_train))\n",
    "ax.set_ylim(0, 5)\n",
    "ax.set_xlabel('Sample Index')\n",
    "ax.set_ylabel('CV Fold')\n",
    "ax.set_title('5-Fold Cross-Validation Splits\\n(Blue: Training, Red: Validation)')\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### Data Splitting\n",
    "1. **Stratify**: Maintain class distribution in splits\n",
    "2. **Random State**: Ensure reproducible results\n",
    "3. **Time Series**: Use temporal splits for time-dependent data\n",
    "\n",
    "### Model Evaluation\n",
    "1. **Never touch test set** until final evaluation\n",
    "2. **Use cross-validation** for model selection\n",
    "3. **Monitor both training and validation performance**\n",
    "4. **Consider multiple metrics** for comprehensive evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete workflow example\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. Hyperparameter tuning using cross-validation\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid, cv=5, scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV score:\", grid_search.best_score_)\n",
    "\n",
    "# 2. Final evaluation on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(f\"\\nFinal test accuracy: {test_score:.3f}\")\n",
    "\n",
    "# 3. Detailed evaluation\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Understanding ML fundamentals is crucial for building effective models:\n",
    "\n",
    "- **Data Understanding**: Know your features, labels, and data splits\n",
    "- **Bias-Variance Tradeoff**: Balance model complexity\n",
    "- **Overfitting Prevention**: Use proper validation techniques\n",
    "- **Cross-Validation**: Get reliable performance estimates\n",
    "\n",
    "## Next Steps\n",
    "- Review Python libraries for ML (NumPy, Pandas, Scikit-learn)\n",
    "- Learn mathematical foundations (calculus, linear algebra, statistics)\n",
    "- Explore specific ML algorithms and their implementations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}